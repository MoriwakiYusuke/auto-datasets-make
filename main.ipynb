{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f6ae47d",
   "metadata": {},
   "source": [
    "## ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30528b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ef483a",
   "metadata": {},
   "source": [
    "## ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5600567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- è¨­å®šé …ç›® ---\n",
    "# ã‚¯ãƒ­ãƒ¼ãƒ³å¯¾è±¡ã®ãƒªãƒã‚¸ãƒˆãƒªURLãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«\n",
    "url_file_path = 'url_list.txt'\n",
    "# ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "clone_to_directory = 'cloned_repositories'\n",
    "\n",
    "# --- å‡¦ç†ã®é–‹å§‹ ---\n",
    "print(f\"--- Starting: Cloning repositories into '{clone_to_directory}' ---\")\n",
    "\n",
    "# ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã™ã‚‹\n",
    "os.makedirs(clone_to_directory, exist_ok=True)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# URLãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€\n",
    "try:\n",
    "    with open(url_file_path, 'r') as file:\n",
    "        # ç©ºè¡Œã‚’é™¤å¤–ã—ã¦ãƒªã‚¹ãƒˆåŒ–ã™ã‚‹\n",
    "        urls = [line.strip() for line in file.readlines() if line.strip()]\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: '{url_file_path}' was not found.\")\n",
    "    print(\"Please make sure the file exists in the same directory as the notebook.\")\n",
    "    urls = [] # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒªã‚¹ãƒˆã‚’ç©ºã«ã™ã‚‹\n",
    "\n",
    "for repo_url in urls:\n",
    "    # --- æ—¢å­˜ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¹ã‚­ãƒƒãƒ—å‡¦ç† ---\n",
    "    # URLã‹ã‚‰ãƒªãƒã‚¸ãƒˆãƒªåã‚’å–å¾—ã™ã‚‹\n",
    "    repo_name = repo_url.split('/')[-1].replace('.git', '')\n",
    "    # ãƒªãƒã‚¸ãƒˆãƒªã®ä¿å­˜ãƒ‘ã‚¹ã‚’æ§‹ç¯‰ã™ã‚‹\n",
    "    repo_path = os.path.join(clone_to_directory, repo_name)\n",
    "    \n",
    "    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã€å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹\n",
    "    if os.path.isdir(repo_path):\n",
    "        print(f\"ğŸŸ¢ Skipping: {repo_name} (Directory already exists)\")\n",
    "        print(\"-\" * 50)\n",
    "        continue\n",
    "\n",
    "    print(f\"Cloning: {repo_url}\")\n",
    "    try:\n",
    "        # git cloneãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ã—ã€é€²æ—ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¡¨ç¤ºã™ã‚‹\n",
    "        # --progressãƒ•ãƒ©ã‚°ã§é€²æ—è¡¨ç¤ºã‚’å¼·åˆ¶ã—ã€stderrã‹ã‚‰å‡ºåŠ›ã‚’å—ã‘å–ã‚‹\n",
    "        process = subprocess.Popen(\n",
    "            ['git', 'clone', '--progress', repo_url],\n",
    "            cwd=clone_to_directory,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "            encoding='utf-8',\n",
    "            errors='replace' # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼ã‚’å›é¿\n",
    "        )\n",
    "\n",
    "        # æ¨™æº–ã‚¨ãƒ©ãƒ¼ã‚’1è¡Œãšã¤èª­ã¿è¾¼ã¿ã€é€²æ—ã¨ã—ã¦è¡¨ç¤ºã™ã‚‹\n",
    "        while process.poll() is None:\n",
    "            line = process.stderr.readline()\n",
    "            if line:\n",
    "                # ã‚«ãƒ¼ã‚½ãƒ«ã‚’è¡Œé ­ã«æˆ»ã—ã€é€²æ—è¡¨ç¤ºã‚’ä¸Šæ›¸ãã™ã‚‹\n",
    "                print(f\"   {line.strip()}\", end='\\r')\n",
    "        \n",
    "        # æœ€å¾Œã®é€²æ—è¡¨ç¤ºè¡Œã‚’ã‚¯ãƒªã‚¢ã™ã‚‹\n",
    "        print(\" \" * 80, end=\"\\r\")\n",
    "\n",
    "        # ã‚¯ãƒ­ãƒ¼ãƒ³ã®æˆå¦ã‚’åˆ¤å®šã™ã‚‹\n",
    "        if process.returncode == 0:\n",
    "            print(\"âœ… Clone successful.\")\n",
    "        else:\n",
    "            # ã‚¨ãƒ©ãƒ¼å†…å®¹ã‚’å–å¾—ã—ã¦è¡¨ç¤ºã™ã‚‹\n",
    "            stdout_err, stderr_err = process.communicate()\n",
    "            error_message = stderr_err if stderr_err else stdout_err\n",
    "            print(f\"âŒ Error cloning. Reason: {error_message.strip()}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ Error: 'git' command not found. Please install Git and ensure it is in your system's PATH.\")\n",
    "        break # GitãŒãªã„å ´åˆã¯å‡¦ç†ã‚’ä¸­æ–­\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "print(\"Clone process finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bc9665",
   "metadata": {},
   "source": [
    "## sbom-toolã®sbomã‚’ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "eeaebc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- è¨­å®šé …ç›® ---\n",
    "clone_to_directory = 'cloned_repositories'\n",
    "sbom_output_directory = 'generated_sboms'\n",
    "\n",
    "# --- å‡¦ç†ã®é–‹å§‹ ---\n",
    "print(f\"--- Starting: Generating and moving SBOMs ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "original_path = os.getcwd()\n",
    "os.makedirs(sbom_output_directory, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # ã‚¯ãƒ­ãƒ¼ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒªãƒã‚¸ãƒˆãƒªä¸€è¦§ã‚’å–å¾—ã™ã‚‹\n",
    "    repo_dirs = [d for d in os.listdir(clone_to_directory) if os.path.isdir(os.path.join(clone_to_directory, d))]\n",
    "    \n",
    "    if not repo_dirs:\n",
    "        print(\"No repositories found to run commands on.\")\n",
    "\n",
    "    for repo_name in repo_dirs:\n",
    "        # æœ€çµ‚çš„ãªä¿å­˜å…ˆãƒ‘ã‚¹ã‚’å®šç¾©ã™ã‚‹\n",
    "        final_repo_dir = os.path.join(original_path, sbom_output_directory, repo_name)\n",
    "        final_manifest_path = os.path.join(final_repo_dir, 'source', '_manifest')\n",
    "\n",
    "        # æ—¢ã«æˆæœç‰©ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹\n",
    "        if os.path.isdir(final_manifest_path):\n",
    "            print(f\"ğŸŸ¢ Skipping: {repo_name} (SBOM manifest already exists)\")\n",
    "            print(\"-\" * 50)\n",
    "            continue\n",
    "\n",
    "        repo_path = os.path.join(clone_to_directory, repo_name)\n",
    "        print(f\"â–¶ï¸  Entering: {repo_name}\")\n",
    "        \n",
    "        try:\n",
    "            os.chdir(repo_path)\n",
    "            \n",
    "            # --- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾— ---\n",
    "            package_name = repo_name\n",
    "            git_version_result = subprocess.run(['git', 'rev-parse', 'HEAD'], capture_output=True, text=True, check=True)\n",
    "            package_version = git_version_result.stdout.strip()\n",
    "            \n",
    "            # .git/configã‹ã‚‰ã‚µãƒ—ãƒ©ã‚¤ãƒ¤ãƒ¼ï¼ˆæ‰€æœ‰è€…ï¼‰æƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹\n",
    "            package_supplier = \"Unknown\"\n",
    "            with open('.git/config', 'r') as config_file:\n",
    "                match = re.search(r'url\\s*=\\s*https?://github\\.com/([^/]+)/', config_file.read())\n",
    "                if match:\n",
    "                    package_supplier = match.group(1)\n",
    "            \n",
    "            print(f\"   Package Name: {package_name}\")\n",
    "            print(f\"   Package Version: {package_version[:12]}...\")\n",
    "            print(f\"   Package Supplier: {package_supplier}\")\n",
    "            \n",
    "            # æ—¢å­˜ã®SBOMå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒã‚ã‚Œã°å‰Šé™¤ã™ã‚‹\n",
    "            if os.path.isdir('_manifest'):\n",
    "                print(\"   Found existing '_manifest' directory. Removing it.\")\n",
    "                shutil.rmtree('_manifest')\n",
    "\n",
    "            # --- sbom-toolå®Ÿè¡Œ ---\n",
    "            command = [\n",
    "                'sbom-tool', 'generate', '-bc', '.', '-b', '.',\n",
    "                '-pn', package_name, '-pv', package_version, '-ps', package_supplier\n",
    "            ]\n",
    "            print(f\"   Executing: {' '.join(command)}\")\n",
    "            subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "            print(\"âœ… SBOM generation successful.\")\n",
    "\n",
    "            # --- ç§»å‹•å‡¦ç† ---\n",
    "            source_manifest_path = '_manifest'\n",
    "            \n",
    "            if os.path.isdir(source_manifest_path):\n",
    "                # 'source' ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã€ãã®ä¸­ã«æˆæœç‰©ã‚’ç§»å‹•ã™ã‚‹\n",
    "                destination_dir = os.path.join(final_repo_dir, 'source')\n",
    "                os.makedirs(destination_dir, exist_ok=True)\n",
    "                \n",
    "                print(f\"   Moving '{source_manifest_path}' into: {destination_dir}\")\n",
    "                shutil.move(source_manifest_path, destination_dir)\n",
    "                print(\"âœ… Move successful.\")\n",
    "            else:\n",
    "                print(f\"âš ï¸ Warning: Could not find generated manifest directory at '{source_manifest_path}'\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"âŒ Error: The command 'sbom-tool' or 'git' was not found.\")\n",
    "            break\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"âŒ Error executing command in {repo_name}.\")\n",
    "            if e.stdout:\n",
    "                print(f\"   [stdout]:\\n{e.stdout.strip()}\")\n",
    "            if e.stderr:\n",
    "                print(f\"   [stderr]:\\n{e.stderr.strip()}\")\n",
    "        finally:\n",
    "            os.chdir(original_path)\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: The directory '{clone_to_directory}' was not found.\")\n",
    "\n",
    "print(\"All processes finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5f0d61",
   "metadata": {},
   "source": [
    "## syftã®sbomç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ff455b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- è¨­å®šé …ç›® ---\n",
    "clone_to_directory = 'cloned_repositories'\n",
    "sbom_output_directory = 'generated_sboms'\n",
    "\n",
    "# --- å‡¦ç†ã®é–‹å§‹ ---\n",
    "print(f\"--- Starting: Generating SBOMs with Syft ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# å®Ÿè¡Œå‰ã®ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä¿å­˜ã™ã‚‹\n",
    "original_path = os.getcwd()\n",
    "os.makedirs(sbom_output_directory, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # ã‚¯ãƒ­ãƒ¼ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒªãƒã‚¸ãƒˆãƒªä¸€è¦§ã‚’å–å¾—ã™ã‚‹\n",
    "    repo_dirs = [d for d in os.listdir(clone_to_directory) if os.path.isdir(os.path.join(clone_to_directory, d))]\n",
    "    \n",
    "    if not repo_dirs:\n",
    "        print(\"No repositories found to run commands on.\")\n",
    "\n",
    "    for repo_name in repo_dirs:\n",
    "        repo_path = os.path.join(clone_to_directory, repo_name)\n",
    "        \n",
    "        try:\n",
    "            # --- æœ€çµ‚çš„ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å®šç¾© ---\n",
    "            destination_dir = os.path.join(original_path, sbom_output_directory, repo_name, 'source')\n",
    "            final_sbom_filename = \"syft-sbom.json\"\n",
    "            final_sbom_path = os.path.join(destination_dir, final_sbom_filename)\n",
    "\n",
    "            # --- å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã‹ã®åˆ¤å®š ---\n",
    "            # æ—¢ã«æˆæœç‰©ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹\n",
    "            if os.path.exists(final_sbom_path):\n",
    "                print(f\"ğŸŸ¢ Skipping: {repo_name} (SBOM file already exists)\")\n",
    "                print(\"-\" * 50)\n",
    "                continue\n",
    "\n",
    "            print(f\"â–¶ï¸  Entering: {repo_name}\")\n",
    "            os.chdir(repo_path)\n",
    "            \n",
    "            # --- syftã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè¡Œ ---\n",
    "            temp_sbom_filename = 'syft-sbom.json'\n",
    "            # ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã€SPDX JSONå½¢å¼ã§å‡ºåŠ›ã™ã‚‹\n",
    "            command = ['syft', 'dir:./', '-o', 'spdx-json']\n",
    "            print(f\"   Executing: {' '.join(command)} > {temp_sbom_filename}\")\n",
    "            \n",
    "            result = subprocess.run(\n",
    "                command, check=True, capture_output=True, text=True\n",
    "            )\n",
    "            print(\"âœ… Syft execution successful.\")\n",
    "\n",
    "            # syftã®æ¨™æº–å‡ºåŠ›ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€\n",
    "            with open(temp_sbom_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(result.stdout)\n",
    "\n",
    "            # --- ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æœ€çµ‚çš„ãªå ´æ‰€ã«ç§»å‹• ---\n",
    "            os.makedirs(destination_dir, exist_ok=True)\n",
    "            print(f\"   Moving SBOM to: {final_sbom_path}\")\n",
    "            shutil.move(temp_sbom_filename, final_sbom_path)\n",
    "            print(\"âœ… SBOM file saved.\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"âŒ Error: The command 'syft' or 'git' was not found.\")\n",
    "            break\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"âŒ Error executing command in {repo_name}.\")\n",
    "            if e.stdout:\n",
    "                print(f\"   [stdout]:\\n{e.stdout.strip()}\")\n",
    "            if e.stderr:\n",
    "                print(f\"   [stderr]:\\n{e.stderr.strip()}\")\n",
    "        finally:\n",
    "            # ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å…ƒã«æˆ»ã™\n",
    "            os.chdir(original_path)\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: The directory '{clone_to_directory}' was not found.\")\n",
    "\n",
    "print(\"All processes finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6036a3",
   "metadata": {},
   "source": [
    "## dependency graphã®sbomå–å¾—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e6600f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- è¨­å®šé …ç›® ---\n",
    "\n",
    "# 1. GitHubãƒªãƒã‚¸ãƒˆãƒªã®URLãƒªã‚¹ãƒˆãŒæ›¸ã‹ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«\n",
    "url_file_path = 'url_list.txt'\n",
    "\n",
    "# 2. ç”Ÿæˆã•ã‚ŒãŸSBOM(JSONãƒ•ã‚¡ã‚¤ãƒ«)ã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "sbom_output_directory = 'generated_sboms'\n",
    "\n",
    "\n",
    "# --- å‡¦ç†ã®é–‹å§‹ ---\n",
    "print(\"--- Starting: Fetching SBOMs from GitHub API (No Token) ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "original_path = os.getcwd()\n",
    "os.makedirs(sbom_output_directory, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    with open(url_file_path, 'r') as file:\n",
    "        urls = [line.strip() for line in file.readlines() if line.strip()]\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: '{url_file_path}' was not found.\")\n",
    "    urls = []\n",
    "\n",
    "for repo_url in urls:\n",
    "    # URLã‹ã‚‰ownerã¨repoã‚’æŠ½å‡º\n",
    "    match = re.search(r\"github\\.com/([^/]+)/([^/.]+)\", repo_url)\n",
    "    if not match:\n",
    "        print(f\"âš ï¸ Warning: Could not parse owner/repo from URL: {repo_url}\")\n",
    "        continue\n",
    "    \n",
    "    owner, repo_name = match.groups()\n",
    "    \n",
    "    # --- ä¿å­˜å…ˆã®ãƒ‘ã‚¹ã‚’å®šç¾©ã—ã€ã‚¹ã‚­ãƒƒãƒ—åˆ¤å®š ---\n",
    "    destination_dir = os.path.join(original_path, sbom_output_directory, repo_name, 'source')\n",
    "    final_sbom_path = os.path.join(destination_dir, 'dependency-graph-sbom.json')\n",
    "\n",
    "    if os.path.exists(final_sbom_path):\n",
    "        print(f\"ğŸŸ¢ Skipping: {repo_name} (SBOM file already exists)\")\n",
    "        print(\"-\" * 50)\n",
    "        continue\n",
    "        \n",
    "    print(f\"â–¶ï¸  Fetching SBOM for: {owner}/{repo_name}\")\n",
    "\n",
    "    # --- GitHub APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ (èªè¨¼ãƒ˜ãƒƒãƒ€ãƒ¼ãªã—) ---\n",
    "    api_url = f\"https://api.github.com/repos/{owner}/{repo_name}/dependency-graph/sbom\"\n",
    "    headers = {\n",
    "        \"Accept\": \"application/vnd.github+json\",\n",
    "        \"X-GitHub-Api-Version\": \"2022-11-28\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(api_url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            print(\"âœ… API request successful.\")\n",
    "            sbom_data = response.json().get('sbom')\n",
    "            if not sbom_data:\n",
    "                print(f\"âŒ Error: 'sbom' key not found in the API response for {repo_name}.\")\n",
    "                continue\n",
    "\n",
    "            # --- SBOMã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ ---\n",
    "            os.makedirs(destination_dir, exist_ok=True)\n",
    "            print(f\"   Writing SBOM to: {final_sbom_path}\")\n",
    "            \n",
    "            with open(final_sbom_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(sbom_data, f, ensure_ascii=False, indent=2)\n",
    "            print(\"âœ… SBOM file saved.\")\n",
    "\n",
    "        elif response.status_code == 404:\n",
    "            print(f\"âš ï¸ Warning: Could not fetch SBOM for {repo_name}. (Status: 404)\")\n",
    "            print(\"   The repository may not exist, or the Dependency Graph may not be enabled.\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"âŒ Error: Failed to fetch SBOM for {repo_name}. Status code: {response.status_code}\")\n",
    "            print(f\"   Response: {response.text}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"âŒ Error: A network error occurred while contacting the GitHub API.\")\n",
    "        print(f\"   Details: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "print(\"All processes finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b95ab33",
   "metadata": {},
   "source": [
    "## trivyã®sbomå–å¾—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "77d4a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- è¨­å®šé …ç›® ---\n",
    "\n",
    "# ã‚¯ãƒ­ãƒ¼ãƒ³ã•ã‚ŒãŸãƒªãƒã‚¸ãƒˆãƒªã®ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "clone_to_directory = 'cloned_repositories'\n",
    "# ç”Ÿæˆã•ã‚ŒãŸSBOMã®ä¿å­˜ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "sbom_output_directory = 'generated_sboms'\n",
    "\n",
    "# --- å‡¦ç†ã®é–‹å§‹ ---\n",
    "# Trivyã‚’ä½¿ã£ãŸSBOMç”Ÿæˆå‡¦ç†é–‹å§‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º\n",
    "print(f\"--- Starting: Generating SBOMs with Trivy ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# ç¾åœ¨ã®ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä¿å­˜\n",
    "original_path = os.getcwd()\n",
    "# SBOMå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ\n",
    "os.makedirs(sbom_output_directory, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # ã‚¯ãƒ­ãƒ¼ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒªãƒã‚¸ãƒˆãƒªä¸€è¦§ã‚’å–å¾—\n",
    "    repo_dirs = [d for d in os.listdir(clone_to_directory) if os.path.isdir(os.path.join(clone_to_directory, d))]\n",
    "    \n",
    "    if not repo_dirs:\n",
    "        print(\"No repositories found to run commands on.\")\n",
    "\n",
    "    # å„ãƒªãƒã‚¸ãƒˆãƒªã«å¯¾ã—ã¦Trivyã‚’ä½¿ã£ãŸSBOMç”Ÿæˆå‡¦ç†ã‚’å®Ÿè¡Œ\n",
    "    for repo_name in repo_dirs:\n",
    "        repo_path = os.path.join(clone_to_directory, repo_name)\n",
    "        \n",
    "        try:\n",
    "            # --- æœ€çµ‚çš„ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å®šç¾© ---\n",
    "            # SBOMã®æœ€çµ‚çš„ãªä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ§‹ç¯‰\n",
    "            destination_dir = os.path.join(original_path, sbom_output_directory, repo_name, 'source')\n",
    "            \n",
    "            # ç”Ÿæˆã•ã‚Œã‚‹SBOMã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ 'trivy-sbom.json' ã«å›ºå®š\n",
    "            final_sbom_filename = \"trivy-sbom.json\"\n",
    "            \n",
    "            # æœ€çµ‚çš„ãªSBOMãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ãƒ«ãƒ‘ã‚¹ã‚’æ§‹ç¯‰\n",
    "            final_sbom_path = os.path.join(destination_dir, final_sbom_filename)\n",
    "\n",
    "            # --- å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã‹ã®åˆ¤å®š ---\n",
    "            # æ—¢ã«SBOMãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—\n",
    "            if os.path.exists(final_sbom_path):\n",
    "                print(f\"ğŸŸ¢ Skipping: {repo_name} (SBOM file already exists)\")\n",
    "                print(\"-\" * 50)\n",
    "                continue\n",
    "\n",
    "            # --- ã“ã“ã‹ã‚‰ãƒªãƒã‚¸ãƒˆãƒªå†…ã§ã®å‡¦ç† ---\n",
    "            print(f\"â–¶ï¸  Entering: {repo_name}\")\n",
    "            # ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ‘ã‚¹ã«å¤‰æ›´\n",
    "            os.chdir(repo_path)\n",
    "            \n",
    "            # --- trivyã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè¡Œ ---\n",
    "            # trivyãŒå‡ºåŠ›ã™ã‚‹ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å®šç¾©\n",
    "            temp_sbom_filename = 'spdx-json-by-trivy.json'\n",
    "            # trivyã‚³ãƒãƒ³ãƒ‰ã‚’æ§‹ç¯‰\n",
    "            command = ['trivy', 'fs', '.', '--format', 'spdx-json', '--output', temp_sbom_filename]\n",
    "            print(f\"   Executing: {' '.join(command)}\")\n",
    "            \n",
    "            # trivyã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ\n",
    "            # Trivyã¯ãƒ•ã‚¡ã‚¤ãƒ«ã«ç›´æ¥å‡ºåŠ›ã™ã‚‹ãŸã‚ã€å‡ºåŠ›ã®ã‚­ãƒ£ãƒ—ãƒãƒ£ã¯ä¸è¦\n",
    "            subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "            print(\"âœ… Trivy execution successful.\")\n",
    "\n",
    "            # --- ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æœ€çµ‚çš„ãªå ´æ‰€ã«ç§»å‹• ---\n",
    "            # æœ€çµ‚çš„ãªä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ\n",
    "            os.makedirs(destination_dir, exist_ok=True)\n",
    "            print(f\"   Moving SBOM to: {final_sbom_path}\")\n",
    "            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æœ€çµ‚çš„ãªä¿å­˜å…ˆã«ãƒªãƒãƒ¼ãƒ ã—ãªãŒã‚‰ç§»å‹•\n",
    "            shutil.move(temp_sbom_filename, final_sbom_path)\n",
    "            print(\"âœ… SBOM file saved.\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            # 'trivy'ã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼å‡¦ç†\n",
    "            print(f\"âŒ Error: The command 'trivy' was not found.\")\n",
    "            break\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            # ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã®å‡¦ç†\n",
    "            print(f\"âŒ Error executing command in {repo_name}.\")\n",
    "            if e.stdout:\n",
    "                print(f\"   [stdout]:\\n{e.stdout.strip()}\")\n",
    "            if e.stderr:\n",
    "                print(f\"   [stderr]:\\n{e.stderr.strip()}\")\n",
    "        finally:\n",
    "            # ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å…ƒã®ãƒ‘ã‚¹ã«æˆ»ã™\n",
    "            os.chdir(original_path)\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    # ã‚¯ãƒ­ãƒ¼ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼å‡¦ç†\n",
    "    print(f\"âŒ Error: The directory '{clone_to_directory}' was not found.\")\n",
    "\n",
    "# å…¨ã¦ã®Trivyã‚’ä½¿ã£ãŸSBOMç”Ÿæˆå‡¦ç†ãŒå®Œäº†\n",
    "print(\"All processes finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1539950b",
   "metadata": {},
   "source": [
    "## sbom-toolã®sbomã‚’ã‚‚ã¨ã«ã—ã¦ä½œæˆã™ã‚‹ãŸã‚ã‚½ãƒ¼ãƒˆã—ã¦ã‚³ãƒ”ãƒ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a2e5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- è¨­å®šé …ç›® ---\n",
    "\n",
    "# 1. å‡¦ç†å¯¾è±¡ã®è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "target_directory = 'generated_sboms'\n",
    "\n",
    "# 2. ç”Ÿæˆã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å\n",
    "target_filename = 'combined_sbom.json'\n",
    "\n",
    "# 3. ä¸¦ã³æ›¿ãˆãŸã„ã‚­ãƒ¼ã®é †ç•ª\n",
    "key_order = [\n",
    "    \"SPDXID\",\n",
    "    \"spdxVersion\",\n",
    "    \"creationInfo\",\n",
    "    \"name\",\n",
    "    \"dataLicense\",\n",
    "    \"documentNamespace\",\n",
    "    \"documentDescribes\",\n",
    "    \"externalDocumentRefs\",\n",
    "    \"packages\",\n",
    "    \"files\",\n",
    "    \"relationships\",\n",
    "]\n",
    "\n",
    "\n",
    "# --- å‡¦ç†ã®é–‹å§‹ ---\n",
    "print(f\"--- Starting: Copying and reordering SBOMs ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "try:\n",
    "    # 'generated_sboms' å†…ã®ãƒªãƒã‚¸ãƒˆãƒªåã‚’å–å¾—\n",
    "    repo_dirs = [d for d in os.listdir(target_directory) if os.path.isdir(os.path.join(target_directory, d))]\n",
    "    \n",
    "    if not repo_dirs:\n",
    "         print(f\"No repository directories found in '{target_directory}'.\")\n",
    "\n",
    "    for repo_name in repo_dirs:\n",
    "        print(f\"â–¶ï¸  Processing: {repo_name}\")\n",
    "\n",
    "        # --- ãƒ‘ã‚¹ã®å®šç¾© ---\n",
    "        source_sbom_path = os.path.join(target_directory, repo_name, 'source', '_manifest', 'spdx_2.2', 'manifest.spdx.json')\n",
    "        destination_sbom_path = os.path.join(target_directory, repo_name, target_filename)\n",
    "\n",
    "        # --- ã‚¹ã‚­ãƒƒãƒ—åˆ¤å®š ---\n",
    "        if os.path.exists(destination_sbom_path):\n",
    "            print(f\"ğŸŸ¢ Skipping: '{target_filename}' already exists.\")\n",
    "            print(\"-\" * 50)\n",
    "            continue\n",
    "        \n",
    "        # --- ã‚³ãƒ”ãƒ¼å…ƒã®å­˜åœ¨ç¢ºèª ---\n",
    "        if not os.path.exists(source_sbom_path):\n",
    "            print(f\"âš ï¸ Warning: sbom-tool SBOM not found for {repo_name}. Skipping.\")\n",
    "            print(\"-\" * 50)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—1: ã‚³ãƒ”ãƒ¼ ---\n",
    "            print(f\"   Copying sbom-tool's output to '{target_filename}'...\")\n",
    "            shutil.copy(source_sbom_path, destination_sbom_path)\n",
    "            print(\"   âœ… Copy successful.\")\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—2: èª­ã¿è¾¼ã¿ã¨ä¸¦ã³æ›¿ãˆ ---\n",
    "            with open(destination_sbom_path, 'r', encoding='utf-8') as f:\n",
    "                original_data = json.load(f)\n",
    "\n",
    "            ordered_data = {}\n",
    "            # æŒ‡å®šã•ã‚ŒãŸé †ã§ã‚­ãƒ¼ã‚’è¿½åŠ \n",
    "            for key in key_order:\n",
    "                if key in original_data:\n",
    "                    ordered_data[key] = original_data[key]\n",
    "            # æ®‹ã‚Šã®ã‚­ãƒ¼ã‚’æœ«å°¾ã«è¿½åŠ \n",
    "            for key, value in original_data.items():\n",
    "                if key not in ordered_data:\n",
    "                    ordered_data[key] = value\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—3: æ•´å½¢ã—ã¦ä¸Šæ›¸ãä¿å­˜ ---\n",
    "            print(f\"   Reordering keys...\")\n",
    "            with open(destination_sbom_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(ordered_data, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"   âœ… Keys reordered and saved.\")\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"âŒ Error: Could not parse source JSON file. It may be corrupted.\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ An unexpected error occurred: {e}\")\n",
    "        \n",
    "        finally:\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: The source directory '{target_directory}' was not found.\")\n",
    "\n",
    "print(\"All processes finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb964aea",
   "metadata": {},
   "source": [
    "## dependency-graphã‹ã‚‰æƒ…å ±ã‚’è£œå®Œ\n",
    "\n",
    "licence decler\n",
    ",,conclude\n",
    "copyright text \n",
    "creatorè¿½åŠ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "63d8ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_purl_from_package(pkg):\n",
    "    \"\"\"ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æƒ…å ±ã‹ã‚‰purlï¼ˆPackage URLï¼‰ã‚’æŠ½å‡ºã™ã‚‹ã€‚\"\"\"\n",
    "    if 'externalRefs' in pkg:\n",
    "        for ref in pkg['externalRefs']:\n",
    "            if ref.get('referenceType') == 'purl':\n",
    "                return ref.get('referenceLocator')\n",
    "    return None\n",
    "\n",
    "# --- è¨­å®šé …ç›® ---\n",
    "target_directory = 'generated_sboms'\n",
    "base_sbom_filename = 'combined_sbom.json'\n",
    "source_sbom_filename = 'dependency-graph-sbom.json'\n",
    "\n",
    "\n",
    "# --- å‡¦ç†ã®é–‹å§‹ ---\n",
    "print(f\"--- Starting: Supplementing '{base_sbom_filename}' with richer data and comments ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "try:\n",
    "    # 'generated_sboms' ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒªãƒã‚¸ãƒˆãƒªåä¸€è¦§ã‚’å–å¾—ã™ã‚‹\n",
    "    repo_dirs = [d for d in os.listdir(target_directory) if os.path.isdir(os.path.join(target_directory, d))]\n",
    "\n",
    "    if not repo_dirs:\n",
    "        print(f\"No repository directories found in '{target_directory}'.\")\n",
    "\n",
    "    # å„ãƒªãƒã‚¸ãƒˆãƒªã«å¯¾ã—ã¦å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹\n",
    "    for repo_name in repo_dirs:\n",
    "        print(f\"â–¶ï¸  Processing: {repo_name}\")\n",
    "\n",
    "        # --- ãƒ‘ã‚¹ã®å®šç¾© ---\n",
    "        base_sbom_path = os.path.join(target_directory, repo_name, base_sbom_filename)\n",
    "        source_sbom_path = os.path.join(target_directory, repo_name, 'source', source_sbom_filename)\n",
    "\n",
    "        # --- ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª ---\n",
    "        if not os.path.exists(base_sbom_path) or not os.path.exists(source_sbom_path):\n",
    "            print(f\"âš ï¸ Warning: One or both SBOM files are missing. Skipping.\")\n",
    "            print(\"-\" * 50)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—1: ä¸¡æ–¹ã®SBOMãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ ---\n",
    "            with open(base_sbom_path, 'r', encoding='utf-8') as f:\n",
    "                base_data = json.load(f)\n",
    "            with open(source_sbom_path, 'r', encoding='utf-8') as f:\n",
    "                source_data = json.load(f)\n",
    "\n",
    "            changes_made = 0\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—2: æ—¢å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®æƒ…å ±ã‚’è£œå®Œ ---\n",
    "            # è£œå®Œå…ƒãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æƒ…å ±ã‚’purlã‚’ã‚­ãƒ¼ã«ãƒãƒƒãƒ—åŒ–ã—ã€æ¤œç´¢ã‚’é«˜é€ŸåŒ–ã™ã‚‹\n",
    "            source_package_map = {}\n",
    "            if 'packages' in source_data:\n",
    "                for pkg in source_data['packages']:\n",
    "                    purl = get_purl_from_package(pkg)\n",
    "                    if purl:\n",
    "                        source_package_map[purl] = {\n",
    "                            'licenseConcluded': pkg.get('licenseConcluded', 'NOASSERTION'),\n",
    "                            'copyrightText': pkg.get('copyrightText', 'NOASSERTION')\n",
    "                        }\n",
    "\n",
    "            # ãƒ™ãƒ¼ã‚¹SBOMã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æƒ…å ±ã‚’é †ã«ç¢ºèªã—ã€ä¸è¶³ã—ã¦ã„ã‚Œã°è£œå®Œã™ã‚‹\n",
    "            if 'packages' in base_data:\n",
    "                for pkg in base_data['packages']:\n",
    "                    purl = get_purl_from_package(pkg)\n",
    "                    if purl and purl in source_package_map:\n",
    "                        source_pkg_info = source_package_map[purl]\n",
    "\n",
    "                        if pkg.get('licenseConcluded') == 'NOASSERTION' and source_pkg_info['licenseConcluded'] != 'NOASSERTION':\n",
    "                            pkg['licenseConcluded'] = source_pkg_info['licenseConcluded']\n",
    "                            changes_made += 1\n",
    "                            print(f\"   Updated license for: {pkg.get('name')}\")\n",
    "\n",
    "                        if pkg.get('copyrightText') == 'NOASSERTION' and source_pkg_info['copyrightText'] != 'NOASSERTION':\n",
    "                            pkg['copyrightText'] = source_pkg_info['copyrightText']\n",
    "                            changes_made += 1\n",
    "                            print(f\"   Updated copyright for: {pkg.get('name')}\")\n",
    "            \n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—3: ä¸è¶³ã—ã¦ã„ã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã€Œãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åã€ã§åˆ¤å®šã—ã¦è¿½åŠ  ---\n",
    "            if 'packages' in source_data:\n",
    "                # ãƒ™ãƒ¼ã‚¹SBOMã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åã‚’ã‚»ãƒƒãƒˆã«æ ¼ç´ã—ã€æ¤œç´¢ã‚’é«˜é€ŸåŒ–ã™ã‚‹\n",
    "                base_pkg_names = {pkg.get('name') for pkg in base_data.get('packages', []) if pkg.get('name')}\n",
    "                new_pkgs_added = 0\n",
    "                \n",
    "                for source_pkg in source_data.get('packages', []):\n",
    "                    pkg_name = source_pkg.get('name')\n",
    "                    # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åãŒãƒ™ãƒ¼ã‚¹SBOMã«å­˜åœ¨ã—ãªã„å ´åˆã®ã¿è¿½åŠ ã™ã‚‹\n",
    "                    if pkg_name and pkg_name not in base_pkg_names:\n",
    "                        base_data.setdefault('packages', []).append(source_pkg)\n",
    "                        base_pkg_names.add(pkg_name) # è¿½åŠ ã—ãŸåå‰ã‚’ã‚»ãƒƒãƒˆã«åŠ ãˆã€é‡è¤‡è¿½åŠ ã‚’é˜²ã\n",
    "                        new_pkgs_added += 1\n",
    "                        print(f\"   Added new package from dependency-graph: {pkg_name}\")\n",
    "                \n",
    "                if new_pkgs_added > 0:\n",
    "                    changes_made += new_pkgs_added\n",
    "                    print(f\"   A total of {new_pkgs_added} new packages were added.\")\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—4: creationInfo.creators ã®æƒ…å ±ã‚’è¿½è¨˜ ---\n",
    "            if 'creationInfo' in source_data and 'creators' in source_data['creationInfo'] and \\\n",
    "               'creationInfo' in base_data and 'creators' in base_data['creationInfo']:\n",
    "                base_creators = base_data['creationInfo']['creators']\n",
    "                for creator in source_data['creationInfo']['creators']:\n",
    "                    if creator not in base_creators:\n",
    "                        base_creators.append(creator)\n",
    "                        changes_made += 1\n",
    "                        print(f\"   Added creator: {creator}\")\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—5: ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¿½è¨˜ ---\n",
    "            source_doc_comment = source_data.get('comment')\n",
    "            if source_doc_comment:\n",
    "                comment_header = \"Note from dependency-graph\"\n",
    "                full_comment_to_add = f\"{comment_header}: {source_doc_comment}\"\n",
    "                if 'comment' not in base_data or not base_data.get('comment'):\n",
    "                    base_data['comment'] = full_comment_to_add\n",
    "                    changes_made += 1\n",
    "                    print(\"   Added document-level comment.\")\n",
    "                elif full_comment_to_add not in base_data['comment']:\n",
    "                    base_data['comment'] += f\"\\\\n\\\\n{full_comment_to_add}\"\n",
    "                    changes_made += 1\n",
    "                    print(\"   Appended document-level comment.\")\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—6: å¤‰æ›´ãŒã‚ã£ãŸå ´åˆã®ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ãä¿å­˜ ---\n",
    "            if changes_made > 0:\n",
    "                print(f\"   {changes_made} fields were updated/added. Reordering and saving file...\")\n",
    "\n",
    "                # ã‚­ãƒ¼ã®é †åºã‚’å®šç¾©ã—ã€ãã‚Œã«å¾“ã£ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†æ§‹ç¯‰ã™ã‚‹\n",
    "                key_order = [\n",
    "                    \"SPDXID\", \"spdxVersion\", \"creationInfo\", \"name\", \"dataLicense\",\n",
    "                    \"documentNamespace\", \"comment\", \"documentDescribes\", \"externalDocumentRefs\",\n",
    "                    \"packages\", \"files\", \"relationships\"\n",
    "                ]\n",
    "                ordered_data = {key: base_data[key] for key in key_order if key in base_data}\n",
    "                ordered_data.update({key: value for key, value in base_data.items() if key not in ordered_data})\n",
    "\n",
    "                with open(base_sbom_path, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(ordered_data, f, indent=2, ensure_ascii=False)\n",
    "                print(f\"âœ… Successfully supplemented '{base_sbom_filename}'.\")\n",
    "            else:\n",
    "                print(\"   No fields needed updating or adding.\")\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"âŒ Error: Could not parse a JSON file. Details: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ An unexpected error occurred: {e}\")\n",
    "        finally:\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: The top-level directory '{target_directory}' was not found.\")\n",
    "\n",
    "print(\"All processes finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7103721d",
   "metadata": {},
   "source": [
    "## syft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4a2e1aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_purl_from_package(pkg):\n",
    "    \"\"\"ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æƒ…å ±ã‹ã‚‰purlï¼ˆPackage URLï¼‰ã‚’æŠ½å‡ºã™ã‚‹ã€‚\"\"\"\n",
    "    if 'externalRefs' in pkg:\n",
    "        for ref in pkg['externalRefs']:\n",
    "            if ref.get('referenceType') == 'purl':\n",
    "                return ref.get('referenceLocator')\n",
    "    return None\n",
    "\n",
    "# --- è¨­å®šé …ç›® ---\n",
    "target_directory = 'generated_sboms'\n",
    "base_sbom_filename = 'combined_sbom.json'\n",
    "source_sbom_filename = 'syft-sbom.json'\n",
    "\n",
    "# --- å‡¦ç†ã®é–‹å§‹ ---\n",
    "print(f\"--- Starting: Supplementing '{base_sbom_filename}' with data from syft (using name for matching) ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "try:\n",
    "    # 'generated_sboms' å†…ã®ãƒªãƒã‚¸ãƒˆãƒªåã‚’å–å¾—ã™ã‚‹\n",
    "    repo_dirs = [d for d in os.listdir(target_directory) if os.path.isdir(os.path.join(target_directory, d))]\n",
    "    \n",
    "    if not repo_dirs:\n",
    "        print(f\"No repository directories found in '{target_directory}'.\")\n",
    "\n",
    "    # å„ãƒªãƒã‚¸ãƒˆãƒªã«å¯¾ã—ã¦å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹\n",
    "    for repo_name in repo_dirs:\n",
    "        print(f\"â–¶ï¸  Processing: {repo_name}\")\n",
    "\n",
    "        # --- ãƒ‘ã‚¹ã®å®šç¾© ---\n",
    "        base_sbom_path = os.path.join(target_directory, repo_name, base_sbom_filename)\n",
    "        source_sbom_path = os.path.join(target_directory, repo_name, 'source', source_sbom_filename)\n",
    "\n",
    "        # --- ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª ---\n",
    "        if not os.path.exists(base_sbom_path) or not os.path.exists(source_sbom_path):\n",
    "            print(f\"âš ï¸ Warning: One or both SBOM files are missing. Skipping.\")\n",
    "            print(\"-\" * 50)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—1: ä¸¡æ–¹ã®SBOMãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ ---\n",
    "            with open(base_sbom_path, 'r', encoding='utf-8') as f:\n",
    "                base_data = json.load(f)\n",
    "            with open(source_sbom_path, 'r', encoding='utf-8') as f:\n",
    "                source_data = json.load(f)\n",
    "\n",
    "            # å¤‰æ›´ã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã€å‡¦ç†å‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜ã™ã‚‹\n",
    "            initial_data_str = json.dumps(base_data, sort_keys=True)\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—2: syftã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æƒ…å ±ã‚’purlã‚’ã‚­ãƒ¼ã«ã—ãŸè¾æ›¸ã«æ•´ç† ---\n",
    "            source_package_map = {}\n",
    "            if 'packages' in source_data:\n",
    "                for pkg in source_data['packages']:\n",
    "                    purl = get_purl_from_package(pkg)\n",
    "                    if purl and purl not in source_package_map:\n",
    "                        source_package_map[purl] = pkg\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—3: æ—¢å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®æƒ…å ±ã‚’è£œå®Œ ---\n",
    "            base_purls = set()\n",
    "            if 'packages' in base_data:\n",
    "                for pkg in base_data['packages']:\n",
    "                    purl = get_purl_from_package(pkg)\n",
    "                    if purl:\n",
    "                        base_purls.add(purl)\n",
    "                        if purl in source_package_map:\n",
    "                            source_pkg = source_package_map[purl]\n",
    "                            \n",
    "                            # ã‚µãƒ—ãƒ©ã‚¤ãƒ¤ãƒ¼æƒ…å ±ã‚’è£œå®Œ\n",
    "                            if (not pkg.get('supplier') or pkg.get('supplier') == 'NOASSERTION') and \\\n",
    "                               source_pkg.get('supplier') and source_pkg.get('supplier') != 'NOASSERTION':\n",
    "                                pkg['supplier'] = source_pkg['supplier']\n",
    "                            \n",
    "                            # ä½œæˆå…ƒæƒ…å ±ã‚’è£œå®Œ\n",
    "                            if (not pkg.get('originator') or pkg.get('originator') == 'NOASSERTION') and \\\n",
    "                               source_pkg.get('originator') and source_pkg.get('originator') != 'NOASSERTION':\n",
    "                                pkg['originator'] = source_pkg['originator']\n",
    "\n",
    "                            # æ¤œå‡ºå…ƒæƒ…å ±ã‚’è£œå®Œ\n",
    "                            if 'sourceInfo' not in pkg and source_pkg.get('sourceInfo'):\n",
    "                                pkg['sourceInfo'] = source_pkg['sourceInfo']\n",
    "                            \n",
    "                            # å¤–éƒ¨ãƒªãƒ³ã‚¯(CPEãªã©)ã‚’è¿½è¨˜\n",
    "                            if 'externalRefs' not in pkg: pkg['externalRefs'] = []\n",
    "                            existing_locators = {ref.get('referenceLocator') for ref in pkg['externalRefs']}\n",
    "                            for new_ref in source_pkg.get('externalRefs', []):\n",
    "                                if new_ref.get('referenceLocator') not in existing_locators:\n",
    "                                    pkg['externalRefs'].append(new_ref)\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—4: ä¸è¶³ã—ã¦ã„ã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã€Œãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åã€ã§åˆ¤å®šã—ã¦è¿½åŠ  ---\n",
    "            if 'packages' in source_data:\n",
    "                # ãƒ™ãƒ¼ã‚¹SBOMã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åã‚’ã‚»ãƒƒãƒˆã«æ ¼ç´ã—ã€æ¤œç´¢ã‚’é«˜é€ŸåŒ–ã™ã‚‹\n",
    "                base_pkg_names = {pkg.get('name') for pkg in base_data.get('packages', []) if pkg.get('name')}\n",
    "                \n",
    "                for source_pkg in source_data.get('packages', []):\n",
    "                    pkg_name = source_pkg.get('name')\n",
    "                    # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åãŒãƒ™ãƒ¼ã‚¹SBOMã«å­˜åœ¨ã—ãªã„å ´åˆã®ã¿è¿½åŠ ã™ã‚‹\n",
    "                    if pkg_name and pkg_name not in base_pkg_names:\n",
    "                        base_data.setdefault('packages', []).append(source_pkg)\n",
    "                        base_pkg_names.add(pkg_name) # è¿½åŠ ã—ãŸåå‰ã‚’ã‚»ãƒƒãƒˆã«åŠ ãˆã€é‡è¤‡è¿½åŠ ã‚’é˜²ã\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—5: syftã®ãƒ„ãƒ¼ãƒ«æƒ…å ±ã‚’creatorsã«è¿½åŠ  ---\n",
    "            if 'creationInfo' in source_data and 'creators' in source_data['creationInfo']:\n",
    "                base_creators = base_data.setdefault('creationInfo', {}).setdefault('creators', [])\n",
    "                for creator in source_data['creationInfo']['creators']:\n",
    "                    if creator not in base_creators:\n",
    "                        base_creators.append(creator)\n",
    "            \n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—6: å¤‰æ›´ãŒã‚ã£ãŸå ´åˆã®ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ ---\n",
    "            if initial_data_str != json.dumps(base_data, sort_keys=True):\n",
    "                print(f\"   Changes detected. Reordering keys and saving file...\")\n",
    "\n",
    "                # ã‚­ãƒ¼ã®é †åºã‚’å®šç¾©ã—ã€ãã‚Œã«å¾“ã£ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†æ§‹ç¯‰ã™ã‚‹\n",
    "                key_order = [\n",
    "                    \"SPDXID\", \"spdxVersion\", \"creationInfo\", \"name\", \"dataLicense\",\n",
    "                    \"documentNamespace\", \"comment\", \"documentDescribes\", \"externalDocumentRefs\",\n",
    "                    \"packages\", \"files\", \"relationships\"\n",
    "                ]\n",
    "                ordered_data = {key: base_data[key] for key in key_order if key in base_data}\n",
    "                ordered_data.update({key: value for key, value in base_data.items() if key not in ordered_data})\n",
    "\n",
    "                with open(base_sbom_path, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(ordered_data, f, indent=2, ensure_ascii=False)\n",
    "                print(f\"âœ… Successfully supplemented and reordered '{base_sbom_filename}'.\")\n",
    "            else:\n",
    "                print(\"   No new information to supplement from syft.\")\n",
    "\n",
    "        except (json.JSONDecodeError, KeyError) as e:\n",
    "            print(f\"âŒ Error processing files for {repo_name}. Details: {e}\")\n",
    "        \n",
    "        finally:\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: The top-level directory '{target_directory}' was not found.\")\n",
    "\n",
    "print(\"All processes finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61f686b",
   "metadata": {},
   "source": [
    "trivy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5c6f7d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_purl_from_package(pkg):\n",
    "    \"\"\"ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æƒ…å ±ã‹ã‚‰purlï¼ˆPackage URLï¼‰ã‚’æŠ½å‡ºã™ã‚‹ã€‚\"\"\"\n",
    "    if 'externalRefs' in pkg:\n",
    "        for ref in pkg['externalRefs']:\n",
    "            if ref.get('referenceType') == 'purl':\n",
    "                return ref.get('referenceLocator')\n",
    "    return None\n",
    "\n",
    "# --- è¨­å®šé …ç›® ---\n",
    "target_directory = 'generated_sboms'\n",
    "base_sbom_filename = 'combined_sbom.json'\n",
    "# Trivyã§ç”Ÿæˆã—ãŸãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŒ‡å®š\n",
    "source_sbom_filename = 'trivy-sbom.json'\n",
    "\n",
    "# --- å‡¦ç†ã®é–‹å§‹ ---\n",
    "print(f\"--- Starting: Supplementing '{base_sbom_filename}' with data from Trivy ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "try:\n",
    "    # 'generated_sboms' å†…ã®ãƒªãƒã‚¸ãƒˆãƒªåã‚’å–å¾—ã™ã‚‹\n",
    "    repo_dirs = [d for d in os.listdir(target_directory) if os.path.isdir(os.path.join(target_directory, d))]\n",
    "    \n",
    "    if not repo_dirs:\n",
    "        print(f\"No repository directories found in '{target_directory}'.\")\n",
    "\n",
    "    # å„ãƒªãƒã‚¸ãƒˆãƒªã«å¯¾ã—ã¦å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹\n",
    "    for repo_name in repo_dirs:\n",
    "        print(f\"â–¶ï¸  Processing: {repo_name}\")\n",
    "\n",
    "        # --- ãƒ‘ã‚¹ã®å®šç¾© ---\n",
    "        base_sbom_path = os.path.join(target_directory, repo_name, base_sbom_filename)\n",
    "        source_sbom_path = os.path.join(target_directory, repo_name, 'source', source_sbom_filename)\n",
    "\n",
    "        # --- ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª ---\n",
    "        if not os.path.exists(base_sbom_path) or not os.path.exists(source_sbom_path):\n",
    "            print(f\"âš ï¸ Warning: One or both SBOM files are missing. Skipping.\")\n",
    "            print(\"-\" * 50)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—1: ä¸¡æ–¹ã®SBOMãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ ---\n",
    "            with open(base_sbom_path, 'r', encoding='utf-8') as f:\n",
    "                base_data = json.load(f)\n",
    "            with open(source_sbom_path, 'r', encoding='utf-8') as f:\n",
    "                source_data = json.load(f)\n",
    "\n",
    "            initial_data_str = json.dumps(base_data, sort_keys=True)\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—2: Trivyã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æƒ…å ±ã‚’purlã‚’ã‚­ãƒ¼ã«ã—ãŸè¾æ›¸ã«æ•´ç† ---\n",
    "            source_package_map = {}\n",
    "            if 'packages' in source_data:\n",
    "                for pkg in source_data['packages']:\n",
    "                    purl = get_purl_from_package(pkg)\n",
    "                    if purl and purl not in source_package_map:\n",
    "                        source_package_map[purl] = pkg\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—3: æ—¢å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®æƒ…å ±ã‚’è£œå®Œ ---\n",
    "            if 'packages' in base_data:\n",
    "                for pkg in base_data['packages']:\n",
    "                    purl = get_purl_from_package(pkg)\n",
    "                    if purl and purl in source_package_map:\n",
    "                        source_pkg = source_package_map[purl]\n",
    "                        \n",
    "                        # primaryPackagePurposeã‚’è£œå®Œ\n",
    "                        if (not pkg.get('primaryPackagePurpose') or pkg.get('primaryPackagePurpose') == 'NOASSERTION') and \\\n",
    "                           source_pkg.get('primaryPackagePurpose') and source_pkg.get('primaryPackagePurpose') != 'NOASSERTION':\n",
    "                            pkg['primaryPackagePurpose'] = source_pkg['primaryPackagePurpose']\n",
    "                            print(f\"   Updated primaryPackagePurpose for: {pkg.get('name')}\")\n",
    "\n",
    "                        # annotationsã‚’è¿½è¨˜\n",
    "                        if 'annotations' not in pkg and source_pkg.get('annotations'):\n",
    "                            pkg['annotations'] = source_pkg['annotations']\n",
    "                            print(f\"   Added annotations for: {pkg.get('name')}\")\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—4: ä¸è¶³ã—ã¦ã„ã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã€Œãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åã€ã§åˆ¤å®šã—ã¦è¿½åŠ  ---\n",
    "            if 'packages' in source_data:\n",
    "                # ãƒ™ãƒ¼ã‚¹SBOMã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åã‚’ã‚»ãƒƒãƒˆã«æ ¼ç´ã—ã€æ¤œç´¢ã‚’é«˜é€ŸåŒ–ã™ã‚‹\n",
    "                base_pkg_names = {pkg.get('name') for pkg in base_data.get('packages', []) if pkg.get('name')}\n",
    "                \n",
    "                for source_pkg in source_data.get('packages', []):\n",
    "                    pkg_name = source_pkg.get('name')\n",
    "                    # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åãŒãƒ™ãƒ¼ã‚¹SBOMã«å­˜åœ¨ã—ãªã„å ´åˆã®ã¿è¿½åŠ ã™ã‚‹\n",
    "                    if pkg_name and pkg_name not in base_pkg_names:\n",
    "                        base_data.setdefault('packages', []).append(source_pkg)\n",
    "                        base_pkg_names.add(pkg_name)\n",
    "                        print(f\"   Added new package from Trivy: {pkg_name}\")\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—5: Trivyã®ãƒ„ãƒ¼ãƒ«æƒ…å ±ã‚’creatorsã«è¿½åŠ  ---\n",
    "            if 'creationInfo' in source_data and 'creators' in source_data['creationInfo']:\n",
    "                base_creators = base_data.setdefault('creationInfo', {}).setdefault('creators', [])\n",
    "                for creator in source_data['creationInfo']['creators']:\n",
    "                    if creator not in base_creators:\n",
    "                        base_creators.append(creator)\n",
    "            \n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—6: å¤‰æ›´ãŒã‚ã£ãŸå ´åˆã®ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ ---\n",
    "            if initial_data_str != json.dumps(base_data, sort_keys=True):\n",
    "                print(f\"   Changes detected. Reordering keys and saving file...\")\n",
    "\n",
    "                # ã‚­ãƒ¼ã®é †åºã‚’å®šç¾©ã—ã€ãã‚Œã«å¾“ã£ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†æ§‹ç¯‰ã™ã‚‹\n",
    "                key_order = [\n",
    "                    \"SPDXID\", \"spdxVersion\", \"creationInfo\", \"name\", \"dataLicense\",\n",
    "                    \"documentNamespace\", \"comment\", \"documentDescribes\", \"externalDocumentRefs\",\n",
    "                    \"packages\", \"files\", \"relationships\"\n",
    "                ]\n",
    "                ordered_data = {key: base_data[key] for key in key_order if key in base_data}\n",
    "                ordered_data.update({key: value for key, value in base_data.items() if key not in ordered_data})\n",
    "\n",
    "                with open(base_sbom_path, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(ordered_data, f, indent=2, ensure_ascii=False)\n",
    "                print(f\"âœ… Successfully supplemented and reordered '{base_sbom_filename}'.\")\n",
    "            else:\n",
    "                print(\"   No new information to supplement from Trivy.\")\n",
    "\n",
    "        except (json.JSONDecodeError, KeyError) as e:\n",
    "            print(f\"âŒ Error processing files for {repo_name}. Details: {e}\")\n",
    "        \n",
    "        finally:\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: The top-level directory '{target_directory}' was not found.\")\n",
    "\n",
    "print(\"All processes finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
