{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f6ae47d",
   "metadata": {},
   "source": [
    "# Step 0: ç’°å¢ƒæ§‹ç¯‰ã¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å…¨ä½“ã®å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã«å¿…è¦ãª,ã™ã¹ã¦ã®Pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—,ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™.\n",
    "\n",
    "### \\#\\# å®Ÿè¡Œå†…å®¹ âš™ï¸\n",
    "\n",
    "1.  **ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä¸€æ‹¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**:\n",
    "\n",
    "      * `!pip install -r requirements.txt` ã‚³ãƒãƒ³ãƒ‰ãŒ,`requirements.txt`ã«è¨˜è¼‰ã•ã‚ŒãŸã™ã¹ã¦ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä¸€åº¦ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™.\n",
    "\n",
    "2.  **ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ**:\n",
    "\n",
    "      * ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãŸãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚„,Pythonã«æ¨™æº–ã§çµ„ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆ`os`, `json`ãªã©ï¼‰ã‚’,ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ãƒ¡ãƒ¢ãƒªã«èª­ã¿è¾¼ã¿,å¾Œç¶šã®ã‚»ãƒ«ã§ä½¿ãˆã‚‹ã‚ˆã†ã«ã—ã¾ã™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30528b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: asttokens==3.0.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: certifi==2025.10.5 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (2025.10.5)\n",
      "Requirement already satisfied: charset-normalizer==3.4.4 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (3.4.4)\n",
      "Requirement already satisfied: comm==0.2.3 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (0.2.3)\n",
      "Requirement already satisfied: debugpy==1.8.17 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 5)) (1.8.17)\n",
      "Requirement already satisfied: decorator==5.2.1 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 6)) (5.2.1)\n",
      "Requirement already satisfied: executing==2.2.1 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 7)) (2.2.1)\n",
      "Requirement already satisfied: idna==3.11 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 8)) (3.11)\n",
      "Requirement already satisfied: ipykernel==7.0.1 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 9)) (7.0.1)\n",
      "Requirement already satisfied: ipython==9.6.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 10)) (9.6.0)\n",
      "Requirement already satisfied: ipython_pygments_lexers==1.1.1 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 11)) (1.1.1)\n",
      "Requirement already satisfied: jedi==0.19.2 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 12)) (0.19.2)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 13)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.9.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 14)) (5.9.0)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 15)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 16)) (1.6.0)\n",
      "Requirement already satisfied: packaging==25.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 17)) (25.0)\n",
      "Requirement already satisfied: parso==0.8.5 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 18)) (0.8.5)\n",
      "Requirement already satisfied: pexpect==4.9.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 19)) (4.9.0)\n",
      "Requirement already satisfied: platformdirs==4.5.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 20)) (4.5.0)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.52 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 21)) (3.0.52)\n",
      "Requirement already satisfied: psutil==7.1.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 22)) (7.1.0)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 23)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 24)) (0.2.3)\n",
      "Requirement already satisfied: Pygments==2.19.2 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 25)) (2.19.2)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 26)) (2.9.0.post0)\n",
      "Requirement already satisfied: pyzmq==27.1.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 27)) (27.1.0)\n",
      "Requirement already satisfied: requests==2.32.5 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 28)) (2.32.5)\n",
      "Requirement already satisfied: six==1.17.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 29)) (1.17.0)\n",
      "Requirement already satisfied: stack-data==0.6.3 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 30)) (0.6.3)\n",
      "Requirement already satisfied: tornado==6.5.2 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 31)) (6.5.2)\n",
      "Requirement already satisfied: traitlets==5.14.3 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 32)) (5.14.3)\n",
      "Requirement already satisfied: urllib3==2.5.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 33)) (2.5.0)\n",
      "Requirement already satisfied: wcwidth==0.2.14 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 34)) (0.2.14)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "179314c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import requests\n",
    "from datetime import datetime, timezone\n",
    "import csv # CSVãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "# --- å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---\n",
    "from utils.sbom_csv_writer import write_summary_to_csv, create_summary_dict, CSV_FIELDNAMES\n",
    "from utils.sbom_json_writer import save_sbom_json\n",
    "from utils.sbom_utils import get_purl_from_package \n",
    "from utils.sbom_package_manager import add_missing_packages_and_relationships, merge_package_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ef483a",
   "metadata": {},
   "source": [
    "# Step 1: ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®æœ€åˆã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦. SBOMã®åˆ†æå¯¾è±¡ã¨ãªã‚‹è¤‡æ•°ã®Gitãƒªãƒã‚¸ãƒˆãƒªã‚’è‡ªå‹•çš„ã«ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã¾ã™.\n",
    "\n",
    "### \\#\\# äº‹å‰æº–å‚™ ğŸ“\n",
    "\n",
    "**`url_list.txt`** ã¨ã„ã†åå‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¨åŒã˜éšå±¤ã«ä½œæˆã—ã¦ãã ã•ã„.\n",
    "ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸­ã«ã¯. ã‚¯ãƒ­ãƒ¼ãƒ³ã—ãŸã„ãƒªãƒã‚¸ãƒˆãƒªã®URLã‚’1è¡Œã«1ã¤ãšã¤è¨˜è¿°ã—ã¾ã™.\n",
    "\n",
    "**`url_list.txt` ã®è¨˜è¿°ä¾‹:**\n",
    "\n",
    "```\n",
    "https://github.com/user1/repo1.git\n",
    "https://github.com/user2/repo2.git\n",
    "https://github.com/user3/another-repo.git\n",
    "```\n",
    "\n",
    "### \\#\\# å®Ÿè¡Œå†…å®¹ âš™ï¸\n",
    "\n",
    "ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯. `url_list.txt` ã‚’èª­ã¿è¾¼ã¿. å„URLã«å¯¾ã—ã¦ `git clone` ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™.\n",
    "\n",
    "  * ã‚¯ãƒ­ãƒ¼ãƒ³ã•ã‚ŒãŸãƒªãƒã‚¸ãƒˆãƒªã¯. **`cloned_repositories`** ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã«ä¿å­˜ã•ã‚Œã¾ã™.\n",
    "  * æ—¢ã«åŒåã®ãƒªãƒã‚¸ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯. æ™‚é–“çŸ­ç¸®ã®ãŸã‚ã‚¯ãƒ­ãƒ¼ãƒ³å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™.\n",
    "  * ã‚¯ãƒ­ãƒ¼ãƒ³ã®é€²æ—çŠ¶æ³ã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¡¨ç¤ºã•ã‚Œã¾ã™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5600567f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting: Cloning repositories ---\n",
      "--------------------------------------------------\n",
      "ğŸŸ¢ Skipping: python-template-project (Directory already exists)\n",
      "--------------------------------------------------\n",
      "Clone process finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "# --- è¨­å®šé …ç›® ---\n",
    "# ã‚¯ãƒ­ãƒ¼ãƒ³å¯¾è±¡ã®ãƒªãƒã‚¸ãƒˆãƒªURLãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«\n",
    "url_file_path = 'url_list.txt'\n",
    "# ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "clone_to_directory = 'cloned_repositories'\n",
    "\n",
    "# --- å‡¦ç†ã®é–‹å§‹ ---\n",
    "print(f\"--- Starting: Cloning repositories ---\")\n",
    "\n",
    "# ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã™ã‚‹\n",
    "os.makedirs(clone_to_directory, exist_ok=True)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# URLãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€\n",
    "try:\n",
    "    with open(url_file_path, 'r') as file:\n",
    "        # ç©ºè¡Œã‚’é™¤å¤–ã—ã¦ãƒªã‚¹ãƒˆåŒ–ã™ã‚‹\n",
    "        urls = [line.strip() for line in file.readlines() if line.strip()]\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: '{url_file_path}' was not found.\")\n",
    "    urls = []\n",
    "\n",
    "for repo_url in urls:\n",
    "    # --- æ—¢å­˜ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¹ã‚­ãƒƒãƒ—å‡¦ç† ---\n",
    "    repo_name = repo_url.split('/')[-1].replace('.git', '')\n",
    "    repo_path = os.path.join(clone_to_directory, repo_name)\n",
    "    \n",
    "    if os.path.isdir(repo_path):\n",
    "        print(f\"ğŸŸ¢ Skipping: {repo_name} (Directory already exists)\")\n",
    "        print(\"-\" * 50)\n",
    "        continue\n",
    "\n",
    "    print(f\"Cloning: {repo_url}\")\n",
    "    try:\n",
    "        # git cloneãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹\n",
    "        process = subprocess.Popen(\n",
    "            ['git', 'clone', '--progress', repo_url],\n",
    "            cwd=clone_to_directory,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "            encoding='utf-8',\n",
    "            errors='replace'\n",
    "        )\n",
    "\n",
    "        # æ¨™æº–ã‚¨ãƒ©ãƒ¼ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¡¨ç¤º\n",
    "        while process.poll() is None:\n",
    "            line = process.stderr.readline()\n",
    "            if line:\n",
    "                print(f\"   {line.strip()}\", end='\\r')\n",
    "        \n",
    "        print(\" \" * 80, end=\"\\r\") # é€²æ—è¡¨ç¤ºè¡Œã‚’ã‚¯ãƒªã‚¢\n",
    "\n",
    "        if process.returncode == 0:\n",
    "            print(\"âœ… Clone successful.\")\n",
    "\n",
    "            print(f\"   Searching and removing hidden directories in '{repo_name}'...\")\n",
    "            \n",
    "            # ã‚¯ãƒ­ãƒ¼ãƒ³ã—ãŸãƒªãƒã‚¸ãƒˆãƒªå†…ã‚’å†å¸°çš„ã«æ¢ç´¢\n",
    "            for root, dirs, files in os.walk(repo_path):\n",
    "                # .ã§å§‹ã¾ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã¦å‰Šé™¤\n",
    "                hidden_dirs = [d for d in dirs if d.startswith('.')]\n",
    "                for d_name in hidden_dirs:\n",
    "                    dir_to_remove = os.path.join(root, d_name)\n",
    "                    try:\n",
    "                        shutil.rmtree(dir_to_remove)\n",
    "                        print(f\"   ğŸ—‘ï¸ Removed: {dir_to_remove}\")\n",
    "                    except OSError as e:\n",
    "                        print(f\"   âŒ Error removing {dir_to_remove}: {e}\")\n",
    "                \n",
    "                # dirsãƒªã‚¹ãƒˆã‹ã‚‰å‰Šé™¤ã—ãŸã‚‚ã®ã‚’é™¤å¤–ã—ã€ãã‚Œä»¥ä¸Šæ·±ãæ¢ç´¢ã—ãªã„ã‚ˆã†ã«ã™ã‚‹\n",
    "                dirs[:] = [d for d in dirs if not d.startswith('.')]\n",
    "            \n",
    "            print(\"   âœ… Hidden directories removed.\")\n",
    "\n",
    "        else:\n",
    "            # ã‚¨ãƒ©ãƒ¼å†…å®¹ã‚’å–å¾—ã—ã¦è¡¨ç¤º\n",
    "            stdout_err, stderr_err = process.communicate()\n",
    "            error_message = stderr_err if stderr_err else stdout_err\n",
    "            print(f\"âŒ Error cloning. Reason: {error_message.strip()}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ Error: 'git' command not found. Please install Git and ensure it is in your system's PATH.\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "print(\"Clone process finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bc9665",
   "metadata": {},
   "source": [
    "# Step 2: SBOMã®ç”Ÿæˆ (sbom-tool)\n",
    "\n",
    "å‰ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã‚¯ãƒ­ãƒ¼ãƒ³ã—ãŸå„ãƒªãƒã‚¸ãƒˆãƒªã«å¯¾ã—ã¦,Microsoftã® **`sbom-tool`** ã‚’ä½¿ç”¨ã—ã¦ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹SBOMã‚’ç”Ÿæˆã—ã¾ã™.ã“ã®ãƒ„ãƒ¼ãƒ«ã¯,ãƒªãƒã‚¸ãƒˆãƒªå†…ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—,ãƒãƒƒã‚·ãƒ¥å€¤ã‚’å«ã‚€è©³ç´°ãªãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã“ã¨ã«å„ªã‚Œã¦ã„ã¾ã™.\n",
    "\n",
    "### ## äº‹å‰æº–å‚™ ğŸ“\n",
    "\n",
    "* **`sbom-tool`** ãŒã‚·ã‚¹ãƒ†ãƒ ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œ,PATHãŒé€šã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™.\n",
    "* Step 1ãŒå®Œäº†ã—ã¦ãŠã‚Š,**`cloned_repositories`** ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã«åˆ†æå¯¾è±¡ã®ãƒªãƒã‚¸ãƒˆãƒªãŒå­˜åœ¨ã—ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™.\n",
    "\n",
    "### ## å®Ÿè¡Œå†…å®¹ âš™ï¸\n",
    "\n",
    "ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯,`cloned_repositories`å†…ã®å„ãƒªãƒã‚¸ãƒˆãƒªã‚’å·¡å›ã—,ä»¥ä¸‹ã®å‡¦ç†ã‚’è‡ªå‹•çš„ã«å®Ÿè¡Œã—ã¾ã™.\n",
    "\n",
    "1.  **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è‡ªå‹•å–å¾—**:\n",
    "    * `git`ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—,ç¾åœ¨ã®ã‚³ãƒŸãƒƒãƒˆãƒãƒƒã‚·ãƒ¥ã‚’ **`packageVersion`** ã¨ã—ã¦å–å¾—ã—ã¾ã™.\n",
    "    * `.git/config`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—,ãƒªãƒã‚¸ãƒˆãƒªã®æ‰€æœ‰è€…ï¼ˆOrganizationã¾ãŸã¯Userï¼‰ã‚’ **`packageSupplier`** ã¨ã—ã¦è‡ªå‹•ã§è¨­å®šã—ã¾ã™.\n",
    "\n",
    "2.  **`sbom-tool` ã®å®Ÿè¡Œ**:\n",
    "    * å–å¾—ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸å,ãƒãƒ¼ã‚¸ãƒ§ãƒ³,ã‚µãƒ—ãƒ©ã‚¤ãƒ¤ãƒ¼ï¼‰ã‚’ä½¿ã£ã¦`sbom-tool generate`ã‚³ãƒãƒ³ãƒ‰ã‚’å‹•çš„ã«æ§‹ç¯‰ã—,å®Ÿè¡Œã—ã¾ã™.\n",
    "    * ã“ã‚Œã«ã‚ˆã‚Š,å„ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ«ãƒ¼ãƒˆã« **`_manifest`** ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒç”Ÿæˆã•ã‚Œã¾ã™.\n",
    "\n",
    "3.  **æˆæœç‰©ã®ç§»å‹•**:\n",
    "    * ç”Ÿæˆã•ã‚ŒãŸ`_manifest`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’,å¾Œç¶šã®å‡¦ç†ã§æ‰±ã„ã‚„ã™ã„ã‚ˆã†ã« **`generated_sboms/<ãƒªãƒã‚¸ãƒˆãƒªå>/source/`** ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã«ç§»å‹•ã—ã¾ã™.\n",
    "\n",
    "ã™ã§ã«æˆæœç‰©ãŒå­˜åœ¨ã™ã‚‹å ´åˆ,ã“ã®å‡¦ç†ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eeaebc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting: Generating SBOMs with sbom-tool\n",
      "--------------------------------------------------\n",
      "ğŸŸ¢ Skipping: python-template-project (SBOM manifest already exists)\n",
      "--------------------------------------------------\n",
      "All processes finished.\n"
     ]
    }
   ],
   "source": [
    "# --- è¨­å®šé …ç›® ---\n",
    "clone_to_directory = 'cloned_repositories'\n",
    "sbom_output_directory = 'generated_sboms'\n",
    "url_file_path = 'url_list.txt'\n",
    "\n",
    "# --- å‡¦ç†ã®é–‹å§‹ ---\n",
    "print(f\"--- Starting: Generating SBOMs with sbom-tool\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "original_path = os.getcwd()\n",
    "os.makedirs(sbom_output_directory, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # --- url_list.txtã‹ã‚‰ãƒªãƒã‚¸ãƒˆãƒªåã¨æä¾›è€…ã®ãƒãƒƒãƒ—ã‚’ä½œæˆ ---\n",
    "    repo_to_supplier_map = {}\n",
    "    try:\n",
    "        with open(url_file_path, 'r') as file:\n",
    "            urls = [line.strip() for line in file.readlines() if line.strip()]\n",
    "            for url in urls:\n",
    "                # URLã‹ã‚‰æ‰€æœ‰è€…ã¨ãƒªãƒã‚¸ãƒˆãƒªåã‚’æŠ½å‡º\n",
    "                match = re.search(r\"github\\.com/([^/]+)/([^/.]+)\", url)\n",
    "                if match:\n",
    "                    owner, repo = match.groups()\n",
    "                    repo_name_from_url = repo.replace('.git', '')\n",
    "                    repo_to_supplier_map[repo_name_from_url] = owner\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âš ï¸ Warning: '{url_file_path}' not found. 'PackageSupplier' will default to 'Unknown'.\")\n",
    "\n",
    "    # --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---\n",
    "    repo_dirs = [d for d in os.listdir(clone_to_directory) if os.path.isdir(os.path.join(clone_to_directory, d))]\n",
    "    \n",
    "    if not repo_dirs:\n",
    "        print(\"No repositories found to run commands on.\")\n",
    "\n",
    "    for repo_name in repo_dirs:\n",
    "        final_repo_dir = os.path.join(original_path, sbom_output_directory, repo_name)\n",
    "        final_manifest_path = os.path.join(final_repo_dir, 'source', '_manifest')\n",
    "\n",
    "        if os.path.isdir(final_manifest_path):\n",
    "            print(f\"ğŸŸ¢ Skipping: {repo_name} (SBOM manifest already exists)\")\n",
    "            print(\"-\" * 50)\n",
    "            continue\n",
    "\n",
    "        repo_path = os.path.join(clone_to_directory, repo_name)\n",
    "        print(f\"â–¶ï¸  Entering: {repo_name}\")\n",
    "        \n",
    "        try:\n",
    "            # --- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š ---\n",
    "            package_name = repo_name\n",
    "            # ãƒãƒƒãƒ—ã‹ã‚‰ã‚µãƒ—ãƒ©ã‚¤ãƒ¤ãƒ¼æƒ…å ±ã‚’å–å¾—\n",
    "            package_supplier = repo_to_supplier_map.get(repo_name, \"Unknown\")\n",
    "            \n",
    "            print(f\"   Package Name: {package_name}\")\n",
    "            print(f\"   Package Supplier: {package_supplier}\")\n",
    "            \n",
    "            manifest_in_repo_path = os.path.join(repo_path, '_manifest')\n",
    "            if os.path.isdir(manifest_in_repo_path):\n",
    "                print(\"   Found existing '_manifest' directory. Removing it.\")\n",
    "                shutil.rmtree(manifest_in_repo_path)\n",
    "\n",
    "            # --- sbom-toolå®Ÿè¡Œ---\n",
    "            command = [\n",
    "                'sbom-tool', 'generate', \n",
    "                '-bc', repo_path,\n",
    "                '-b', repo_path,\n",
    "                '-pn', package_name, \n",
    "                '-ps', package_supplier,\n",
    "                '-m', repo_path,\n",
    "                '-pv', 'latest'\n",
    "            ]\n",
    "            print(f\"   Executing: {' '.join(command)}\")\n",
    "            subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "            print(\"âœ… SBOM generation successful.\")\n",
    "\n",
    "            # --- ç§»å‹•å‡¦ç† ---\n",
    "            source_manifest_path = manifest_in_repo_path\n",
    "            \n",
    "            if os.path.isdir(source_manifest_path):\n",
    "                destination_dir = os.path.join(final_repo_dir, 'source')\n",
    "                os.makedirs(destination_dir, exist_ok=True)\n",
    "                \n",
    "                print(f\"   Moving '{source_manifest_path}' into: {destination_dir}\")\n",
    "                shutil.move(source_manifest_path, final_manifest_path)\n",
    "                print(\"âœ… Move successful.\")\n",
    "            else:\n",
    "                print(f\"âš ï¸ Warning: Could not find generated manifest directory at '{source_manifest_path}'\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"âŒ Error: The command 'sbom-tool' was not found.\")\n",
    "            break\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"âŒ Error executing command in {repo_name}.\")\n",
    "            if e.stderr:\n",
    "                print(f\"   [stderr]:\\n{e.stderr.strip()}\")\n",
    "        finally:\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: The directory '{clone_to_directory}' was not found.\")\n",
    "\n",
    "print(\"All processes finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5f0d61",
   "metadata": {},
   "source": [
    "# Step 3: SBOMã®ç”Ÿæˆ (Syft)\n",
    "\n",
    "`Step 1`ã§ã‚¯ãƒ­ãƒ¼ãƒ³ã—ãŸå„ãƒªãƒã‚¸ãƒˆãƒªã«å¯¾ã—,**`syft`** ã‚’ä½¿ç”¨ã—ã¦SBOMã‚’ç”Ÿæˆã—ã¾ã™.`syft`ã¯,`requirements.txt`ã‚„GitHub Actionsã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãªã©,æ§˜ã€…ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‹ã‚‰ä¾å­˜é–¢ä¿‚ã‚’æ¤œå‡ºã™ã‚‹ã“ã¨ã«å„ªã‚Œã¦ã„ã¾ã™.\n",
    "\n",
    "### ## äº‹å‰æº–å‚™ ğŸ“\n",
    "\n",
    "* **`syft`** ãŒã‚·ã‚¹ãƒ†ãƒ ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œ,PATHãŒé€šã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™.\n",
    "* Step 1ãŒå®Œäº†ã—ã¦ãŠã‚Š,**`cloned_repositories`** ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã«åˆ†æå¯¾è±¡ã®ãƒªãƒã‚¸ãƒˆãƒªãŒå­˜åœ¨ã—ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™.\n",
    "\n",
    "### ## å®Ÿè¡Œå†…å®¹ âš™ï¸\n",
    "\n",
    "ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯,`cloned_repositories`å†…ã®å„ãƒªãƒã‚¸ãƒˆãƒªã‚’å·¡å›ã—,ä»¥ä¸‹ã®å‡¦ç†ã‚’è‡ªå‹•çš„ã«å®Ÿè¡Œã—ã¾ã™.\n",
    "\n",
    "1.  **`syft` ã®å®Ÿè¡Œ**:\n",
    "    * å„ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•ã—,`syft dir:./ -o spdx-json`ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™.\n",
    "    * ã‚³ãƒãƒ³ãƒ‰ã®æ¨™æº–å‡ºåŠ›ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã—,ãƒªãƒã‚¸ãƒˆãƒªå†…ã«`syft-sbom.json`ã¨ã„ã†åå‰ã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã—ã¾ã™.\n",
    "\n",
    "2.  **æˆæœç‰©ã®ç§»å‹•**:\n",
    "    * ç”Ÿæˆã•ã‚ŒãŸ`syft-sbom.json`ã‚’,å¾Œç¶šã®å‡¦ç†ã§æ‰±ã„ã‚„ã™ã„ã‚ˆã†ã« **`generated_sboms/<ãƒªãƒã‚¸ãƒˆãƒªå>/source/`** ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã«ç§»å‹•ã—ã¾ã™.\n",
    "\n",
    "ã™ã§ã«`syft-sbom.json`ãŒæœ€çµ‚çš„ãªä¿å­˜å…ˆã«å­˜åœ¨ã™ã‚‹å ´åˆ,ãã®ãƒªãƒã‚¸ãƒˆãƒªã®å‡¦ç†ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff455b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting: Generating SBOMs with Syft ---\n",
      "--------------------------------------------------\n",
      "ğŸŸ¢ Skipping: python-template-project (SBOM file already exists)\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "All processes finished.\n"
     ]
    }
   ],
   "source": [
    "# --- è¨­å®šé …ç›® ---\n",
    "clone_to_directory = 'cloned_repositories'\n",
    "sbom_output_directory = 'generated_sboms'\n",
    "\n",
    "# --- å‡¦ç†ã®é–‹å§‹ ---\n",
    "print(f\"--- Starting: Generating SBOMs with Syft ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# å®Ÿè¡Œå‰ã®ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä¿å­˜ã™ã‚‹\n",
    "original_path = os.getcwd()\n",
    "os.makedirs(sbom_output_directory, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # ã‚¯ãƒ­ãƒ¼ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒªãƒã‚¸ãƒˆãƒªä¸€è¦§ã‚’å–å¾—ã™ã‚‹\n",
    "    repo_dirs = [d for d in os.listdir(clone_to_directory) if os.path.isdir(os.path.join(clone_to_directory, d))]\n",
    "    \n",
    "    if not repo_dirs:\n",
    "        print(\"No repositories found to run commands on.\")\n",
    "\n",
    "    for repo_name in repo_dirs:\n",
    "        repo_path = os.path.join(clone_to_directory, repo_name)\n",
    "        \n",
    "        try:\n",
    "            # --- æœ€çµ‚çš„ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å®šç¾© ---\n",
    "            destination_dir = os.path.join(original_path, sbom_output_directory, repo_name, 'source')\n",
    "            final_sbom_filename = \"syft-sbom.json\"\n",
    "            final_sbom_path = os.path.join(destination_dir, final_sbom_filename)\n",
    "\n",
    "            # --- å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã‹ã®åˆ¤å®š ---\n",
    "            # æ—¢ã«æˆæœç‰©ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹\n",
    "            if os.path.exists(final_sbom_path):\n",
    "                print(f\"ğŸŸ¢ Skipping: {repo_name} (SBOM file already exists)\")\n",
    "                print(\"-\" * 50)\n",
    "                continue\n",
    "\n",
    "            print(f\"â–¶ï¸  Entering: {repo_name}\")\n",
    "            os.chdir(repo_path)\n",
    "            \n",
    "            # --- syftã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè¡Œ ---\n",
    "            temp_sbom_filename = 'syft-sbom.json'\n",
    "            # ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—,SPDX JSONå½¢å¼ã§å‡ºåŠ›ã™ã‚‹\n",
    "            command = ['syft', 'dir:./', '-o', 'spdx-json']\n",
    "            print(f\"   Executing: {' '.join(command)} > {temp_sbom_filename}\")\n",
    "            \n",
    "            result = subprocess.run(\n",
    "                command, check=True, capture_output=True, text=True\n",
    "            )\n",
    "            print(\"âœ… Syft execution successful.\")\n",
    "\n",
    "            # syftã®æ¨™æº–å‡ºåŠ›ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€\n",
    "            with open(temp_sbom_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(result.stdout)\n",
    "\n",
    "            # --- ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æœ€çµ‚çš„ãªå ´æ‰€ã«ç§»å‹• ---\n",
    "            os.makedirs(destination_dir, exist_ok=True)\n",
    "            print(f\"   Moving SBOM to: {final_sbom_path}\")\n",
    "            shutil.move(temp_sbom_filename, final_sbom_path)\n",
    "            print(\"âœ… SBOM file saved.\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"âŒ Error: The command 'syft' or was not found.\")\n",
    "            break\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"âŒ Error executing command in {repo_name}.\")\n",
    "            if e.stdout:\n",
    "                print(f\"   [stdout]:\\n{e.stdout.strip()}\")\n",
    "            if e.stderr:\n",
    "                print(f\"   [stderr]:\\n{e.stderr.strip()}\")\n",
    "        finally:\n",
    "            # ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å…ƒã«æˆ»ã™\n",
    "            os.chdir(original_path)\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: The directory '{clone_to_directory}' was not found.\")\n",
    "\n",
    "print(\"All processes finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6036a3",
   "metadata": {},
   "source": [
    "# Step 4: SBOMã®å–å¾— (GitHub Dependency Graph API)\n",
    "\n",
    "ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯,GitHubã® **Dependency Graph API** ã‚’åˆ©ç”¨ã—ã¦,å„ãƒªãƒã‚¸ãƒˆãƒªã®SBOMï¼ˆSoftware Bill of Materialsï¼‰ã‚’å–å¾—ã—ã¾ã™.ã“ã®APIã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹SBOMã¯,ç‰¹ã«**ãƒ©ã‚¤ã‚»ãƒ³ã‚¹**ã‚„**è‘—ä½œæ¨©æƒ…å ±**ãŒè±Šå¯Œã«å«ã¾ã‚Œã¦ã„ã‚‹ã¨ã„ã†é•·æ‰€ãŒã‚ã‚Šã¾ã™.\n",
    "\n",
    "### ## äº‹å‰æº–å‚™ ğŸ“\n",
    "\n",
    "* **Dependency Graphã®æœ‰åŠ¹åŒ–**: åˆ†æå¯¾è±¡ã®ãƒªãƒã‚¸ãƒˆãƒªã§,**Dependency Graph**æ©Ÿèƒ½ãŒæœ‰åŠ¹ã«ãªã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™.ã“ã‚Œã¯é€šå¸¸,ãƒ‘ãƒ–ãƒªãƒƒã‚¯ãƒªãƒã‚¸ãƒˆãƒªã§ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ‰åŠ¹ã§ã™ãŒ,ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒªãƒã‚¸ãƒˆãƒªã§ã¯æ‰‹å‹•ã§ã®æœ‰åŠ¹åŒ–ãŒå¿…è¦ã§ã™.ï¼ˆ`Settings` > `Code security and analysis`ï¼‰\n",
    "* **`url_list.txt`**: Step 1ã§ä½œæˆã—ãŸ,ãƒªãƒã‚¸ãƒˆãƒªã®URLãŒè¨˜è¼‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã§ã™.\n",
    "\n",
    "### ## å®Ÿè¡Œå†…å®¹ âš™ï¸\n",
    "\n",
    "ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯,`url_list.txt`ã‚’èª­ã¿è¾¼ã¿,å„ãƒªãƒã‚¸ãƒˆãƒªã«å¯¾ã—ã¦ä»¥ä¸‹ã®å‡¦ç†ã‚’è‡ªå‹•çš„ã«å®Ÿè¡Œã—ã¾ã™.\n",
    "\n",
    "1.  **APIãƒªã‚¯ã‚¨ã‚¹ãƒˆ**:\n",
    "    * URLã‹ã‚‰ãƒªãƒã‚¸ãƒˆãƒªã®æ‰€æœ‰è€…ã¨åå‰ã‚’æŠ½å‡ºã—,é©åˆ‡ãªAPIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆ`api.github.com/repos/{owner}/{repo}/dependency-graph/sbom`ï¼‰ã‚’æ§‹ç¯‰ã—ã¾ã™.\n",
    "    * æ§‹ç¯‰ã—ãŸURLã«å¯¾ã—ã¦`GET`ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ã—,SBOMãƒ‡ãƒ¼ã‚¿ã‚’JSONå½¢å¼ã§å–å¾—ã—ã¾ã™.\n",
    "\n",
    "2.  **æˆæœç‰©ã®ä¿å­˜**:\n",
    "    * APIã‹ã‚‰æ­£å¸¸ã«å–å¾—ã§ããŸSBOMãƒ‡ãƒ¼ã‚¿ã‚’,**`generated_sboms/<ãƒªãƒã‚¸ãƒˆãƒªå>/source/dependency-graph-sbom.json`** ã¨ã„ã†åå‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã—ã¾ã™.\n",
    "\n",
    "æ—¢ã«æˆæœç‰©ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆ,APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ç¯€ç´„ã™ã‚‹ãŸã‚,ãã®ãƒªãƒã‚¸ãƒˆãƒªã®å‡¦ç†ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6600f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting: Fetching SBOMs from GitHub API ---\n",
      "--------------------------------------------------\n",
      "ğŸŸ¢ Skipping: python-template-project (SBOM file already exists)\n",
      "--------------------------------------------------\n",
      "All processes finished.\n"
     ]
    }
   ],
   "source": [
    "# --- è¨­å®šé …ç›® ---\n",
    "\n",
    "# 1. GitHubãƒªãƒã‚¸ãƒˆãƒªã®URLãƒªã‚¹ãƒˆãŒæ›¸ã‹ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«\n",
    "url_file_path = 'url_list.txt'\n",
    "\n",
    "# 2. ç”Ÿæˆã•ã‚ŒãŸSBOM(JSONãƒ•ã‚¡ã‚¤ãƒ«)ã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "sbom_output_directory = 'generated_sboms'\n",
    "\n",
    "\n",
    "# --- å‡¦ç†ã®é–‹å§‹ ---\n",
    "print(\"--- Starting: Fetching SBOMs from GitHub API ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "original_path = os.getcwd()\n",
    "os.makedirs(sbom_output_directory, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    with open(url_file_path, 'r') as file:\n",
    "        urls = [line.strip() for line in file.readlines() if line.strip()]\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: '{url_file_path}' was not found.\")\n",
    "    urls = []\n",
    "\n",
    "for repo_url in urls:\n",
    "    # URLã‹ã‚‰ownerã¨repoã‚’æŠ½å‡º\n",
    "    match = re.search(r\"github\\.com/([^/]+)/([^/.]+)\", repo_url)\n",
    "    if not match:\n",
    "        print(f\"âš ï¸ Warning: Could not parse owner/repo from URL: {repo_url}\")\n",
    "        continue\n",
    "    \n",
    "    owner, repo_name = match.groups()\n",
    "    \n",
    "    # --- ä¿å­˜å…ˆã®ãƒ‘ã‚¹ã‚’å®šç¾©ã—,ã‚¹ã‚­ãƒƒãƒ—åˆ¤å®š ---\n",
    "    destination_dir = os.path.join(original_path, sbom_output_directory, repo_name, 'source')\n",
    "    final_sbom_path = os.path.join(destination_dir, 'dependency-graph-sbom.json')\n",
    "\n",
    "    if os.path.exists(final_sbom_path):\n",
    "        print(f\"ğŸŸ¢ Skipping: {repo_name} (SBOM file already exists)\")\n",
    "        print(\"-\" * 50)\n",
    "        continue\n",
    "        \n",
    "    print(f\"â–¶ï¸  Fetching SBOM for: {owner}/{repo_name}\")\n",
    "\n",
    "    # --- GitHub APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ (èªè¨¼ãƒ˜ãƒƒãƒ€ãƒ¼ãªã—) ---\n",
    "    api_url = f\"https://api.github.com/repos/{owner}/{repo_name}/dependency-graph/sbom\"\n",
    "    headers = {\n",
    "        \"Accept\": \"application/vnd.github+json\",\n",
    "        \"X-GitHub-Api-Version\": \"2022-11-28\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(api_url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            print(\"âœ… API request successful.\")\n",
    "            sbom_data = response.json().get('sbom')\n",
    "            if not sbom_data:\n",
    "                print(f\"âŒ Error: 'sbom' key not found in the API response for {repo_name}.\")\n",
    "                continue\n",
    "\n",
    "            # --- SBOMã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ ---\n",
    "            os.makedirs(destination_dir, exist_ok=True)\n",
    "            print(f\"   Writing SBOM to: {final_sbom_path}\")\n",
    "            \n",
    "            with open(final_sbom_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(sbom_data, f, ensure_ascii=False, indent=2)\n",
    "            print(\"âœ… SBOM file saved.\")\n",
    "\n",
    "        elif response.status_code == 404:\n",
    "            print(f\"âš ï¸ Warning: Could not fetch SBOM for {repo_name}. (Status: 404)\")\n",
    "            print(\"   The repository may not exist, or the Dependency Graph may not be enabled.\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"âŒ Error: Failed to fetch SBOM for {repo_name}. Status code: {response.status_code}\")\n",
    "            print(f\"   Response: {response.text}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"âŒ Error: A network error occurred while contacting the GitHub API.\")\n",
    "        print(f\"   Details: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "print(\"All processes finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b95ab33",
   "metadata": {},
   "source": [
    "# Step 5: SBOMã®ç”Ÿæˆ (Trivy)\n",
    "\n",
    "ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯,ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®è„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒŠã§ã‚ã‚‹ **`Trivy`** ã‚’ä½¿ç”¨ã—ã¦,å„ãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰SBOMã‚’ç”Ÿæˆã—ã¾ã™.`Trivy`ã¯,ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ å†…ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä¾å­˜é–¢ä¿‚ã‚’é«˜é€Ÿã‹ã¤åºƒç¯„å›²ã«æ¤œå‡ºã™ã‚‹èƒ½åŠ›ã«å„ªã‚Œã¦ã„ã¾ã™.\n",
    "\n",
    "### ## äº‹å‰æº–å‚™ ğŸ“\n",
    "\n",
    "* **`Trivy`** ãŒã‚·ã‚¹ãƒ†ãƒ ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œ,PATHãŒé€šã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™.\n",
    "* Step 1ãŒå®Œäº†ã—ã¦ãŠã‚Š,**`cloned_repositories`** ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã«åˆ†æå¯¾è±¡ã®ãƒªãƒã‚¸ãƒˆãƒªãŒå­˜åœ¨ã—ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™.\n",
    "\n",
    "### ## å®Ÿè¡Œå†…å®¹ âš™ï¸\n",
    "\n",
    "ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯,`cloned_repositories`å†…ã®å„ãƒªãƒã‚¸ãƒˆãƒªã‚’å·¡å›ã—,ä»¥ä¸‹ã®å‡¦ç†ã‚’è‡ªå‹•çš„ã«å®Ÿè¡Œã—ã¾ã™.\n",
    "\n",
    "1.  **`Trivy` ã®å®Ÿè¡Œ**:\n",
    "    * å„ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•ã—,`trivy fs . --format spdx-json --output spdx-json-by-trivy.json` ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™.\n",
    "    * ã“ã‚Œã«ã‚ˆã‚Š,ãƒªãƒã‚¸ãƒˆãƒªå†…ã«`spdx-json-by-trivy.json`ã¨ã„ã†åå‰ã§SBOMãƒ•ã‚¡ã‚¤ãƒ«ãŒç›´æ¥ç”Ÿæˆã•ã‚Œã¾ã™.\n",
    "\n",
    "2.  **æˆæœç‰©ã®ç§»å‹•ã¨ãƒªãƒãƒ¼ãƒ **:\n",
    "    * ç”Ÿæˆã•ã‚ŒãŸ`spdx-json-by-trivy.json`ã‚’,å¾Œç¶šã®å‡¦ç†ã§çµ±ä¸€çš„ã«æ‰±ãˆã‚‹ã‚ˆã†ã« **`generated_sboms/<ãƒªãƒã‚¸ãƒˆãƒªå>/source/trivy-sbom.json`** ã¨ã„ã†åå‰ã«å¤‰æ›´ã—ã¦ç§»å‹•ã—ã¾ã™.\n",
    "\n",
    "ã™ã§ã«`trivy-sbom.json`ãŒæœ€çµ‚çš„ãªä¿å­˜å…ˆã«å­˜åœ¨ã™ã‚‹å ´åˆ,ãã®ãƒªãƒã‚¸ãƒˆãƒªã®å‡¦ç†ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77d4a25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting: Generating SBOMs with Trivy ---\n",
      "--------------------------------------------------\n",
      "ğŸŸ¢ Skipping: python-template-project (SBOM file already exists)\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "All processes finished.\n"
     ]
    }
   ],
   "source": [
    "# --- è¨­å®šé …ç›® ---\n",
    "\n",
    "# ã‚¯ãƒ­ãƒ¼ãƒ³ã•ã‚ŒãŸãƒªãƒã‚¸ãƒˆãƒªã®ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "clone_to_directory = 'cloned_repositories'\n",
    "# ç”Ÿæˆã•ã‚ŒãŸSBOMã®ä¿å­˜ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "sbom_output_directory = 'generated_sboms'\n",
    "\n",
    "# --- å‡¦ç†ã®é–‹å§‹ ---\n",
    "# Trivyã‚’ä½¿ã£ãŸSBOMç”Ÿæˆå‡¦ç†é–‹å§‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º\n",
    "print(f\"--- Starting: Generating SBOMs with Trivy ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# ç¾åœ¨ã®ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä¿å­˜\n",
    "original_path = os.getcwd()\n",
    "# SBOMå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ\n",
    "os.makedirs(sbom_output_directory, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # ã‚¯ãƒ­ãƒ¼ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒªãƒã‚¸ãƒˆãƒªä¸€è¦§ã‚’å–å¾—\n",
    "    repo_dirs = [d for d in os.listdir(clone_to_directory) if os.path.isdir(os.path.join(clone_to_directory, d))]\n",
    "    \n",
    "    if not repo_dirs:\n",
    "        print(\"No repositories found to run commands on.\")\n",
    "\n",
    "    # å„ãƒªãƒã‚¸ãƒˆãƒªã«å¯¾ã—ã¦Trivyã‚’ä½¿ã£ãŸSBOMç”Ÿæˆå‡¦ç†ã‚’å®Ÿè¡Œ\n",
    "    for repo_name in repo_dirs:\n",
    "        repo_path = os.path.join(clone_to_directory, repo_name)\n",
    "        \n",
    "        try:\n",
    "            # --- æœ€çµ‚çš„ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å®šç¾© ---\n",
    "            # SBOMã®æœ€çµ‚çš„ãªä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ§‹ç¯‰\n",
    "            destination_dir = os.path.join(original_path, sbom_output_directory, repo_name, 'source')\n",
    "            \n",
    "            # ç”Ÿæˆã•ã‚Œã‚‹SBOMã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ 'trivy-sbom.json' ã«å›ºå®š\n",
    "            final_sbom_filename = \"trivy-sbom.json\"\n",
    "            \n",
    "            # æœ€çµ‚çš„ãªSBOMãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ãƒ«ãƒ‘ã‚¹ã‚’æ§‹ç¯‰\n",
    "            final_sbom_path = os.path.join(destination_dir, final_sbom_filename)\n",
    "\n",
    "            # --- å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã‹ã®åˆ¤å®š ---\n",
    "            # æ—¢ã«SBOMãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—\n",
    "            if os.path.exists(final_sbom_path):\n",
    "                print(f\"ğŸŸ¢ Skipping: {repo_name} (SBOM file already exists)\")\n",
    "                print(\"-\" * 50)\n",
    "                continue\n",
    "\n",
    "            # --- ã“ã“ã‹ã‚‰ãƒªãƒã‚¸ãƒˆãƒªå†…ã§ã®å‡¦ç† ---\n",
    "            print(f\"â–¶ï¸  Entering: {repo_name}\")\n",
    "            # ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ‘ã‚¹ã«å¤‰æ›´\n",
    "            os.chdir(repo_path)\n",
    "            \n",
    "            # --- trivyã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè¡Œ ---\n",
    "            # trivyãŒå‡ºåŠ›ã™ã‚‹ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å®šç¾©\n",
    "            temp_sbom_filename = 'spdx-json-by-trivy.json'\n",
    "            # trivyã‚³ãƒãƒ³ãƒ‰ã‚’æ§‹ç¯‰\n",
    "            command = ['trivy', 'fs', '.', '--format', 'spdx-json', '--output', temp_sbom_filename]\n",
    "            print(f\"   Executing: {' '.join(command)}\")\n",
    "            \n",
    "            # trivyã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ\n",
    "            # Trivyã¯ãƒ•ã‚¡ã‚¤ãƒ«ã«ç›´æ¥å‡ºåŠ›ã™ã‚‹ãŸã‚,å‡ºåŠ›ã®ã‚­ãƒ£ãƒ—ãƒãƒ£ã¯ä¸è¦\n",
    "            subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "            print(\"âœ… Trivy execution successful.\")\n",
    "\n",
    "            # --- ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æœ€çµ‚çš„ãªå ´æ‰€ã«ç§»å‹• ---\n",
    "            # æœ€çµ‚çš„ãªä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ\n",
    "            os.makedirs(destination_dir, exist_ok=True)\n",
    "            print(f\"   Moving SBOM to: {final_sbom_path}\")\n",
    "            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æœ€çµ‚çš„ãªä¿å­˜å…ˆã«ãƒªãƒãƒ¼ãƒ ã—ãªãŒã‚‰ç§»å‹•\n",
    "            shutil.move(temp_sbom_filename, final_sbom_path)\n",
    "            print(\"âœ… SBOM file saved.\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            # 'trivy'ã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼å‡¦ç†\n",
    "            print(f\"âŒ Error: The command 'trivy' was not found.\")\n",
    "            break\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            # ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã®å‡¦ç†\n",
    "            print(f\"âŒ Error executing command in {repo_name}.\")\n",
    "            if e.stdout:\n",
    "                print(f\"   [stdout]:\\n{e.stdout.strip()}\")\n",
    "            if e.stderr:\n",
    "                print(f\"   [stderr]:\\n{e.stderr.strip()}\")\n",
    "        finally:\n",
    "            # ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å…ƒã®ãƒ‘ã‚¹ã«æˆ»ã™\n",
    "            os.chdir(original_path)\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    # ã‚¯ãƒ­ãƒ¼ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼å‡¦ç†\n",
    "    print(f\"âŒ Error: The directory '{clone_to_directory}' was not found.\")\n",
    "\n",
    "# å…¨ã¦ã®Trivyã‚’ä½¿ã£ãŸSBOMç”Ÿæˆå‡¦ç†ãŒå®Œäº†\n",
    "print(\"All processes finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1539950b",
   "metadata": {},
   "source": [
    "# Step 6: ãƒ™ãƒ¼ã‚¹SBOMã®ä½œæˆã¨æ•´å½¢\n",
    "\n",
    "ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯,`Step 2`ã§`sbom-tool`ãŒå‡ºåŠ›ã—ãŸ`manifest.spdx.json`ã‚’ã‚³ãƒ”ãƒ¼ã—,å¾Œç¶šã®å‡¦ç†ã®åŸºç¤ã¨ãªã‚‹ **`combined_sbom.json`** ã‚’ä½œæˆã—ã¾ã™.åŒæ™‚ã«,JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã®ã‚­ãƒ¼ã®é †åºã‚’çµ±ä¸€ã™ã‚‹ã“ã¨ã§,ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€è²«æ€§ã‚’ä¿ã¡ã¾ã™.\n",
    "\n",
    "### ## äº‹å‰æº–å‚™ ğŸ“\n",
    "\n",
    "* `Step 2`ã®`sbom-tool`ã«ã‚ˆã‚‹SBOMç”ŸæˆãŒå®Œäº†ã—ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™.\n",
    "* **`generated_sboms/<ãƒªãƒã‚¸ãƒˆãƒªå>/source/_manifest`** ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã«,`manifest.spdx.json`ãŒå­˜åœ¨ã—ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™.\n",
    "\n",
    "### ## å®Ÿè¡Œå†…å®¹ âš™ï¸\n",
    "\n",
    "ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯,`generated_sboms`å†…ã®å„ãƒªãƒã‚¸ãƒˆãƒªã‚’å·¡å›ã—,ä»¥ä¸‹ã®å‡¦ç†ã‚’è‡ªå‹•çš„ã«å®Ÿè¡Œã—ã¾ã™.\n",
    "\n",
    "1.  `source/_manifest/spdx_2.2/manifest.spdx.json` ã‚’ **`combined_sbom.json`** ã¨ã—ã¦å„ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ«ãƒ¼ãƒˆã«ã‚³ãƒ”ãƒ¼ã—ã¾ã™.\n",
    "2.  ã‚³ãƒ”ãƒ¼ç›´å¾Œã«`combined_sbom.json`ã‚’å†åº¦é–‹ã,å®šç¾©ã•ã‚ŒãŸ`key_order`ãƒªã‚¹ãƒˆã®é †åºã«å¾“ã£ã¦ã‚­ãƒ¼ã‚’ä¸¦ã³æ›¿ãˆã¾ã™.\n",
    "3.  ä¸¦ã³æ›¿ãˆãŸå†…å®¹ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ãä¿å­˜ã—ã¾ã™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04a2e5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting: Copying and reordering SBOMs ---\n",
      "--------------------------------------------------\n",
      "â–¶ï¸  Processing: python-template-project\n",
      "   Copying sbom-tool's output to 'combined_sbom.json'...\n",
      "   âœ… Copy successful.\n",
      "   Reordering keys...\n",
      "   âœ… Keys reordered and saved.\n",
      "--------------------------------------------------\n",
      "All processes finished.\n"
     ]
    }
   ],
   "source": [
    "# --- è¨­å®šé …ç›® ---\n",
    "\n",
    "# 1. å‡¦ç†å¯¾è±¡ã®è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "target_directory = 'generated_sboms'\n",
    "\n",
    "# 2. ç”Ÿæˆã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å\n",
    "target_filename = 'combined_sbom.json'\n",
    "\n",
    "# 3. ä¸¦ã³æ›¿ãˆãŸã„ã‚­ãƒ¼ã®é †ç•ª\n",
    "key_order = [\n",
    "    \"SPDXID\",\n",
    "    \"spdxVersion\",\n",
    "    \"creationInfo\",\n",
    "    \"name\",\n",
    "    \"dataLicense\",\n",
    "    \"documentNamespace\",\n",
    "    \"documentDescribes\",\n",
    "    \"externalDocumentRefs\",\n",
    "    \"packages\",\n",
    "    \"files\",\n",
    "    \"relationships\",\n",
    "]\n",
    "\n",
    "\n",
    "# --- å‡¦ç†ã®é–‹å§‹ ---\n",
    "print(f\"--- Starting: Copying and reordering SBOMs ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "try:\n",
    "    # 'generated_sboms' å†…ã®ãƒªãƒã‚¸ãƒˆãƒªåã‚’å–å¾—\n",
    "    repo_dirs = [d for d in os.listdir(target_directory) if os.path.isdir(os.path.join(target_directory, d))]\n",
    "    \n",
    "    if not repo_dirs:\n",
    "         print(f\"No repository directories found in '{target_directory}'.\")\n",
    "\n",
    "    for repo_name in repo_dirs:\n",
    "        print(f\"â–¶ï¸  Processing: {repo_name}\")\n",
    "\n",
    "        # --- ãƒ‘ã‚¹ã®å®šç¾© ---\n",
    "        source_sbom_path = os.path.join(target_directory, repo_name, 'source', '_manifest', 'spdx_2.2', 'manifest.spdx.json')\n",
    "        destination_sbom_path = os.path.join(target_directory, repo_name, target_filename)\n",
    "\n",
    "        # --- ã‚¹ã‚­ãƒƒãƒ—åˆ¤å®š ---\n",
    "        if os.path.exists(destination_sbom_path):\n",
    "            print(f\"ğŸŸ¢ Skipping: '{target_filename}' already exists.\")\n",
    "            print(\"-\" * 50)\n",
    "            continue\n",
    "        \n",
    "        # --- ã‚³ãƒ”ãƒ¼å…ƒã®å­˜åœ¨ç¢ºèª ---\n",
    "        if not os.path.exists(source_sbom_path):\n",
    "            print(f\"âš ï¸ Warning: sbom-tool SBOM not found for {repo_name}. Skipping.\")\n",
    "            print(\"-\" * 50)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—1: ã‚³ãƒ”ãƒ¼ ---\n",
    "            print(f\"   Copying sbom-tool's output to '{target_filename}'...\")\n",
    "            shutil.copy(source_sbom_path, destination_sbom_path)\n",
    "            print(\"   âœ… Copy successful.\")\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—2: èª­ã¿è¾¼ã¿ã¨ä¸¦ã³æ›¿ãˆ ---\n",
    "            with open(destination_sbom_path, 'r', encoding='utf-8') as f:\n",
    "                original_data = json.load(f)\n",
    "\n",
    "            ordered_data = {}\n",
    "            # æŒ‡å®šã•ã‚ŒãŸé †ã§ã‚­ãƒ¼ã‚’è¿½åŠ \n",
    "            for key in key_order:\n",
    "                if key in original_data:\n",
    "                    ordered_data[key] = original_data[key]\n",
    "            # æ®‹ã‚Šã®ã‚­ãƒ¼ã‚’æœ«å°¾ã«è¿½åŠ \n",
    "            for key, value in original_data.items():\n",
    "                if key not in ordered_data:\n",
    "                    ordered_data[key] = value\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—3: æ•´å½¢ã—ã¦ä¸Šæ›¸ãä¿å­˜ ---\n",
    "            print(f\"   Reordering keys...\")\n",
    "            with open(destination_sbom_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(ordered_data, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"   âœ… Keys reordered and saved.\")\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"âŒ Error: Could not parse source JSON file. It may be corrupted.\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ An unexpected error occurred: {e}\")\n",
    "        \n",
    "        finally:\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: The source directory '{target_directory}' was not found.\")\n",
    "\n",
    "print(\"All processes finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb964aea",
   "metadata": {},
   "source": [
    "# Step 7: SBOMã®çµ±åˆ (GitHub Dependency Graph)\n",
    "\n",
    "ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯,`Step 6`ã§ä½œæˆã—ãŸãƒ™ãƒ¼ã‚¹SBOM (`combined_sbom.json`) ã«å¯¾ã—ã¦,`Step 4`ã§GitHub APIã‹ã‚‰å–å¾—ã—ãŸ`dependency-graph-sbom.json`ã®æƒ…å ±ã‚’çµ±åˆã—ã¾ã™.ã“ã®å‡¦ç†ã«ã‚ˆã‚Š,ç‰¹ã«**ãƒ©ã‚¤ã‚»ãƒ³ã‚¹**ã‚„**è‘—ä½œæ¨©**ã«é–¢ã™ã‚‹æƒ…å ±ãŒå¤§å¹…ã«è£œå¼·ã•ã‚Œã¾ã™.\n",
    "\n",
    "### ## å®Ÿè¡Œå†…å®¹ âš™ï¸\n",
    "\n",
    "ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯,2ã¤ã®SBOMãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¯”è¼ƒã—,`combined_sbom.json`ã‚’ã‚ˆã‚Šå®Œå…¨ãªã‚‚ã®ã«ã™ã‚‹ãŸã‚ã«,ä»¥ä¸‹ã®4ã¤ã®ä¸»è¦ãªå‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™.\n",
    "\n",
    "#### 1. æ—¢å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æƒ…å ±ã®è£œå®Œ\n",
    "`purl`ï¼ˆPackage URLï¼‰ã‚’åŸºæº–ã«2ã¤ã®SBOMé–“ã§ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ç…§åˆã—,`combined_sbom.json`ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æƒ…å ±ã«ä¸è¶³ãŒã‚ã‚Œã°,`dependency-graph-sbom.json`ã‹ã‚‰ä»¥ä¸‹ã®æƒ…å ±ã‚’è£œå®Œã—ã¾ã™.\n",
    "\n",
    "* **`licenseConcluded`**: ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æƒ…å ±ãŒ`NOASSERTION`ã®å ´åˆã«æ›´æ–°ã—ã¾ã™.\n",
    "* **`copyrightText`**: è‘—ä½œæ¨©æƒ…å ±ãŒ`NOASSERTION`ã®å ´åˆã«æ›´æ–°ã—ã¾ã™.\n",
    "\n",
    "#### 2. ä¸è¶³ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®è¿½åŠ \n",
    "`sbom-tool`ã§ã¯æ¤œå‡ºã•ã‚Œãªã‹ã£ãŸãŒ,`dependency-graph`ã§ã¯æ¤œå‡ºã•ã‚ŒãŸãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ï¼ˆä¸»ã«GitHub Actionsãªã©ï¼‰ã‚’è¿½åŠ ã—ã¾ã™.é‡è¤‡ã‚’é˜²ããŸã‚,**`name`ï¼ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åï¼‰**ãŒ`combined_sbom.json`ã«å­˜åœ¨ã—ãªã„ã‚‚ã®ã®ã¿ãŒè¿½åŠ å¯¾è±¡ã¨ãªã‚Šã¾ã™.\n",
    "\n",
    "#### 3. `creators`æƒ…å ±ã®è¿½è¨˜\n",
    "`creationInfo`ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«,`dependency-graph`ã‚’ç”Ÿæˆã—ãŸãƒ„ãƒ¼ãƒ«ã®æƒ…å ±ï¼ˆ`Tool: ...`ï¼‰ã‚’è¿½è¨˜ã—ã¾ã™.\n",
    "\n",
    "#### 4. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚³ãƒ¡ãƒ³ãƒˆã®è¿½è¨˜\n",
    "ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã«é–¢ã™ã‚‹`comment`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«,`dependency-graph`ã‹ã‚‰ã®æ³¨é‡ˆã‚’è¿½è¨˜ã—ã¾ã™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63d8ccd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting: Supplementing 'combined_sbom.json' with data from dependency-graph-sbom.json ---\n",
      "--------------------------------------------------\n",
      "â–¶ï¸  Processing: python-template-project\n",
      "   Added new package from dependency-graph: com.github.MoriwakiYusuke/python-template-project (pkg:github/MoriwakiYusuke/python-template-project@main)\n",
      "\n",
      "   --- Summary of Changes (Dependency graph) ---\n",
      "   - Licenses updated: 2\n",
      "   - Copyrights updated: 2\n",
      "   - New packages added: 1\n",
      "   - New relationships added: 1\n",
      "   - Creators added: 2\n",
      "   - Merge annotations added: 5\n",
      "   --------------------------\n",
      "   Total changes: 13. Saving file...\n",
      "âœ… Successfully saved and reordered 'combined_sbom.json'.\n",
      "--------------------------------------------------\n",
      "\n",
      "Writing/Appending merge summary to 'generated_sboms/merge_summary.csv'...\n",
      "âœ… CSV summary saved successfully.\n",
      "All processes finished.\n"
     ]
    }
   ],
   "source": [
    "# --- è¨­å®šé …ç›® ---\n",
    "target_directory = 'generated_sboms'\n",
    "base_sbom_filename = 'combined_sbom.json'\n",
    "source_sbom_filename = 'dependency-graph-sbom.json'\n",
    "# å…¨ã¦ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§å…±é€šã®CSVã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«å\n",
    "csv_output_filename = 'merge_summary.csv'\n",
    "\n",
    "# --- å‡¦ç†ã®é–‹å§‹ ---\n",
    "print(f\"--- Starting: Supplementing '{base_sbom_filename}' with data from {source_sbom_filename} ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- CSVå‡ºåŠ›ç”¨ã®è¨­å®š ---\n",
    "# ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§å‡¦ç†ã—ãŸå…¨ãƒªãƒã‚¸ãƒˆãƒªã®å¤‰æ›´ã‚µãƒãƒªãƒ¼ã‚’ä¸€æ™‚çš„ã«æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ.\n",
    "all_changes_data = []\n",
    "# æœ€çµ‚çš„ãªCSVãƒ•ã‚¡ã‚¤ãƒ«ã®å‡ºåŠ›å…ˆãƒ‘ã‚¹.\n",
    "csv_output_path = os.path.join(target_directory, csv_output_filename)\n",
    "# (CSV_FIELDNAMESã¯å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ)\n",
    "\n",
    "try:\n",
    "    # 'generated_sboms' ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒªãƒã‚¸ãƒˆãƒªåä¸€è¦§ã‚’å–å¾—ã™ã‚‹.\n",
    "    repo_dirs = [d for d in os.listdir(target_directory) if os.path.isdir(os.path.join(target_directory, d))]\n",
    "    if not repo_dirs:\n",
    "        print(f\"No repository directories found in '{target_directory}'.\")\n",
    "\n",
    "    # å„ãƒªãƒã‚¸ãƒˆãƒªã«å¯¾ã—ã¦ãƒãƒ¼ã‚¸å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹.\n",
    "    for repo_name in repo_dirs:\n",
    "        print(f\"â–¶ï¸  Processing: {repo_name}\")\n",
    "\n",
    "        base_sbom_path = os.path.join(target_directory, repo_name, base_sbom_filename)\n",
    "        source_sbom_path = os.path.join(target_directory, repo_name, 'source', source_sbom_filename)\n",
    "\n",
    "        # ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ã©ã¡ã‚‰ã‹ãŒæ¬ ã‘ã¦ã„ã‚‹å ´åˆã€å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹.\n",
    "        if not os.path.exists(base_sbom_path) or not os.path.exists(source_sbom_path):\n",
    "            print(f\"âš ï¸ Warning: One or both SBOM files are missing. Skipping.\")\n",
    "            print(\"-\" * 50)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—1: ä¸¡æ–¹ã®SBOMãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ ---\n",
    "            with open(base_sbom_path, 'r', encoding='utf-8') as f:\n",
    "                base_data = json.load(f)\n",
    "            with open(source_sbom_path, 'r', encoding='utf-8') as f:\n",
    "                source_data = json.load(f)\n",
    "\n",
    "            # --- å¤‰æ›´é …ç›®ã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹ãŸã‚ã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’è¾æ›¸ã¨ã—ã¦åˆæœŸåŒ– ---\n",
    "            # å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®CSV_FIELDNAMESã‚’ä½¿ã„ã€é–¢é€£ã™ã‚‹ã‚­ãƒ¼ã®ã¿ã‚’0ã§åˆæœŸåŒ–\n",
    "            counts = {field: 0 for field in CSV_FIELDNAMES if field not in ['repository', 'source_tool']}\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—2: æ—¢å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®æƒ…å ±ã‚’è£œå®Œã—ã€æ³¨é‡ˆã‚’è¿½åŠ  ---\n",
    "            # è£œå®Œå…ƒãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æƒ…å ±ã‚’purlã‚’ã‚­ãƒ¼ã«è¾æ›¸åŒ–ã—ã€å¾Œã®æ¤œç´¢å‡¦ç†ã‚’é«˜é€ŸåŒ–ã™ã‚‹.\n",
    "            source_package_map = {}\n",
    "            if 'packages' in source_data:\n",
    "                for pkg in source_data['packages']:\n",
    "                    purl = get_purl_from_package(pkg)\n",
    "                    if purl:\n",
    "                        source_package_map[purl] = {\n",
    "                            'licenseConcluded': pkg.get('licenseConcluded'), # NOASSERTIONåˆ¤å®šã¯merge_package_infoã§è¡Œã†ãŸã‚ç”Ÿã®å€¤ã‚’å–å¾—\n",
    "                            'copyrightText': pkg.get('copyrightText')\n",
    "                        }\n",
    "\n",
    "            \n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—3: æ—¢å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®æƒ…å ±ã‚’è£œå®Œã—ã€æ³¨é‡ˆã‚’è¿½åŠ  ---\n",
    "            if 'packages' in base_data:\n",
    "                for pkg in base_data['packages']:\n",
    "                    purl = get_purl_from_package(pkg)\n",
    "                    if purl and purl in source_package_map:\n",
    "                        source_pkg = source_package_map[purl]\n",
    "                        \n",
    "                        # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªé–¢æ•°ã‚’ä½¿ã£ã¦ãƒãƒ¼ã‚¸ã¨ç«¶åˆãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ\n",
    "                        merge_results = merge_package_info(\n",
    "                            base_pkg=pkg,\n",
    "                            source_pkg=source_pkg,\n",
    "                            fields_to_check=['licenseConcluded', 'copyrightText'],\n",
    "                            source_tool_name='dependency-graph'\n",
    "                        )\n",
    "                        \n",
    "                        # çµæœã«åŸºã¥ã„ã¦ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’æ›´æ–°\n",
    "                        if merge_results.get('licenseConcluded') == 'updated':\n",
    "                            counts['licenses_updated'] += 1\n",
    "                        elif merge_results.get('licenseConcluded') == 'conflict':\n",
    "                            counts['conflicts_detected'] += 1\n",
    "                            \n",
    "                        if merge_results.get('copyrightText') == 'updated':\n",
    "                            counts['copyrights_updated'] += 1\n",
    "                        elif merge_results.get('copyrightText') == 'conflict':\n",
    "                            counts['conflicts_detected'] += 1\n",
    "                        \n",
    "                        # æ³¨é‡ˆã®è¿½åŠ æ•°ã¯ã€updatedã¾ãŸã¯conflictã®æ•°ã ã‘å¢—ãˆã‚‹\n",
    "                        counts['merge_annotations_added'] += len(merge_results)\n",
    "            \n",
    "            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚³ãƒ¡ãƒ³ãƒˆã‚’è¿½è¨˜\n",
    "            source_doc_comment = source_data.get('comment')\n",
    "            if source_doc_comment:\n",
    "                comment_header = \"Note from dependency-graph\"\n",
    "                full_comment_to_add = f\"{comment_header}: {source_doc_comment}\"\n",
    "                if 'comment' not in base_data or not base_data.get('comment'):\n",
    "                    base_data['comment'] = full_comment_to_add\n",
    "                    counts['comments_updated'] = 1 # è¾æ›¸ã®å€¤ã‚’æ›´æ–°\n",
    "                elif full_comment_to_add not in base_data['comment']:\n",
    "                    base_data['comment'] += f\"\\\\n\\\\n{full_comment_to_add}\"\n",
    "                    counts['comments_updated'] = 1 # è¾æ›¸ã®å€¤ã‚’æ›´æ–°\n",
    "            \n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—4: ä¸è¶³ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’è¿½åŠ ã—ã€æ³¨é‡ˆã¨Relationshipã‚‚è¿½åŠ  ---\n",
    "            # å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®é–¢æ•°ã‚’å‘¼ã³å‡ºã™\n",
    "            new_pkg_count, new_rel_count = add_missing_packages_and_relationships(\n",
    "                base_data, \n",
    "                source_data, \n",
    "                'dependency-graph' # ã“ã®ãƒ„ãƒ¼ãƒ«ã®åå‰ã‚’æ¸¡ã™\n",
    "            )\n",
    "            counts['new_packages_added'] += new_pkg_count\n",
    "            counts['new_relationships_added'] += new_rel_count\n",
    "            # æ³¨é‡ˆã¯ add_missing_packages_and_relationships å†…éƒ¨ã§è¿½åŠ ãƒ»ã‚«ã‚¦ãƒ³ãƒˆã•ã‚Œã‚‹\n",
    "            counts['merge_annotations_added'] += new_pkg_count # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã”ã¨ã®æ³¨é‡ˆ\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—5: dependency-graphã®ãƒ„ãƒ¼ãƒ«æƒ…å ±ã‚’creatorsã«è¿½åŠ  ---\n",
    "            if 'creationInfo' in source_data and 'creators' in source_data['creationInfo']:\n",
    "                base_creators = base_data.setdefault('creationInfo', {}).setdefault('creators', [])\n",
    "                for creator in source_data['creationInfo']['creators']:\n",
    "                    if creator not in base_creators:\n",
    "                        base_creators.append(creator)\n",
    "                        counts['creators_added'] += 1 # è¾æ›¸ã®å€¤ã‚’æ›´æ–°\n",
    "\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—6: å¤‰æ›´ãŒã‚ã£ãŸå ´åˆã®ã¿ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤ºã—ã¦ä¿å­˜ ---\n",
    "            total_changes = sum(counts.values())\n",
    "            if total_changes > 0:\n",
    "                print(\"\\n   --- Summary of Changes (Dependency graph) ---\")\n",
    "                if counts['licenses_updated'] > 0: print(f\"   - Licenses updated: {counts['licenses_updated']}\")\n",
    "                if counts['copyrights_updated'] > 0: print(f\"   - Copyrights updated: {counts['copyrights_updated']}\")\n",
    "                if counts['conflicts_detected'] > 0: print(f\"   - Conflicts detected (Warning): {counts['conflicts_detected']}\")\n",
    "                if counts['new_packages_added'] > 0: print(f\"   - New packages added: {counts['new_packages_added']}\")\n",
    "                if counts['new_relationships_added'] > 0: print(f\"   - New relationships added: {counts['new_relationships_added']}\")\n",
    "                if counts['creators_added'] > 0: print(f\"   - Creators added: {counts['creators_added']}\")\n",
    "                if counts['comments_updated'] > 0: print(f\"   - Document comment updated: {counts['comments_updated']}\")\n",
    "                if counts['merge_annotations_added'] > 0: print(f\"   - Merge annotations added: {counts['merge_annotations_added']}\")\n",
    "                print(f\"   --------------------------\\n   Total changes: {total_changes}. Saving file...\")\n",
    "                \n",
    "                # CSVãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¦ã€ã‚µãƒãƒªãƒ¼è¾æ›¸ã‚’ä½œæˆ\n",
    "                counts['total_changes'] = total_changes\n",
    "                repo_summary = create_summary_dict(\n",
    "                    repo_name=repo_name,\n",
    "                    source_tool='dependency-graph', # ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æƒ…å ±æºã‚’æ˜è¨˜.\n",
    "                    counts=counts\n",
    "                )\n",
    "                all_changes_data.append(repo_summary)\n",
    "                \n",
    "                # JSONä¿å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¦ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜\n",
    "                save_sbom_json(base_data, base_sbom_path)\n",
    "            else:\n",
    "                print(\"   No fields needed updating or adding.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ An unexpected error occurred: {e}\")\n",
    "        finally:\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: The directory '{target_directory}' was not found.\")\n",
    "\n",
    "# --- ã‚¹ãƒ†ãƒƒãƒ—7: ç·åˆã‚µãƒãƒªãƒ¼ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãå‡ºã™ ---\n",
    "write_summary_to_csv(\n",
    "    all_changes_data,\n",
    "    csv_output_path\n",
    ")\n",
    "\n",
    "print(\"All processes finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7103721d",
   "metadata": {},
   "source": [
    "# Step 8: SBOMã®çµ±åˆ (Syft)\n",
    "\n",
    "`sbom-tool`ã¨GitHub APIã®æƒ…å ±ã‚’çµ±åˆã—ãŸ`combined_sbom.json`ã«å¯¾ã—,ã•ã‚‰ã«`syft`ãŒæ¤œå‡ºã—ãŸæƒ…å ±ã‚’ãƒãƒ¼ã‚¸ã—ã¦SBOMã‚’å®Œæˆã•ã›ã¾ã™.`syft`ã¯,ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®æä¾›è€…ï¼ˆ`supplier`ï¼‰ã‚„ä½œæˆå…ƒï¼ˆ`originator`ï¼‰,æ¤œå‡ºå ´æ‰€ï¼ˆ`sourceInfo`ï¼‰,ãã—ã¦è„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒ³ã«ä¸å¯æ¬ ãª**CPE**ï¼ˆCommon Platform Enumerationï¼‰ãªã©ã®è©³ç´°æƒ…å ±ã‚’æ¤œå‡ºã™ã‚‹èƒ½åŠ›ã«å„ªã‚Œã¦ã„ã¾ã™.\n",
    "\n",
    "### ## å®Ÿè¡Œå†…å®¹ âš™ï¸\n",
    "\n",
    "ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯,2ã¤ã®SBOMãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¯”è¼ƒã—,`combined_sbom.json`ã‚’ã•ã‚‰ã«ãƒªãƒƒãƒãªã‚‚ã®ã«ã™ã‚‹ãŸã‚ã«,ä»¥ä¸‹ã®4ã¤ã®ä¸»è¦ãªå‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™.\n",
    "\n",
    "#### 1. æ—¢å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æƒ…å ±ã®è£œå®Œ\n",
    "`purl`ã‚’åŸºæº–ã«ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ç…§åˆã—,`combined_sbom.json`ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æƒ…å ±ã«ä¸è¶³ãŒã‚ã‚Œã°,`syft-sbom.json`ã‹ã‚‰ä»¥ä¸‹ã®æƒ…å ±ã‚’è£œå®Œã—ã¾ã™.\n",
    "\n",
    "* **`supplier`** ã¨ **`originator`**: `NOASSERTION`ã®å ´åˆã«æ›´æ–°ã—ã¾ã™.\n",
    "* **`sourceInfo`**: é …ç›®ãŒå­˜åœ¨ã—ãªã„å ´åˆã«è¿½åŠ ã—ã¾ã™.\n",
    "* **`externalRefs`**: `purl`ã‚„`cpe`ãªã©ã®å¤–éƒ¨ãƒªãƒ³ã‚¯ãŒé‡è¤‡ã—ãªã„ã‚ˆã†ã«è¿½è¨˜ã—ã¾ã™.\n",
    "\n",
    "#### 2. ä¸è¶³ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®è¿½åŠ \n",
    "`sbom-tool`ã‚„GitHub APIã§ã¯æ¤œå‡ºã•ã‚Œãªã‹ã£ãŸãŒ,`syft`ã§ã¯æ¤œå‡ºã•ã‚ŒãŸãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’è¿½åŠ ã—ã¾ã™.é‡è¤‡ã‚’é˜²ããŸã‚,**`name`ï¼ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åï¼‰**ãŒ`combined_sbom.json`ã«å­˜åœ¨ã—ãªã„ã‚‚ã®ã®ã¿ãŒè¿½åŠ å¯¾è±¡ã¨ãªã‚Šã¾ã™.\n",
    "\n",
    "#### 3. `creators`æƒ…å ±ã®è¿½è¨˜\n",
    "`creationInfo`ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«,`syft`ã‚’ç”Ÿæˆã—ãŸãƒ„ãƒ¼ãƒ«ã®æƒ…å ±ï¼ˆ`Tool: syft-...`ï¼‰ã‚’è¿½è¨˜ã—ã¾ã™.\n",
    "\n",
    "#### 4. æ•´å½¢ã—ã¦ä¿å­˜\n",
    "æœ€å¾Œã«,ã™ã¹ã¦ã®æƒ…å ±ãŒçµ±åˆã•ã‚ŒãŸ`combined_sbom.json`ã®ã‚­ãƒ¼ã®é †åºã‚’çµ±ä¸€çš„ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«æ•´ãˆ,ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ãä¿å­˜ã—ã¾ã™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2e1aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting: Supplementing 'combined_sbom.json' with data from syft-sbom.json ---\n",
      "--------------------------------------------------\n",
      "â–¶ï¸  Processing: python-template-project\n",
      "\n",
      "   --- Summary of Changes (syft) ---\n",
      "   - Source infos added: 2\n",
      "   - External refs added: 24\n",
      "   - Creators added: 2\n",
      "   - Merge annotations added: 2\n",
      "   ----------------------------------\n",
      "   Total changes: 30. Saving file...\n",
      "âœ… Successfully saved and reordered 'combined_sbom.json'.\n",
      "--------------------------------------------------\n",
      "\n",
      "Writing/Appending merge summary to 'generated_sboms/merge_summary.csv'...\n",
      "âœ… CSV summary saved successfully.\n",
      "All processes finished.\n"
     ]
    }
   ],
   "source": [
    "# --- è¨­å®šé …ç›® ---\n",
    "target_directory = 'generated_sboms'\n",
    "base_sbom_filename = 'combined_sbom.json'\n",
    "source_sbom_filename = 'syft-sbom.json'\n",
    "# å…¨ã¦ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§å…±é€šã®CSVã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«å\n",
    "csv_output_filename = 'merge_summary.csv'\n",
    "\n",
    "# --- å‡¦ç†ã®é–‹å§‹ ---\n",
    "print(f\"--- Starting: Supplementing '{base_sbom_filename}' with data from {source_sbom_filename} ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- CSVå‡ºåŠ›ç”¨ã®è¨­å®š ---\n",
    "# ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§å‡¦ç†ã—ãŸå…¨ãƒªãƒã‚¸ãƒˆãƒªã®å¤‰æ›´ã‚µãƒãƒªãƒ¼ã‚’ä¸€æ™‚çš„ã«æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ.\n",
    "all_changes_data = []\n",
    "# æœ€çµ‚çš„ãªCSVãƒ•ã‚¡ã‚¤ãƒ«ã®å‡ºåŠ›å…ˆãƒ‘ã‚¹.\n",
    "csv_output_path = os.path.join(target_directory, csv_output_filename)\n",
    "# (CSV_FIELDNAMESã¯å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ)\n",
    "\n",
    "try:\n",
    "    # 'generated_sboms' å†…ã®ãƒªãƒã‚¸ãƒˆãƒªåã‚’å–å¾—ã™ã‚‹\n",
    "    repo_dirs = [d for d in os.listdir(target_directory) if os.path.isdir(os.path.join(target_directory, d))]\n",
    "    \n",
    "    if not repo_dirs:\n",
    "        print(f\"No repository directories found in '{target_directory}'.\")\n",
    "\n",
    "    # å„ãƒªãƒã‚¸ãƒˆãƒªã«å¯¾ã—ã¦å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹\n",
    "    for repo_name in repo_dirs:\n",
    "        print(f\"â–¶ï¸  Processing: {repo_name}\")\n",
    "\n",
    "        base_sbom_path = os.path.join(target_directory, repo_name, base_sbom_filename)\n",
    "        source_sbom_path = os.path.join(target_directory, repo_name, 'source', source_sbom_filename)\n",
    "\n",
    "        if not os.path.exists(base_sbom_path) or not os.path.exists(source_sbom_path):\n",
    "            print(f\"âš ï¸ Warning: One or both SBOM files are missing. Skipping.\")\n",
    "            print(\"-\" * 50)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            with open(base_sbom_path, 'r', encoding='utf-8') as f:\n",
    "                base_data = json.load(f)\n",
    "            with open(source_sbom_path, 'r', encoding='utf-8') as f:\n",
    "                source_data = json.load(f)\n",
    "\n",
    "            # --- å¤‰æ›´é …ç›®ã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹ãŸã‚ã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’è¾æ›¸ã¨ã—ã¦åˆæœŸåŒ– ---\n",
    "            # å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®CSV_FIELDNAMESã‚’ä½¿ã„ã€é–¢é€£ã™ã‚‹ã‚­ãƒ¼ã®ã¿ã‚’0ã§åˆæœŸåŒ–\n",
    "            counts = {field: 0 for field in CSV_FIELDNAMES if field not in ['repository', 'source_tool']}\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—2: syftã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æƒ…å ±ã‚’purlã‚’ã‚­ãƒ¼ã«ã—ãŸè¾æ›¸ã«æ•´ç† ---\n",
    "            # è£œå®Œå…ƒãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æƒ…å ±ã‚’purlã‚’ã‚­ãƒ¼ã«è¾æ›¸åŒ–ã—ã€å¾Œã®æ¤œç´¢å‡¦ç†ã‚’é«˜é€ŸåŒ–ã™ã‚‹.\n",
    "            source_package_map = {}\n",
    "            if 'packages' in source_data:\n",
    "                for pkg in source_data['packages']:\n",
    "                    purl = get_purl_from_package(pkg)\n",
    "                    if purl and purl not in source_package_map:\n",
    "                        source_package_map[purl] = pkg\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—3: æ—¢å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®æƒ…å ±ã‚’è£œå®Œã—ã€æ³¨é‡ˆã‚’è¿½åŠ  ---\n",
    "            # ãƒ™ãƒ¼ã‚¹SBOMã®å…¨ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ãƒ«ãƒ¼ãƒ—ã—ã€æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚Œã°è£œå®Œã™ã‚‹.\n",
    "            if 'packages' in base_data:\n",
    "                for pkg in base_data['packages']:\n",
    "                    purl = get_purl_from_package(pkg)\n",
    "                    # åŒã˜purlã‚’æŒã¤ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒè£œå®Œå…ƒã«ã‚‚å­˜åœ¨ã™ã‚‹å ´åˆã®ã¿å‡¦ç†ã‚’è¡Œã†.\n",
    "                    if purl and purl in source_package_map:\n",
    "                        source_pkg = source_package_map[purl]\n",
    "                        supplemented_fields = []\n",
    "\n",
    "                        # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªé–¢æ•°ã‚’ä½¿ã£ã¦ supplier, originator ã®ãƒãƒ¼ã‚¸ã¨ç«¶åˆãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ\n",
    "                        merge_results = merge_package_info(\n",
    "                            base_pkg=pkg,\n",
    "                            source_pkg=source_pkg,\n",
    "                            fields_to_check=['supplier', 'originator'],\n",
    "                            source_tool_name='syft'\n",
    "                        )\n",
    "                        \n",
    "                        # çµæœã«åŸºã¥ã„ã¦ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’æ›´æ–°\n",
    "                        if merge_results.get('supplier') == 'updated':\n",
    "                            counts['suppliers_updated'] += 1\n",
    "                        elif merge_results.get('supplier') == 'conflict':\n",
    "                            counts['conflicts_detected'] += 1\n",
    "                            \n",
    "                        if merge_results.get('originator') == 'updated':\n",
    "                            counts['originators_updated'] += 1\n",
    "                        elif merge_results.get('originator') == 'conflict':\n",
    "                            counts['conflicts_detected'] += 1\n",
    "                        \n",
    "                        # æ³¨é‡ˆã®è¿½åŠ æ•°ã¯ã€updatedã¾ãŸã¯conflictã®æ•°ã ã‘å¢—ãˆã‚‹\n",
    "                        counts['merge_annotations_added'] += len(merge_results)\n",
    "\n",
    "                        # --- ä»¥ä¸‹ã®å‡¦ç†ï¼ˆsourceInfo, externalRefsï¼‰ã¯ã€å˜ç´”ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ›´æ–°ã§ã¯ãªã„ãŸã‚ã€\n",
    "                        #     merge_package_infoã«ã¯ä»»ã›ãšã€å…ƒã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¶­æŒã™ã‚‹ ---\n",
    "\n",
    "                        # sourceInfoãŒå­˜åœ¨ã—ãªã„å ´åˆã€syftã®æƒ…å ±ã‚’è¿½åŠ ã™ã‚‹.\n",
    "                        if 'sourceInfo' not in pkg and source_pkg.get('sourceInfo'):\n",
    "                            pkg['sourceInfo'] = source_pkg['sourceInfo']\n",
    "                            supplemented_fields.append('sourceInfo')\n",
    "                            counts['source_infos_added'] += 1 # è¾æ›¸ã®å€¤ã‚’æ›´æ–°\n",
    "                        \n",
    "                        # externalRefs (CPEãªã©) ã«é‡è¤‡ãŒãªã„ã‚ˆã†ã«æƒ…å ±ã‚’è¿½è¨˜ã™ã‚‹.\n",
    "                        refs_before = len(pkg.get('externalRefs', []))\n",
    "                        if 'externalRefs' not in pkg: pkg['externalRefs'] = []\n",
    "                        existing_locators = {ref.get('referenceLocator') for ref in pkg['externalRefs']}\n",
    "                        for new_ref in source_pkg.get('externalRefs', []):\n",
    "                            if new_ref.get('referenceLocator') not in existing_locators:\n",
    "                                pkg['externalRefs'].append(new_ref)\n",
    "                        refs_after = len(pkg['externalRefs'])\n",
    "                        if refs_after > refs_before:\n",
    "                            supplemented_fields.append('externalRefs')\n",
    "                            counts['external_refs_added'] += (refs_after - refs_before) # è¾æ›¸ã®å€¤ã‚’æ›´æ–°\n",
    "\n",
    "                        # 1ã¤ä»¥ä¸Šã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒè£œå®Œã•ã‚ŒãŸå ´åˆã€ãã®å‡ºå…¸ã‚’SPDXã®annotationsã¨ã—ã¦è¨˜éŒ²ã™ã‚‹.\n",
    "                        if supplemented_fields:\n",
    "                            annotation = {\n",
    "                                \"annotationDate\": datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "                                \"annotationType\": \"OTHER\",\n",
    "                                \"annotator\": \"Tool: sbom-merge-script\",\n",
    "                                \"comment\": f\"Multi fields ({', '.join(supplemented_fields)}) were supplemented by syft.\"\n",
    "                            }\n",
    "                            pkg.setdefault('annotations', []).append(annotation)\n",
    "                            counts['merge_annotations_added'] += 1 # æ³¨é‡ˆã®è¿½åŠ ã‚’ã‚«ã‚¦ãƒ³ãƒˆ\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—4: ä¸è¶³ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’è¿½åŠ ã—ã€é–¢é€£ã™ã‚‹å…¨ã¦ã®Relationshipã‚‚è¿½åŠ  ---\n",
    "            # å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®é–¢æ•°ã‚’å‘¼ã³å‡ºã™\n",
    "            new_pkg_count, new_rel_count = add_missing_packages_and_relationships(\n",
    "                base_data, \n",
    "                source_data, \n",
    "                'syft' # ã“ã®ãƒ„ãƒ¼ãƒ«ã®åå‰ã‚’æ¸¡ã™\n",
    "            )\n",
    "            counts['new_packages_added'] += new_pkg_count\n",
    "            counts['new_relationships_added'] += new_rel_count\n",
    "            counts['merge_annotations_added'] += new_pkg_count # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã”ã¨ã®æ³¨é‡ˆã‚’ã‚«ã‚¦ãƒ³ãƒˆ\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—5: syftã®ãƒ„ãƒ¼ãƒ«æƒ…å ±ã‚’creatorsã«è¿½åŠ  ---\n",
    "            if 'creationInfo' in source_data and 'creators' in source_data['creationInfo']:\n",
    "                base_creators = base_data.setdefault('creationInfo', {}).setdefault('creators', [])\n",
    "                for creator in source_data['creationInfo']['creators']:\n",
    "                    if creator not in base_creators:\n",
    "                        base_creators.append(creator)\n",
    "                        counts['creators_added'] += 1 # è¾æ›¸ã®å€¤ã‚’æ›´æ–°\n",
    "            \n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—6: å¤‰æ›´ãŒã‚ã£ãŸå ´åˆã®ã¿ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤ºã—ã¦ä¿å­˜ ---\n",
    "            total_changes = sum(counts.values())\n",
    "            \n",
    "            if total_changes > 0:\n",
    "                print(\"\\n   --- Summary of Changes (syft) ---\")\n",
    "                if counts['suppliers_updated'] > 0: print(f\"   - Suppliers updated: {counts['suppliers_updated']}\")\n",
    "                if counts['originators_updated'] > 0: print(f\"   - Originators updated: {counts['originators_updated']}\")\n",
    "                if counts['conflicts_detected'] > 0: print(f\"   - Conflicts detected (Warning): {counts['conflicts_detected']}\")\n",
    "                if counts['source_infos_added'] > 0: print(f\"   - Source infos added: {counts['source_infos_added']}\")\n",
    "                if counts['external_refs_added'] > 0: print(f\"   - External refs added: {counts['external_refs_added']}\")\n",
    "                if counts['new_packages_added'] > 0: print(f\"   - New packages added: {counts['new_packages_added']}\")\n",
    "                if counts['new_relationships_added'] > 0: print(f\"   - New relationships added: {counts['new_relationships_added']}\")\n",
    "                if counts['creators_added'] > 0: print(f\"   - Creators added: {counts['creators_added']}\")\n",
    "                if counts['merge_annotations_added'] > 0: print(f\"   - Merge annotations added: {counts['merge_annotations_added']}\")\n",
    "                print(f\"   ----------------------------------\\n   Total changes: {total_changes}. Saving file...\")\n",
    "                \n",
    "                # CSVãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¦ã€ã‚µãƒãƒªãƒ¼è¾æ›¸ã‚’ä½œæˆ\n",
    "                counts['total_changes'] = total_changes\n",
    "                repo_summary = create_summary_dict(\n",
    "                    repo_name=repo_name, \n",
    "                    source_tool='syft', \n",
    "                    counts=counts\n",
    "                )\n",
    "                all_changes_data.append(repo_summary)\n",
    "                \n",
    "                # JSONä¿å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¦ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜\n",
    "                save_sbom_json(base_data, base_sbom_path)\n",
    "            else:\n",
    "                print(\"   No new information to supplement from syft.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ An unexpected error occurred: {e}\")\n",
    "        finally:\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: The directory '{target_directory}' was not found.\")\n",
    "\n",
    "# --- ã‚¹ãƒ†ãƒƒãƒ—7: ç·åˆã‚µãƒãƒªãƒ¼ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãå‡ºã™ ---\n",
    "write_summary_to_csv(\n",
    "    all_changes_data,\n",
    "    csv_output_path\n",
    ")\n",
    "\n",
    "print(\"All processes finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61f686b",
   "metadata": {},
   "source": [
    "# Step 9: SBOMã®çµ±åˆ (Trivy)\n",
    "\n",
    "ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯,ã“ã‚Œã¾ã§ã®å‡¦ç†ã§æƒ…å ±ã‚’å……å®Ÿã•ã›ã¦ããŸ`combined_sbom.json`ã«å¯¾ã—,æœ€å¾Œã«`Trivy`ãŒç”Ÿæˆã—ãŸ`trivy-sbom.json`ã®æƒ…å ±ã‚’çµ±åˆã—ã¾ã™.`Trivy`ã¯,ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ç›®çš„ (`primaryPackagePurpose`) ã‚„,ãƒ„ãƒ¼ãƒ«å›ºæœ‰ã®æ³¨é‡ˆ (`annotations`) ã¨ã„ã£ãŸ,ä»–ã®ãƒ„ãƒ¼ãƒ«ã§ã¯å¾—ã‚‰ã‚Œãªã„ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªæƒ…å ±ã‚’æä¾›ã—ã¾ã™.\n",
    "\n",
    "### ## å®Ÿè¡Œå†…å®¹ âš™ï¸\n",
    "\n",
    "ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯,`combined_sbom.json`ã‚’æœ€çµ‚çš„ã«å®Œæˆã•ã›ã‚‹ãŸã‚,ä»¥ä¸‹ã®4ã¤ã®ä¸»è¦ãªå‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™.\n",
    "\n",
    "#### 1. æ—¢å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æƒ…å ±ã®è£œå®Œ\n",
    "`purl`ã‚’åŸºæº–ã«ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ç…§åˆã—,`combined_sbom.json`ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æƒ…å ±ã«ä¸è¶³ãŒã‚ã‚Œã°,`trivy-sbom.json`ã‹ã‚‰ä»¥ä¸‹ã®æƒ…å ±ã‚’è£œå®Œã—ã¾ã™.\n",
    "\n",
    "* **`primaryPackagePurpose`**: ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ä¸»ãªç›®çš„ï¼ˆä¾‹: `LIBRARY`, `APPLICATION`ï¼‰ãŒ`NOASSERTION`ã¾ãŸã¯æœªè¨­å®šã®å ´åˆã«æ›´æ–°ã—ã¾ã™.\n",
    "* **`annotations`**: `Trivy`ã«ã‚ˆã‚‹æ³¨é‡ˆæƒ…å ±ï¼ˆä¾‹: `PkgType: pip`ï¼‰ãŒæœªè¨­å®šã®å ´åˆã«è¿½åŠ ã—ã¾ã™.\n",
    "\n",
    "#### 2. ä¸è¶³ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®è¿½åŠ \n",
    "ã“ã‚Œã¾ã§ã®ãƒ„ãƒ¼ãƒ«ã§ã¯æ¤œå‡ºã•ã‚Œãªã‹ã£ãŸãŒ,`Trivy`ãŒç‹¬è‡ªã«æ¤œå‡ºã—ãŸãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’è¿½åŠ ã—ã¾ã™.é‡è¤‡ã‚’é˜²ããŸã‚,**`name`ï¼ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åï¼‰**ãŒ`combined_sbom.json`ã«å­˜åœ¨ã—ãªã„ã‚‚ã®ã®ã¿ãŒè¿½åŠ å¯¾è±¡ã¨ãªã‚Šã¾ã™.\n",
    "\n",
    "#### 3. `creators`æƒ…å ±ã®è¿½è¨˜\n",
    "`creationInfo`ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«,`Trivy`ã‚’ç”Ÿæˆã—ãŸãƒ„ãƒ¼ãƒ«ã®æƒ…å ±ï¼ˆ`Tool: trivy-...`ï¼‰ã‚’è¿½è¨˜ã—ã¾ã™.\n",
    "\n",
    "#### 4. æ•´å½¢ã—ã¦ä¿å­˜\n",
    "æœ€å¾Œã«,ã™ã¹ã¦ã®æƒ…å ±ãŒçµ±åˆã•ã‚ŒãŸ`combined_sbom.json`ã®ã‚­ãƒ¼ã®é †åºã‚’çµ±ä¸€çš„ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«æ•´ãˆ,ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ãä¿å­˜ã—ã¾ã™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6f7d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting: Supplementing 'combined_sbom.json' with data from trivy-sbom.json ---\n",
      "--------------------------------------------------\n",
      "â–¶ï¸  Processing: python-template-project\n",
      "\n",
      "   --- Summary of Changes (Trivy) ---\n",
      "   - Purposes updated: 2\n",
      "   - Annotations added: 2\n",
      "   - Creators added: 2\n",
      "   - Merge annotations added: 4\n",
      "   ---------------------------------\n",
      "   Total changes: 10. Saving file...\n",
      "âœ… Successfully saved and reordered 'combined_sbom.json'.\n",
      "--------------------------------------------------\n",
      "\n",
      "Writing/Appending merge summary to 'generated_sboms/merge_summary.csv'...\n",
      "âœ… CSV summary saved successfully.\n",
      "All processes finished.\n"
     ]
    }
   ],
   "source": [
    "# --- è¨­å®šé …ç›® ---\n",
    "target_directory = 'generated_sboms'\n",
    "base_sbom_filename = 'combined_sbom.json'\n",
    "# Trivyã§ç”Ÿæˆã—ãŸãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŒ‡å®š\n",
    "source_sbom_filename = 'trivy-sbom.json'\n",
    "# å…¨ã¦ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§å…±é€šã®CSVã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«å\n",
    "csv_output_filename = 'merge_summary.csv'\n",
    "\n",
    "# --- å‡¦ç†ã®é–‹å§‹ ---\n",
    "print(f\"--- Starting: Supplementing '{base_sbom_filename}' with data from {source_sbom_filename} ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- CSVå‡ºåŠ›ç”¨ã®è¨­å®š ---\n",
    "# ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§å‡¦ç†ã—ãŸå…¨ãƒªãƒã‚¸ãƒˆãƒªã®å¤‰æ›´ã‚µãƒãƒªãƒ¼ã‚’ä¸€æ™‚çš„ã«æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ.\n",
    "all_changes_data = []\n",
    "# æœ€çµ‚çš„ãªCSVãƒ•ã‚¡ã‚¤ãƒ«ã®å‡ºåŠ›å…ˆãƒ‘ã‚¹.\n",
    "csv_output_path = os.path.join(target_directory, csv_output_filename)\n",
    "\n",
    "try:\n",
    "    # 'generated_sboms' å†…ã®ãƒªãƒã‚¸ãƒˆãƒªåã‚’å–å¾—ã™ã‚‹\n",
    "    repo_dirs = [d for d in os.listdir(target_directory) if os.path.isdir(os.path.join(target_directory, d))]\n",
    "    \n",
    "    if not repo_dirs:\n",
    "        print(f\"No repository directories found in '{target_directory}'.\")\n",
    "\n",
    "    # å„ãƒªãƒã‚¸ãƒˆãƒªã«å¯¾ã—ã¦å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹\n",
    "    for repo_name in repo_dirs:\n",
    "        print(f\"â–¶ï¸  Processing: {repo_name}\")\n",
    "\n",
    "        # --- ãƒ‘ã‚¹ã®å®šç¾© ---\n",
    "        base_sbom_path = os.path.join(target_directory, repo_name, base_sbom_filename)\n",
    "        source_sbom_path = os.path.join(target_directory, repo_name, 'source', source_sbom_filename)\n",
    "\n",
    "        # --- ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª ---\n",
    "        if not os.path.exists(base_sbom_path) or not os.path.exists(source_sbom_path):\n",
    "            print(f\"âš ï¸ Warning: One or both SBOM files are missing. Skipping.\")\n",
    "            print(\"-\" * 50)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—1: ä¸¡æ–¹ã®SBOMãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ ---\n",
    "            with open(base_sbom_path, 'r', encoding='utf-8') as f:\n",
    "                base_data = json.load(f)\n",
    "            with open(source_sbom_path, 'r', encoding='utf-8') as f:\n",
    "                source_data = json.load(f)\n",
    "\n",
    "            initial_data_str = json.dumps(base_data, sort_keys=True)\n",
    "\n",
    "            # --- å¤‰æ›´é …ç›®ã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹ãŸã‚ã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’è¾æ›¸ã¨ã—ã¦åˆæœŸåŒ– ---\n",
    "            # å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®CSV_FIELDNAMESã‚’ä½¿ã„ã€é–¢é€£ã™ã‚‹ã‚­ãƒ¼ã®ã¿ã‚’0ã§åˆæœŸåŒ–\n",
    "            counts = {field: 0 for field in CSV_FIELDNAMES if field not in ['repository', 'source_tool']}\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—2: Trivyã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æƒ…å ±ã‚’purlã‚’ã‚­ãƒ¼ã«ã—ãŸè¾æ›¸ã«æ•´ç† ---\n",
    "            # è£œå®Œå…ƒãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æƒ…å ±ã‚’purlã‚’ã‚­ãƒ¼ã«è¾æ›¸åŒ–ã—ã€å¾Œã®æ¤œç´¢å‡¦ç†ã‚’é«˜é€ŸåŒ–ã™ã‚‹.\n",
    "            source_package_map = {}\n",
    "            if 'packages' in source_data:\n",
    "                for pkg in source_data['packages']:\n",
    "                    purl = get_purl_from_package(pkg)\n",
    "                    if purl and purl not in source_package_map:\n",
    "                        source_package_map[purl] = pkg\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—3: æ—¢å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®æƒ…å ±ã‚’è£œå®Œã—ã€æ³¨é‡ˆã‚’è¿½åŠ  ---\n",
    "            # ãƒ™ãƒ¼ã‚¹SBOMã®å…¨ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ãƒ«ãƒ¼ãƒ—ã—ã€æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚Œã°è£œå®Œã™ã‚‹.\n",
    "            if 'packages' in base_data:\n",
    "                for pkg in base_data['packages']:\n",
    "                    purl = get_purl_from_package(pkg)\n",
    "                    if purl and purl in source_package_map:\n",
    "                        source_pkg = source_package_map[purl]\n",
    "                        supplemented_fields = []\n",
    "                        \n",
    "                        # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªé–¢æ•°ã‚’ä½¿ã£ã¦ primaryPackagePurpose ã®ãƒãƒ¼ã‚¸ã¨ç«¶åˆãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ\n",
    "                        merge_results = merge_package_info(\n",
    "                            base_pkg=pkg,\n",
    "                            source_pkg=source_pkg,\n",
    "                            fields_to_check=['primaryPackagePurpose'],\n",
    "                            source_tool_name='trivy'\n",
    "                        )\n",
    "\n",
    "                        # çµæœã«åŸºã¥ã„ã¦ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’æ›´æ–°\n",
    "                        if merge_results.get('primaryPackagePurpose') == 'updated':\n",
    "                            counts['purposes_updated'] += 1\n",
    "                        elif merge_results.get('primaryPackagePurpose') == 'conflict':\n",
    "                            counts['conflicts_detected'] += 1\n",
    "                        \n",
    "                        # æ³¨é‡ˆã®è¿½åŠ æ•°ã¯ã€updatedã¾ãŸã¯conflictã®æ•°ã ã‘å¢—ãˆã‚‹\n",
    "                        counts['merge_annotations_added'] += len(merge_results)\n",
    "\n",
    "                        # --- ä»¥ä¸‹ã®å‡¦ç†ï¼ˆannotationsãƒªã‚¹ãƒˆï¼‰ã¯ã€å˜ç´”ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ›´æ–°ã§ã¯ãªã„ãŸã‚ã€\n",
    "                        #     merge_package_infoã«ã¯ä»»ã›ãšã€å…ƒã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¶­æŒã™ã‚‹ ---\n",
    "\n",
    "                        # annotationsãŒå­˜åœ¨ã—ãªã„å ´åˆã€Trivyã®æƒ…å ±ã‚’è¿½åŠ ã™ã‚‹.\n",
    "                        if source_pkg.get('annotations'):\n",
    "                            base_annotations = pkg.setdefault('annotations', [])\n",
    "                            existing_comments = {ann.get('comment') for ann in base_annotations}\n",
    "                            added_count_for_this_pkg = 0\n",
    "                            for source_ann in source_pkg['annotations']:\n",
    "                                # é‡è¤‡ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆï¼ˆï¼åŒã˜æ³¨é‡ˆï¼‰ã§ãªã‘ã‚Œã°è¿½åŠ ã™ã‚‹.\n",
    "                                if source_ann.get('comment') not in existing_comments:\n",
    "                                    base_annotations.append(source_ann)\n",
    "                                    existing_comments.add(source_ann.get('comment'))\n",
    "                                    added_count_for_this_pkg += 1\n",
    "                            if added_count_for_this_pkg > 0:\n",
    "                                supplemented_fields.append('annotations')\n",
    "                                counts['annotations_added'] += added_count_for_this_pkg # è¾æ›¸ã®å€¤ã‚’æ›´æ–°\n",
    "\n",
    "                        # 1ã¤ä»¥ä¸Šã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒè£œå®Œã•ã‚ŒãŸå ´åˆã€ãã®å‡ºå…¸ã‚’SPDXã®annotationsã¨ã—ã¦è¨˜éŒ²ã™ã‚‹.\n",
    "                        if supplemented_fields:\n",
    "                            annotation = {\n",
    "                                \"annotationDate\": datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "                                \"annotationType\": \"OTHER\",\n",
    "                                \"annotator\": \"Tool: sbom-merge-script\",\n",
    "                                \"comment\": f\"Multi fields ({', '.join(supplemented_fields)}) were supplemented by trivy.\"\n",
    "                            }\n",
    "                            pkg.setdefault('annotations', []).append(annotation)\n",
    "                            counts['merge_annotations_added'] += 1 # æ³¨é‡ˆã®è¿½åŠ ã‚’ã‚«ã‚¦ãƒ³ãƒˆ\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—4: ä¸è¶³ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’è¿½åŠ ã—ã€é–¢é€£ã™ã‚‹å…¨ã¦ã®Relationshipã‚‚è¿½åŠ  ---\n",
    "            # å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®é–¢æ•°ã‚’å‘¼ã³å‡ºã™\n",
    "            new_pkg_count, new_rel_count = add_missing_packages_and_relationships(\n",
    "                base_data, \n",
    "                source_data, \n",
    "                'trivy' # ã“ã®ãƒ„ãƒ¼ãƒ«ã®åå‰ã‚’æ¸¡ã™\n",
    "            )\n",
    "            counts['new_packages_added'] += new_pkg_count\n",
    "            counts['new_relationships_added'] += new_rel_count\n",
    "            counts['merge_annotations_added'] += new_pkg_count # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã”ã¨ã®æ³¨é‡ˆã‚’ã‚«ã‚¦ãƒ³ãƒˆ\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—5: Trivyã®ãƒ„ãƒ¼ãƒ«æƒ…å ±ã‚’creatorsã«è¿½åŠ  ---\n",
    "            if 'creationInfo' in source_data and 'creators' in source_data['creationInfo']:\n",
    "                base_creators = base_data.setdefault('creationInfo', {}).setdefault('creators', [])\n",
    "                for creator in source_data['creationInfo']['creators']:\n",
    "                    if creator not in base_creators:\n",
    "                        base_creators.append(creator)\n",
    "                        counts['creators_added'] += 1 # è¾æ›¸ã®å€¤ã‚’æ›´æ–°\n",
    "            \n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—6: å¤‰æ›´ãŒã‚ã£ãŸå ´åˆã®ã¿ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤ºã—ã¦ä¿å­˜ ---\n",
    "            total_changes = sum(counts.values())\n",
    "\n",
    "            if total_changes > 0:\n",
    "                print(\"\\n   --- Summary of Changes (Trivy) ---\")\n",
    "                if counts['purposes_updated'] > 0: print(f\"   - Purposes updated: {counts['purposes_updated']}\")\n",
    "                if counts['annotations_added'] > 0: print(f\"   - Annotations added: {counts['annotations_added']}\")\n",
    "                if counts['conflicts_detected'] > 0: print(f\"   - Conflicts detected (Warning): {counts['conflicts_detected']}\")\n",
    "                if counts['new_packages_added'] > 0: print(f\"   - New packages added: {counts['new_packages_added']}\")\n",
    "                if counts['new_relationships_added'] > 0: print(f\"   - New relationships added: {counts['new_relationships_added']}\")\n",
    "                if counts['creators_added'] > 0: print(f\"   - Creators added: {counts['creators_added']}\")\n",
    "                if counts['merge_annotations_added'] > 0: print(f\"   - Merge annotations added: {counts['merge_annotations_added']}\")\n",
    "                print(f\"   ---------------------------------\\n   Total changes: {total_changes}. Saving file...\")\n",
    "\n",
    "                # CSVãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¦ã€ã‚µãƒãƒªãƒ¼è¾æ›¸ã‚’ä½œæˆ\n",
    "                counts['total_changes'] = total_changes\n",
    "                repo_summary = create_summary_dict(\n",
    "                    repo_name=repo_name,\n",
    "                    source_tool='trivy', # ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æƒ…å ±æºã‚’æ˜è¨˜.\n",
    "                    counts=counts\n",
    "                )\n",
    "                all_changes_data.append(repo_summary)\n",
    "                \n",
    "                # JSONä¿å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¦ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜\n",
    "                save_sbom_json(base_data, base_sbom_path)\n",
    "            else:\n",
    "                print(\"   No new information to supplement from Trivy.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ An unexpected error occurred: {e}\")\n",
    "        finally:\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: The directory '{target_directory}' was not found.\")\n",
    "\n",
    "# --- ã‚¹ãƒ†ãƒƒãƒ—7: ç·åˆã‚µãƒãƒªãƒ¼ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãå‡ºã™ ---\n",
    "write_summary_to_csv(\n",
    "    all_changes_data,\n",
    "    csv_output_path\n",
    ")\n",
    "\n",
    "print(\"All processes finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aa869f",
   "metadata": {},
   "source": [
    "# Step 10: `fileTypes`ã®è¿½åŠ ã«ã‚ˆã‚‹SBOMã®å“è³ªå‘ä¸Š\n",
    "\n",
    "ã“ã‚Œã¾ã§ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ä½œæˆã—ãŸ`combined_sbom.json`ã‚’ã•ã‚‰ã«æ”¹è‰¯ã—ã€SBOMã¨ã—ã¦ã®å“è³ªã¨å®Ÿç”¨æ€§ã‚’é«˜ã‚ã¾ã™. ã“ã®æœ€çµ‚ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€`files`ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«å«ã¾ã‚Œã‚‹å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ³ãƒˆãƒªã«å¯¾ã—ã€ãã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¹å‰²ã‚’ç¤ºã™ **`fileTypes`** ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ ã—ã¾ã™.\n",
    "\n",
    "### ## å®Ÿè¡Œå†…å®¹ âš™ï¸\n",
    "\n",
    "SPDXã®ä»•æ§˜ã§ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã€ãƒã‚¤ãƒŠãƒªã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãªã©ã€ã©ã®ã‚«ãƒ†ã‚´ãƒªã«å±ã™ã‚‹ã‹ã‚’ç¤ºã™`fileTypes`ã‚’å®šç¾©ã§ãã¾ã™. ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯ã€ã“ã®ä»•æ§˜ã«åŸºã¥ãã€å„ãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­ã‚’èª­ã¿å–ã£ã¦é©åˆ‡ãªã‚¿ã‚¤ãƒ—ã‚’è‡ªå‹•ã§å‰²ã‚Šå½“ã¦ã¾ã™.\n",
    "\n",
    "1.  **`combined_sbom.json`ã®èª­ã¿è¾¼ã¿**:\n",
    "    * å„ãƒªãƒã‚¸ãƒˆãƒªã®`combined_sbom.json`ã‚’èª­ã¿è¾¼ã¿ã€`files`ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è§£æã—ã¾ã™.\n",
    "\n",
    "2.  **ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã®åˆ¤å®š**:\n",
    "    * äº‹å‰ã«å®šç¾©ã•ã‚ŒãŸæ‹¡å¼µå­ã®ãƒãƒƒãƒ”ãƒ³ã‚° (`EXTENSION_TO_FILE_TYPE`) ã‚’åŸºã«ã€å„ãƒ•ã‚¡ã‚¤ãƒ«ã®`fileName`ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®šã—ã¾ã™ (ä¾‹: `.py` â†’ `SOURCE`, `.md` â†’ `DOCUMENTATION`).\n",
    "    * ãƒ•ã‚¡ã‚¤ãƒ«åãŒ `.spdx.json` ã§çµ‚ã‚ã‚‹å ´åˆã¯ã€å„ªå…ˆçš„ã« `SPDX` ã‚¿ã‚¤ãƒ—ã¨ã—ã¦åˆ†é¡ã—ã¾ã™.\n",
    "    * ã©ã®ã‚«ãƒ†ã‚´ãƒªã«ã‚‚ä¸€è‡´ã—ãªã„æ‹¡å¼µå­ã¯ã€æ±ç”¨çš„ãª `OTHER` ã‚¿ã‚¤ãƒ—ã¨ã—ã¦åˆ†é¡ã•ã‚Œã¾ã™.\n",
    "\n",
    "3.  **`fileTypes`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®è¿½åŠ **:\n",
    "    * åˆ¤å®šã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã‚’ã€å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ³ãƒˆãƒªã«`fileTypes`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¨ã—ã¦è¿½åŠ ã€ã¾ãŸã¯æ›´æ–°ã—ã¾ã™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ceddece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting: Adding 'fileTypes' and annotations to 'combined_sbom.json' ---\n",
      "--------------------------------------------------\n",
      "â–¶ï¸  Processing: python-template-project\n",
      "   Added 'Tool: sbom-merge-script' to creators list.\n",
      "   Updated 'spdxVersion' to 'SPDX-2.3'.\n",
      "\n",
      "   --- Summary of Changes (File Types & Version) ---\n",
      "   - File types added/updated: 4\n",
      "   - Script added to creators: 1\n",
      "   - Merge annotations added: 4\n",
      "   ------------------------------------------\n",
      "   Total changes: 9. Saving file...\n",
      "âœ… Successfully saved and reordered 'combined_sbom.json'.\n",
      "--------------------------------------------------\n",
      "\n",
      "Writing/Appending merge summary to 'generated_sboms/merge_summary.csv'...\n",
      "âœ… CSV summary saved successfully.\n",
      "All processes finished.\n"
     ]
    }
   ],
   "source": [
    "# --- è¨­å®šé …ç›® ---\n",
    "target_directory = 'generated_sboms'\n",
    "target_filename = 'combined_sbom.json'\n",
    "# å…¨ã¦ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§å…±é€šã®CSVã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«å\n",
    "csv_output_filename = 'merge_summary.csv'\n",
    "\n",
    "# --- æ‹¡å¼µå­ã¨SPDX FileTypeã®ãƒãƒƒãƒ”ãƒ³ã‚° ---\n",
    "EXTENSION_TO_FILE_TYPE = {\n",
    "    # SOURCE: äººé–“ãŒèª­ã‚ã‚‹ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰\n",
    "    '.c': 'SOURCE', '.cpp': 'SOURCE', '.h': 'SOURCE', '.cs': 'SOURCE', \n",
    "    '.java': 'SOURCE', '.py': 'SOURCE', '.js': 'SOURCE', '.ts': 'SOURCE',\n",
    "    '.go': 'SOURCE', '.rs': 'SOURCE', '.rb': 'SOURCE', '.sh': 'SOURCE', \n",
    "    '.html': 'SOURCE', '.css': 'SOURCE',\n",
    "\n",
    "    # BINARY: ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚„å®Ÿè¡Œå¯èƒ½ãƒ•ã‚¡ã‚¤ãƒ«\n",
    "    '.o': 'BINARY', '.a': 'BINARY', '.exe': 'BINARY', '.dll': 'BINARY', \n",
    "    '.so': 'BINARY', '.bin': 'BINARY',\n",
    "\n",
    "    # ARCHIVE: ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ•ã‚¡ã‚¤ãƒ«\n",
    "    '.tar': 'ARCHIVE', '.jar': 'ARCHIVE', '.zip': 'ARCHIVE', '.gz': 'ARCHIVE',\n",
    "    '.whl': 'ARCHIVE',\n",
    "\n",
    "    # IMAGE: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«\n",
    "    '.jpg': 'IMAGE', '.jpeg': 'IMAGE', '.png': 'IMAGE', '.gif': 'IMAGE', \n",
    "    '.svg': 'IMAGE',\n",
    "\n",
    "    # TEXT: äººé–“ãŒèª­ã‚ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«\n",
    "    '.txt': 'TEXT',\n",
    "\n",
    "    # AUDIO: ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ã‚¡ã‚¤ãƒ«\n",
    "    '.mp3': 'AUDIO', '.wav': 'AUDIO', '.ogg': 'AUDIO', '.flac': 'AUDIO',\n",
    "\n",
    "    # VIDEO: ãƒ“ãƒ‡ã‚ªãƒ•ã‚¡ã‚¤ãƒ«\n",
    "    '.mp4': 'VIDEO', '.mov': 'VIDEO', '.avi': 'VIDEO', '.mkv': 'VIDEO',\n",
    "\n",
    "    # DOCUMENTATION: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«\n",
    "    '.md': 'DOCUMENTATION', '.rst': 'DOCUMENTATION', '.pdf': 'DOCUMENTATION',\n",
    "    '.doc': 'DOCUMENTATION', '.docx': 'DOCUMENTATION',\n",
    "}\n",
    "\n",
    "# --- å‡¦ç†ã®é–‹å§‹ ---\n",
    "print(f\"--- Starting: Adding 'fileTypes' and annotations to '{target_filename}' ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- CSVå‡ºåŠ›ç”¨ã®è¨­å®š ---\n",
    "all_changes_data = []\n",
    "csv_output_path = os.path.join(target_directory, csv_output_filename)\n",
    "# (CSV_FIELDNAMESã¯å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ)\n",
    "\n",
    "try:\n",
    "    repo_dirs = [d for d in os.listdir(target_directory) if os.path.isdir(os.path.join(target_directory, d))]\n",
    "    if not repo_dirs:\n",
    "        print(f\"No repository directories found in '{target_directory}'.\")\n",
    "\n",
    "    for repo_name in repo_dirs:\n",
    "        print(f\"â–¶ï¸  Processing: {repo_name}\")\n",
    "        sbom_path = os.path.join(target_directory, repo_name, target_filename)\n",
    "\n",
    "        if not os.path.exists(sbom_path):\n",
    "            print(f\"âš ï¸ Warning: '{target_filename}' not found. Skipping.\")\n",
    "            print(\"-\" * 50)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            with open(sbom_path, 'r', encoding='utf-8') as f:\n",
    "                sbom_data = json.load(f)\n",
    "\n",
    "            if 'files' not in sbom_data or not sbom_data['files']:\n",
    "                print(\"   No 'files' section found to update. Skipping.\")\n",
    "                print(\"-\" * 50)\n",
    "                continue\n",
    "            \n",
    "            # --- å¤‰æ›´é …ç›®ã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹ãŸã‚ã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’è¾æ›¸ã¨ã—ã¦åˆæœŸåŒ– ---\n",
    "            counts = {field: 0 for field in CSV_FIELDNAMES if field not in ['repository', 'source_tool']}\n",
    "            \n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—1: creatorsãƒªã‚¹ãƒˆã«ã‚¹ã‚¯ãƒªãƒ—ãƒˆæƒ…å ±ã‚’è¿½åŠ  ---\n",
    "            script_creator_string = \"Tool: sbom-merge-script\"\n",
    "            creators_list = sbom_data.setdefault('creationInfo', {}).setdefault('creators', [])\n",
    "            \n",
    "            if script_creator_string not in creators_list:\n",
    "                creators_list.append(script_creator_string)\n",
    "                counts['creators_added'] = 1 # è¾æ›¸ã®å€¤ã‚’æ›´æ–°\n",
    "                print(f\"   Added '{script_creator_string}' to creators list.\")\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—2: spdxVersionã®æ›´æ–° ---\n",
    "            # primaryPackagePurpose (Trivyç”±æ¥) ã®ãŸã‚ã«ã€SPDX-2.3ã«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä¸Šã’ã‚‹\n",
    "            sbom_data['spdxVersion'] = 'SPDX-2.3'\n",
    "            print(f\"   Updated 'spdxVersion' to 'SPDX-2.3'.\")\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—3: fileTypesã®è¿½åŠ ã¨æ³¨é‡ˆ ---\n",
    "            for file_entry in sbom_data['files']:\n",
    "                filename = file_entry.get('fileName')\n",
    "                if not filename:\n",
    "                    continue\n",
    "\n",
    "                if filename.lower().endswith('.spdx.json'):\n",
    "                    file_type = 'SPDX'\n",
    "                else:\n",
    "                    _, extension = os.path.splitext(filename)\n",
    "                    file_type = EXTENSION_TO_FILE_TYPE.get(extension.lower(), 'OTHER')\n",
    "                \n",
    "                if file_entry.get('fileTypes') != [file_type]:\n",
    "                    file_entry['fileTypes'] = [file_type]\n",
    "                    counts['file_types_added'] += 1 # è¾æ›¸ã®å€¤ã‚’æ›´æ–°\n",
    "                    \n",
    "                    annotation = {\n",
    "                        \"annotationDate\": datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "                        \"annotationType\": \"OTHER\",\n",
    "                        \"annotator\": \"Tool: sbom-merge-script\", \n",
    "                        \"comment\": \"Field (fileTypes) was added/updated based on file extension.\"\n",
    "                    }\n",
    "                    file_entry.setdefault('annotations', []).append(annotation)\n",
    "                    counts['merge_annotations_added'] += 1 # æ³¨é‡ˆã®è¿½åŠ ã‚’ã‚«ã‚¦ãƒ³ãƒˆ\n",
    "\n",
    "            # --- ã‚¹ãƒ†ãƒƒãƒ—4: å¤‰æ›´ã‚µãƒãƒªãƒ¼ã®é›†è¨ˆã¨ä¿å­˜ ---\n",
    "            total_changes = sum(counts.values())\n",
    "\n",
    "            if total_changes > 0:\n",
    "                print(f\"\\n   --- Summary of Changes (File Types & Version) ---\")\n",
    "                if counts['file_types_added'] > 0: print(f\"   - File types added/updated: {counts['file_types_added']}\")\n",
    "                if counts['creators_added'] > 0: print(f\"   - Script added to creators: {counts['creators_added']}\")\n",
    "                if counts['merge_annotations_added'] > 0: print(f\"   - Merge annotations added: {counts['merge_annotations_added']}\")\n",
    "                print(f\"   ------------------------------------------\\n   Total changes: {total_changes}. Saving file...\")\n",
    "                \n",
    "                # CSVãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¦ã€ã‚µãƒãƒªãƒ¼è¾æ›¸ã‚’ä½œæˆ\n",
    "                counts['total_changes'] = total_changes\n",
    "                repo_summary = create_summary_dict(\n",
    "                    repo_name=repo_name,\n",
    "                    source_tool='sbom-merge-script', # ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æƒ…å ±æºã‚’æ˜è¨˜.\n",
    "                    counts=counts\n",
    "                )\n",
    "                all_changes_data.append(repo_summary)\n",
    "                \n",
    "                # JSONä¿å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¦ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜\n",
    "                save_sbom_json(sbom_data, sbom_path)\n",
    "            else:\n",
    "                print(\"   No changes needed.\")\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"âŒ Error: Could not parse JSON file. Details: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ An unexpected error occurred: {e}\")\n",
    "        finally:\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: The directory '{target_directory}' was not found.\")\n",
    "\n",
    "# --- ã‚¹ãƒ†ãƒƒãƒ—5: ç·åˆã‚µãƒãƒªãƒ¼ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãå‡ºã™ ---\n",
    "write_summary_to_csv(\n",
    "    all_changes_data,\n",
    "    csv_output_path\n",
    ")\n",
    "\n",
    "print(\"All processes finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
