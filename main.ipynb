{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f6ae47d",
   "metadata": {},
   "source": [
    "# Step 0: 環境構築とライブラリのインポート\n",
    "\n",
    "このノートブック全体の処理を実行するために必要な,すべてのPythonライブラリをインストールし,インポートします.\n",
    "\n",
    "### \\#\\# 実行内容 ⚙️\n",
    "\n",
    "1.  **ライブラリの一括インストール**:\n",
    "\n",
    "      * `!pip install -r requirements.txt` コマンドが,`requirements.txt`に記載されたすべてのライブラリを一度にインストールします.\n",
    "\n",
    "2.  **ライブラリのインポート**:\n",
    "\n",
    "      * インストールしたライブラリや,Pythonに標準で組み込まれているライブラリ（`os`, `json`など）を,このノートブックのメモリに読み込み,後続のセルで使えるようにします."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30528b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: asttokens==3.0.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: certifi==2025.10.5 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (2025.10.5)\n",
      "Requirement already satisfied: charset-normalizer==3.4.4 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (3.4.4)\n",
      "Requirement already satisfied: comm==0.2.3 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (0.2.3)\n",
      "Requirement already satisfied: debugpy==1.8.17 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 5)) (1.8.17)\n",
      "Requirement already satisfied: decorator==5.2.1 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 6)) (5.2.1)\n",
      "Requirement already satisfied: executing==2.2.1 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 7)) (2.2.1)\n",
      "Requirement already satisfied: idna==3.11 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 8)) (3.11)\n",
      "Requirement already satisfied: ipykernel==7.0.1 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 9)) (7.0.1)\n",
      "Requirement already satisfied: ipython==9.6.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 10)) (9.6.0)\n",
      "Requirement already satisfied: ipython_pygments_lexers==1.1.1 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 11)) (1.1.1)\n",
      "Requirement already satisfied: jedi==0.19.2 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 12)) (0.19.2)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 13)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.9.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 14)) (5.9.0)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 15)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 16)) (1.6.0)\n",
      "Requirement already satisfied: packaging==25.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 17)) (25.0)\n",
      "Requirement already satisfied: parso==0.8.5 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 18)) (0.8.5)\n",
      "Requirement already satisfied: pexpect==4.9.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 19)) (4.9.0)\n",
      "Requirement already satisfied: platformdirs==4.5.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 20)) (4.5.0)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.52 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 21)) (3.0.52)\n",
      "Requirement already satisfied: psutil==7.1.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 22)) (7.1.0)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 23)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 24)) (0.2.3)\n",
      "Requirement already satisfied: Pygments==2.19.2 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 25)) (2.19.2)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 26)) (2.9.0.post0)\n",
      "Requirement already satisfied: pyzmq==27.1.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 27)) (27.1.0)\n",
      "Requirement already satisfied: requests==2.32.5 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 28)) (2.32.5)\n",
      "Requirement already satisfied: six==1.17.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 29)) (1.17.0)\n",
      "Requirement already satisfied: stack-data==0.6.3 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 30)) (0.6.3)\n",
      "Requirement already satisfied: tornado==6.5.2 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 31)) (6.5.2)\n",
      "Requirement already satisfied: traitlets==5.14.3 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 32)) (5.14.3)\n",
      "Requirement already satisfied: urllib3==2.5.0 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 33)) (2.5.0)\n",
      "Requirement already satisfied: wcwidth==0.2.14 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 34)) (0.2.14)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179314c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ef483a",
   "metadata": {},
   "source": [
    "# Step 1: リポジトリのクローン\n",
    "\n",
    "このノートブックの最初のステップとして. SBOMの分析対象となる複数のGitリポジトリを自動的にクローンします.\n",
    "\n",
    "### \\#\\# 事前準備 📝\n",
    "\n",
    "**`url_list.txt`** という名前のファイルをこのノートブックと同じ階層に作成してください.\n",
    "ファイルの中には. クローンしたいリポジトリのURLを1行に1つずつ記述します.\n",
    "\n",
    "**`url_list.txt` の記述例:**\n",
    "\n",
    "```\n",
    "https://github.com/user1/repo1.git\n",
    "https://github.com/user2/repo2.git\n",
    "https://github.com/user3/another-repo.git\n",
    "```\n",
    "\n",
    "### \\#\\# 実行内容 ⚙️\n",
    "\n",
    "以下のコードは. `url_list.txt` を読み込み. 各URLに対して `git clone` コマンドを実行します.\n",
    "\n",
    "  * クローンされたリポジトリは. **`cloned_repositories`** ディレクトリ内に保存されます.\n",
    "  * 既に同名のリポジトリが存在する場合は. 時間短縮のためクローン処理をスキップします.\n",
    "  * クローンの進捗状況はリアルタイムで表示されます."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5600567f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting: Cloning repositories ---\n",
      "--------------------------------------------------\n",
      "Cloning: https://github.com/MoriwakiYusuke/sbom-python-test.git\n",
      "✅ Clone successful.                                                             \n",
      "   Searching and removing hidden directories in 'sbom-python-test'...\n",
      "   🗑️ Removed: cloned_repositories/sbom-python-test/.git\n",
      "   ✅ Hidden directories removed.\n",
      "--------------------------------------------------\n",
      "Cloning: https://github.com/MoriwakiYusuke/sbom-go-test.git\n",
      "✅ Clone successful.                                                             \n",
      "   Searching and removing hidden directories in 'sbom-go-test'...\n",
      "   🗑️ Removed: cloned_repositories/sbom-go-test/.git\n",
      "   ✅ Hidden directories removed.\n",
      "--------------------------------------------------\n",
      "Cloning: https://github.com/TheAlgorithms/Python.git\n",
      "✅ Clone successful.                                                             )\n",
      "   Searching and removing hidden directories in 'Python'...\n",
      "   🗑️ Removed: cloned_repositories/Python/.devcontainer\n",
      "   🗑️ Removed: cloned_repositories/Python/.github\n",
      "   🗑️ Removed: cloned_repositories/Python/.vscode\n",
      "   🗑️ Removed: cloned_repositories/Python/.git\n",
      "   ✅ Hidden directories removed.\n",
      "--------------------------------------------------\n",
      "Cloning: https://github.com/Python-World/python-mini-projects.git\n",
      "✅ Clone successful.                                                             \n",
      "   Searching and removing hidden directories in 'python-mini-projects'...\n",
      "   🗑️ Removed: cloned_repositories/python-mini-projects/.github\n",
      "   🗑️ Removed: cloned_repositories/python-mini-projects/.git\n",
      "   ✅ Hidden directories removed.\n",
      "--------------------------------------------------\n",
      "Clone process finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "# --- 設定項目 ---\n",
    "# クローン対象のリポジトリURLリストファイル\n",
    "url_file_path = 'url_list.txt'\n",
    "# リポジトリのクローン先ディレクトリ\n",
    "clone_to_directory = 'cloned_repositories'\n",
    "\n",
    "# --- 処理の開始 ---\n",
    "print(f\"--- Starting: Cloning repositories ---\")\n",
    "\n",
    "# 保存先ディレクトリを作成する\n",
    "os.makedirs(clone_to_directory, exist_ok=True)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# URLリストファイルを読み込む\n",
    "try:\n",
    "    with open(url_file_path, 'r') as file:\n",
    "        # 空行を除外してリスト化する\n",
    "        urls = [line.strip() for line in file.readlines() if line.strip()]\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: '{url_file_path}' was not found.\")\n",
    "    urls = []\n",
    "\n",
    "for repo_url in urls:\n",
    "    # --- 既存リポジトリのスキップ処理 ---\n",
    "    repo_name = repo_url.split('/')[-1].replace('.git', '')\n",
    "    repo_path = os.path.join(clone_to_directory, repo_name)\n",
    "    \n",
    "    if os.path.isdir(repo_path):\n",
    "        print(f\"🟢 Skipping: {repo_name} (Directory already exists)\")\n",
    "        print(\"-\" * 50)\n",
    "        continue\n",
    "\n",
    "    print(f\"Cloning: {repo_url}\")\n",
    "    try:\n",
    "        # git cloneプロセスを開始\n",
    "        process = subprocess.Popen(\n",
    "            ['git', 'clone', '--progress', repo_url],\n",
    "            cwd=clone_to_directory,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "            encoding='utf-8',\n",
    "            errors='replace'\n",
    "        )\n",
    "\n",
    "        # 標準エラーをリアルタイムで表示\n",
    "        while process.poll() is None:\n",
    "            line = process.stderr.readline()\n",
    "            if line:\n",
    "                print(f\"   {line.strip()}\", end='\\r')\n",
    "        \n",
    "        print(\" \" * 80, end=\"\\r\") # 進捗表示行をクリア\n",
    "\n",
    "        if process.returncode == 0:\n",
    "            print(\"✅ Clone successful.\")\n",
    "\n",
    "            print(f\"   Searching and removing hidden directories in '{repo_name}'...\")\n",
    "            \n",
    "            # クローンしたリポジトリ内を再帰的に探索\n",
    "            for root, dirs, files in os.walk(repo_path):\n",
    "                # .で始まるディレクトリをリストアップして削除\n",
    "                hidden_dirs = [d for d in dirs if d.startswith('.')]\n",
    "                for d_name in hidden_dirs:\n",
    "                    dir_to_remove = os.path.join(root, d_name)\n",
    "                    try:\n",
    "                        shutil.rmtree(dir_to_remove)\n",
    "                        print(f\"   🗑️ Removed: {dir_to_remove}\")\n",
    "                    except OSError as e:\n",
    "                        print(f\"   ❌ Error removing {dir_to_remove}: {e}\")\n",
    "                \n",
    "                # dirsリストから削除したものを除外し、それ以上深く探索しないようにする\n",
    "                dirs[:] = [d for d in dirs if not d.startswith('.')]\n",
    "            \n",
    "            print(\"   ✅ Hidden directories removed.\")\n",
    "\n",
    "        else:\n",
    "            # エラー内容を取得して表示\n",
    "            stdout_err, stderr_err = process.communicate()\n",
    "            error_message = stderr_err if stderr_err else stdout_err\n",
    "            print(f\"❌ Error cloning. Reason: {error_message.strip()}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ Error: 'git' command not found. Please install Git and ensure it is in your system's PATH.\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "print(\"Clone process finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bc9665",
   "metadata": {},
   "source": [
    "# Step 2: SBOMの生成 (sbom-tool)\n",
    "\n",
    "前のステップでクローンした各リポジトリに対して,Microsoftの **`sbom-tool`** を使用してベースとなるSBOMを生成します.このツールは,リポジトリ内の全ファイルをスキャンし,ハッシュ値を含む詳細なファイル情報を取得することに優れています.\n",
    "\n",
    "### ## 事前準備 📝\n",
    "\n",
    "* **`sbom-tool`** がシステムにインストールされ,PATHが通っている必要があります.\n",
    "* Step 1が完了しており,**`cloned_repositories`** ディレクトリ内に分析対象のリポジトリが存在している必要があります.\n",
    "\n",
    "### ## 実行内容 ⚙️\n",
    "\n",
    "以下のコードは,`cloned_repositories`内の各リポジトリを巡回し,以下の処理を自動的に実行します.\n",
    "\n",
    "1.  **パラメータの自動取得**:\n",
    "    * `git`コマンドを実行し,現在のコミットハッシュを **`packageVersion`** として取得します.\n",
    "    * `.git/config`ファイルを解析し,リポジトリの所有者（OrganizationまたはUser）を **`packageSupplier`** として自動で設定します.\n",
    "\n",
    "2.  **`sbom-tool` の実行**:\n",
    "    * 取得したパラメータ（パッケージ名,バージョン,サプライヤー）を使って`sbom-tool generate`コマンドを動的に構築し,実行します.\n",
    "    * これにより,各リポジトリのルートに **`_manifest`** ディレクトリが生成されます.\n",
    "\n",
    "3.  **成果物の移動**:\n",
    "    * 生成された`_manifest`ディレクトリを,後続の処理で扱いやすいように **`generated_sboms/<リポジトリ名>/source/`** ディレクトリ内に移動します.\n",
    "\n",
    "すでに成果物が存在する場合,この処理はスキップされます."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eeaebc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting: Generating SBOMs with sbom-tool\n",
      "--------------------------------------------------\n",
      "🟢 Skipping: sbom-python-test (SBOM manifest already exists)\n",
      "--------------------------------------------------\n",
      "🟢 Skipping: Python (SBOM manifest already exists)\n",
      "--------------------------------------------------\n",
      "🟢 Skipping: python-mini-projects (SBOM manifest already exists)\n",
      "--------------------------------------------------\n",
      "🟢 Skipping: sbom-go-test (SBOM manifest already exists)\n",
      "--------------------------------------------------\n",
      "All processes finished.\n"
     ]
    }
   ],
   "source": [
    "# --- 設定項目 ---\n",
    "clone_to_directory = 'cloned_repositories'\n",
    "sbom_output_directory = 'generated_sboms'\n",
    "url_file_path = 'url_list.txt'\n",
    "\n",
    "# --- 処理の開始 ---\n",
    "print(f\"--- Starting: Generating SBOMs with sbom-tool\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "original_path = os.getcwd()\n",
    "os.makedirs(sbom_output_directory, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # --- url_list.txtからリポジトリ名と提供者のマップを作成 ---\n",
    "    repo_to_supplier_map = {}\n",
    "    try:\n",
    "        with open(url_file_path, 'r') as file:\n",
    "            urls = [line.strip() for line in file.readlines() if line.strip()]\n",
    "            for url in urls:\n",
    "                # URLから所有者とリポジトリ名を抽出\n",
    "                match = re.search(r\"github\\.com/([^/]+)/([^/.]+)\", url)\n",
    "                if match:\n",
    "                    owner, repo = match.groups()\n",
    "                    repo_name_from_url = repo.replace('.git', '')\n",
    "                    repo_to_supplier_map[repo_name_from_url] = owner\n",
    "    except FileNotFoundError:\n",
    "        print(f\"⚠️ Warning: '{url_file_path}' not found. 'PackageSupplier' will default to 'Unknown'.\")\n",
    "\n",
    "    # --- メイン処理 ---\n",
    "    repo_dirs = [d for d in os.listdir(clone_to_directory) if os.path.isdir(os.path.join(clone_to_directory, d))]\n",
    "    \n",
    "    if not repo_dirs:\n",
    "        print(\"No repositories found to run commands on.\")\n",
    "\n",
    "    for repo_name in repo_dirs:\n",
    "        final_repo_dir = os.path.join(original_path, sbom_output_directory, repo_name)\n",
    "        final_manifest_path = os.path.join(final_repo_dir, 'source', '_manifest')\n",
    "\n",
    "        if os.path.isdir(final_manifest_path):\n",
    "            print(f\"🟢 Skipping: {repo_name} (SBOM manifest already exists)\")\n",
    "            print(\"-\" * 50)\n",
    "            continue\n",
    "\n",
    "        repo_path = os.path.join(clone_to_directory, repo_name)\n",
    "        print(f\"▶️  Entering: {repo_name}\")\n",
    "        \n",
    "        try:\n",
    "            # --- パラメータ設定 ---\n",
    "            package_name = repo_name\n",
    "            # マップからサプライヤー情報を取得\n",
    "            package_supplier = repo_to_supplier_map.get(repo_name, \"Unknown\")\n",
    "            \n",
    "            print(f\"   Package Name: {package_name}\")\n",
    "            print(f\"   Package Supplier: {package_supplier}\")\n",
    "            \n",
    "            manifest_in_repo_path = os.path.join(repo_path, '_manifest')\n",
    "            if os.path.isdir(manifest_in_repo_path):\n",
    "                print(\"   Found existing '_manifest' directory. Removing it.\")\n",
    "                shutil.rmtree(manifest_in_repo_path)\n",
    "\n",
    "            # --- sbom-tool実行---\n",
    "            command = [\n",
    "                'sbom-tool', 'generate', \n",
    "                '-bc', repo_path,\n",
    "                '-b', repo_path,\n",
    "                '-pn', package_name, \n",
    "                '-ps', package_supplier,\n",
    "                '-m', repo_path,\n",
    "                '-pv', 'latest'\n",
    "            ]\n",
    "            print(f\"   Executing: {' '.join(command)}\")\n",
    "            subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "            print(\"✅ SBOM generation successful.\")\n",
    "\n",
    "            # --- 移動処理 ---\n",
    "            source_manifest_path = manifest_in_repo_path\n",
    "            \n",
    "            if os.path.isdir(source_manifest_path):\n",
    "                destination_dir = os.path.join(final_repo_dir, 'source')\n",
    "                os.makedirs(destination_dir, exist_ok=True)\n",
    "                \n",
    "                print(f\"   Moving '{source_manifest_path}' into: {destination_dir}\")\n",
    "                shutil.move(source_manifest_path, final_manifest_path)\n",
    "                print(\"✅ Move successful.\")\n",
    "            else:\n",
    "                print(f\"⚠️ Warning: Could not find generated manifest directory at '{source_manifest_path}'\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"❌ Error: The command 'sbom-tool' was not found.\")\n",
    "            break\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"❌ Error executing command in {repo_name}.\")\n",
    "            if e.stderr:\n",
    "                print(f\"   [stderr]:\\n{e.stderr.strip()}\")\n",
    "        finally:\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: The directory '{clone_to_directory}' was not found.\")\n",
    "\n",
    "print(\"All processes finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5f0d61",
   "metadata": {},
   "source": [
    "# Step 3: SBOMの生成 (Syft)\n",
    "\n",
    "`Step 1`でクローンした各リポジトリに対し,**`syft`** を使用してSBOMを生成します.`syft`は,`requirements.txt`やGitHub Actionsのワークフローファイルなど,様々なパッケージマニフェストから依存関係を検出することに優れています.\n",
    "\n",
    "### ## 事前準備 📝\n",
    "\n",
    "* **`syft`** がシステムにインストールされ,PATHが通っている必要があります.\n",
    "* Step 1が完了しており,**`cloned_repositories`** ディレクトリ内に分析対象のリポジトリが存在している必要があります.\n",
    "\n",
    "### ## 実行内容 ⚙️\n",
    "\n",
    "以下のコードは,`cloned_repositories`内の各リポジトリを巡回し,以下の処理を自動的に実行します.\n",
    "\n",
    "1.  **`syft` の実行**:\n",
    "    * 各リポジトリのディレクトリに移動し,`syft dir:./ -o spdx-json`コマンドを実行します.\n",
    "    * コマンドの標準出力をキャプチャし,リポジトリ内に`syft-sbom.json`という名前の一時ファイルとして保存します.\n",
    "\n",
    "2.  **成果物の移動**:\n",
    "    * 生成された`syft-sbom.json`を,後続の処理で扱いやすいように **`generated_sboms/<リポジトリ名>/source/`** ディレクトリ内に移動します.\n",
    "\n",
    "すでに`syft-sbom.json`が最終的な保存先に存在する場合,そのリポジトリの処理はスキップされます."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff455b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting: Generating SBOMs with Syft ---\n",
      "--------------------------------------------------\n",
      "▶️  Entering: sbom-python-test\n",
      "   Executing: syft dir:./ -o spdx-json > syft-sbom.json\n",
      "✅ Syft execution successful.\n",
      "   Moving SBOM to: /home/moriwaki-y/ritsumei/sbom/auto-datasets-make/generated_sboms/sbom-python-test/source/syft-sbom.json\n",
      "✅ SBOM file saved.\n",
      "--------------------------------------------------\n",
      "▶️  Entering: Python\n",
      "   Executing: syft dir:./ -o spdx-json > syft-sbom.json\n",
      "✅ Syft execution successful.\n",
      "   Moving SBOM to: /home/moriwaki-y/ritsumei/sbom/auto-datasets-make/generated_sboms/Python/source/syft-sbom.json\n",
      "✅ SBOM file saved.\n",
      "--------------------------------------------------\n",
      "▶️  Entering: python-mini-projects\n",
      "   Executing: syft dir:./ -o spdx-json > syft-sbom.json\n",
      "✅ Syft execution successful.\n",
      "   Moving SBOM to: /home/moriwaki-y/ritsumei/sbom/auto-datasets-make/generated_sboms/python-mini-projects/source/syft-sbom.json\n",
      "✅ SBOM file saved.\n",
      "--------------------------------------------------\n",
      "▶️  Entering: sbom-go-test\n",
      "   Executing: syft dir:./ -o spdx-json > syft-sbom.json\n",
      "✅ Syft execution successful.\n",
      "   Moving SBOM to: /home/moriwaki-y/ritsumei/sbom/auto-datasets-make/generated_sboms/sbom-go-test/source/syft-sbom.json\n",
      "✅ SBOM file saved.\n",
      "--------------------------------------------------\n",
      "All processes finished.\n"
     ]
    }
   ],
   "source": [
    "# --- 設定項目 ---\n",
    "clone_to_directory = 'cloned_repositories'\n",
    "sbom_output_directory = 'generated_sboms'\n",
    "\n",
    "# --- 処理の開始 ---\n",
    "print(f\"--- Starting: Generating SBOMs with Syft ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 実行前のカレントディレクトリを保存する\n",
    "original_path = os.getcwd()\n",
    "os.makedirs(sbom_output_directory, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # クローンディレクトリ内のリポジトリ一覧を取得する\n",
    "    repo_dirs = [d for d in os.listdir(clone_to_directory) if os.path.isdir(os.path.join(clone_to_directory, d))]\n",
    "    \n",
    "    if not repo_dirs:\n",
    "        print(\"No repositories found to run commands on.\")\n",
    "\n",
    "    for repo_name in repo_dirs:\n",
    "        repo_path = os.path.join(clone_to_directory, repo_name)\n",
    "        \n",
    "        try:\n",
    "            # --- 最終的なファイルパスを定義 ---\n",
    "            destination_dir = os.path.join(original_path, sbom_output_directory, repo_name, 'source')\n",
    "            final_sbom_filename = \"syft-sbom.json\"\n",
    "            final_sbom_path = os.path.join(destination_dir, final_sbom_filename)\n",
    "\n",
    "            # --- 処理をスキップするかの判定 ---\n",
    "            # 既に成果物が存在する場合は処理をスキップする\n",
    "            if os.path.exists(final_sbom_path):\n",
    "                print(f\"🟢 Skipping: {repo_name} (SBOM file already exists)\")\n",
    "                print(\"-\" * 50)\n",
    "                continue\n",
    "\n",
    "            print(f\"▶️  Entering: {repo_name}\")\n",
    "            os.chdir(repo_path)\n",
    "            \n",
    "            # --- syftコマンドの実行 ---\n",
    "            temp_sbom_filename = 'syft-sbom.json'\n",
    "            # 現在のディレクトリをスキャンし,SPDX JSON形式で出力する\n",
    "            command = ['syft', 'dir:./', '-o', 'spdx-json']\n",
    "            print(f\"   Executing: {' '.join(command)} > {temp_sbom_filename}\")\n",
    "            \n",
    "            result = subprocess.run(\n",
    "                command, check=True, capture_output=True, text=True\n",
    "            )\n",
    "            print(\"✅ Syft execution successful.\")\n",
    "\n",
    "            # syftの標準出力を一時ファイルに書き込む\n",
    "            with open(temp_sbom_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(result.stdout)\n",
    "\n",
    "            # --- 一時ファイルを最終的な場所に移動 ---\n",
    "            os.makedirs(destination_dir, exist_ok=True)\n",
    "            print(f\"   Moving SBOM to: {final_sbom_path}\")\n",
    "            shutil.move(temp_sbom_filename, final_sbom_path)\n",
    "            print(\"✅ SBOM file saved.\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"❌ Error: The command 'syft' or was not found.\")\n",
    "            break\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"❌ Error executing command in {repo_name}.\")\n",
    "            if e.stdout:\n",
    "                print(f\"   [stdout]:\\n{e.stdout.strip()}\")\n",
    "            if e.stderr:\n",
    "                print(f\"   [stderr]:\\n{e.stderr.strip()}\")\n",
    "        finally:\n",
    "            # カレントディレクトリを元に戻す\n",
    "            os.chdir(original_path)\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: The directory '{clone_to_directory}' was not found.\")\n",
    "\n",
    "print(\"All processes finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6036a3",
   "metadata": {},
   "source": [
    "# Step 4: SBOMの取得 (GitHub Dependency Graph API)\n",
    "\n",
    "このステップでは,GitHubの **Dependency Graph API** を利用して,各リポジトリのSBOM（Software Bill of Materials）を取得します.このAPIから得られるSBOMは,特に**ライセンス**や**著作権情報**が豊富に含まれているという長所があります.\n",
    "\n",
    "### ## 事前準備 📝\n",
    "\n",
    "* **Dependency Graphの有効化**: 分析対象のリポジトリで,**Dependency Graph**機能が有効になっている必要があります.これは通常,パブリックリポジトリではデフォルトで有効ですが,プライベートリポジトリでは手動での有効化が必要です.（`Settings` > `Code security and analysis`）\n",
    "* **`url_list.txt`**: Step 1で作成した,リポジトリのURLが記載されたファイルが必要です.\n",
    "\n",
    "### ## 実行内容 ⚙️\n",
    "\n",
    "以下のコードは,`url_list.txt`を読み込み,各リポジトリに対して以下の処理を自動的に実行します.\n",
    "\n",
    "1.  **APIリクエスト**:\n",
    "    * URLからリポジトリの所有者と名前を抽出し,適切なAPIエンドポイント（`api.github.com/repos/{owner}/{repo}/dependency-graph/sbom`）を構築します.\n",
    "    * 構築したURLに対して`GET`リクエストを送信し,SBOMデータをJSON形式で取得します.\n",
    "\n",
    "2.  **成果物の保存**:\n",
    "    * APIから正常に取得できたSBOMデータを,**`generated_sboms/<リポジトリ名>/source/dependency-graph-sbom.json`** という名前のファイルとして保存します.\n",
    "\n",
    "既に成果物ファイルが存在する場合,APIへのリクエストを節約するため,そのリポジトリの処理はスキップされます."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6600f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting: Fetching SBOMs from GitHub API (No Token) ---\n",
      "--------------------------------------------------\n",
      "▶️  Fetching SBOM for: MoriwakiYusuke/sbom-python-test\n",
      "✅ API request successful.\n",
      "   Writing SBOM to: /home/moriwaki-y/ritsumei/sbom/auto-datasets-make/generated_sboms/sbom-python-test/source/dependency-graph-sbom.json\n",
      "✅ SBOM file saved.\n",
      "--------------------------------------------------\n",
      "▶️  Fetching SBOM for: MoriwakiYusuke/sbom-go-test\n",
      "✅ API request successful.\n",
      "   Writing SBOM to: /home/moriwaki-y/ritsumei/sbom/auto-datasets-make/generated_sboms/sbom-go-test/source/dependency-graph-sbom.json\n",
      "✅ SBOM file saved.\n",
      "--------------------------------------------------\n",
      "▶️  Fetching SBOM for: TheAlgorithms/Python\n",
      "✅ API request successful.\n",
      "   Writing SBOM to: /home/moriwaki-y/ritsumei/sbom/auto-datasets-make/generated_sboms/Python/source/dependency-graph-sbom.json\n",
      "✅ SBOM file saved.\n",
      "--------------------------------------------------\n",
      "▶️  Fetching SBOM for: Python-World/python-mini-projects\n",
      "✅ API request successful.\n",
      "   Writing SBOM to: /home/moriwaki-y/ritsumei/sbom/auto-datasets-make/generated_sboms/python-mini-projects/source/dependency-graph-sbom.json\n",
      "✅ SBOM file saved.\n",
      "--------------------------------------------------\n",
      "All processes finished.\n"
     ]
    }
   ],
   "source": [
    "# --- 設定項目 ---\n",
    "\n",
    "# 1. GitHubリポジトリのURLリストが書かれたファイル\n",
    "url_file_path = 'url_list.txt'\n",
    "\n",
    "# 2. 生成されたSBOM(JSONファイル)を保存するディレクトリ\n",
    "sbom_output_directory = 'generated_sboms'\n",
    "\n",
    "\n",
    "# --- 処理の開始 ---\n",
    "print(\"--- Starting: Fetching SBOMs from GitHub API (No Token) ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "original_path = os.getcwd()\n",
    "os.makedirs(sbom_output_directory, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    with open(url_file_path, 'r') as file:\n",
    "        urls = [line.strip() for line in file.readlines() if line.strip()]\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: '{url_file_path}' was not found.\")\n",
    "    urls = []\n",
    "\n",
    "for repo_url in urls:\n",
    "    # URLからownerとrepoを抽出\n",
    "    match = re.search(r\"github\\.com/([^/]+)/([^/.]+)\", repo_url)\n",
    "    if not match:\n",
    "        print(f\"⚠️ Warning: Could not parse owner/repo from URL: {repo_url}\")\n",
    "        continue\n",
    "    \n",
    "    owner, repo_name = match.groups()\n",
    "    \n",
    "    # --- 保存先のパスを定義し,スキップ判定 ---\n",
    "    destination_dir = os.path.join(original_path, sbom_output_directory, repo_name, 'source')\n",
    "    final_sbom_path = os.path.join(destination_dir, 'dependency-graph-sbom.json')\n",
    "\n",
    "    if os.path.exists(final_sbom_path):\n",
    "        print(f\"🟢 Skipping: {repo_name} (SBOM file already exists)\")\n",
    "        print(\"-\" * 50)\n",
    "        continue\n",
    "        \n",
    "    print(f\"▶️  Fetching SBOM for: {owner}/{repo_name}\")\n",
    "\n",
    "    # --- GitHub APIへのリクエスト (認証ヘッダーなし) ---\n",
    "    api_url = f\"https://api.github.com/repos/{owner}/{repo_name}/dependency-graph/sbom\"\n",
    "    headers = {\n",
    "        \"Accept\": \"application/vnd.github+json\",\n",
    "        \"X-GitHub-Api-Version\": \"2022-11-28\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(api_url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            print(\"✅ API request successful.\")\n",
    "            sbom_data = response.json().get('sbom')\n",
    "            if not sbom_data:\n",
    "                print(f\"❌ Error: 'sbom' key not found in the API response for {repo_name}.\")\n",
    "                continue\n",
    "\n",
    "            # --- SBOMをファイルに保存 ---\n",
    "            os.makedirs(destination_dir, exist_ok=True)\n",
    "            print(f\"   Writing SBOM to: {final_sbom_path}\")\n",
    "            \n",
    "            with open(final_sbom_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(sbom_data, f, ensure_ascii=False, indent=2)\n",
    "            print(\"✅ SBOM file saved.\")\n",
    "\n",
    "        elif response.status_code == 404:\n",
    "            print(f\"⚠️ Warning: Could not fetch SBOM for {repo_name}. (Status: 404)\")\n",
    "            print(\"   The repository may not exist, or the Dependency Graph may not be enabled.\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"❌ Error: Failed to fetch SBOM for {repo_name}. Status code: {response.status_code}\")\n",
    "            print(f\"   Response: {response.text}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ Error: A network error occurred while contacting the GitHub API.\")\n",
    "        print(f\"   Details: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "print(\"All processes finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b95ab33",
   "metadata": {},
   "source": [
    "# Step 5: SBOMの生成 (Trivy)\n",
    "\n",
    "このステップでは,オープンソースの脆弱性スキャナである **`Trivy`** を使用して,各リポジトリからSBOMを生成します.`Trivy`は,ファイルシステム内のパッケージ依存関係を高速かつ広範囲に検出する能力に優れています.\n",
    "\n",
    "### ## 事前準備 📝\n",
    "\n",
    "* **`Trivy`** がシステムにインストールされ,PATHが通っている必要があります.\n",
    "* Step 1が完了しており,**`cloned_repositories`** ディレクトリ内に分析対象のリポジトリが存在している必要があります.\n",
    "\n",
    "### ## 実行内容 ⚙️\n",
    "\n",
    "以下のコードは,`cloned_repositories`内の各リポジトリを巡回し,以下の処理を自動的に実行します.\n",
    "\n",
    "1.  **`Trivy` の実行**:\n",
    "    * 各リポジトリのディレクトリに移動し,`trivy fs . --format spdx-json --output spdx-json-by-trivy.json` コマンドを実行します.\n",
    "    * これにより,リポジトリ内に`spdx-json-by-trivy.json`という名前でSBOMファイルが直接生成されます.\n",
    "\n",
    "2.  **成果物の移動とリネーム**:\n",
    "    * 生成された`spdx-json-by-trivy.json`を,後続の処理で統一的に扱えるように **`generated_sboms/<リポジトリ名>/source/trivy-sbom.json`** という名前に変更して移動します.\n",
    "\n",
    "すでに`trivy-sbom.json`が最終的な保存先に存在する場合,そのリポジトリの処理はスキップされます."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77d4a25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting: Generating SBOMs with Trivy ---\n",
      "--------------------------------------------------\n",
      "▶️  Entering: sbom-python-test\n",
      "   Executing: trivy fs . --format spdx-json --output spdx-json-by-trivy.json\n",
      "✅ Trivy execution successful.\n",
      "   Moving SBOM to: /home/moriwaki-y/ritsumei/sbom/auto-datasets-make/generated_sboms/sbom-python-test/source/trivy-sbom.json\n",
      "✅ SBOM file saved.\n",
      "--------------------------------------------------\n",
      "▶️  Entering: Python\n",
      "   Executing: trivy fs . --format spdx-json --output spdx-json-by-trivy.json\n",
      "✅ Trivy execution successful.\n",
      "   Moving SBOM to: /home/moriwaki-y/ritsumei/sbom/auto-datasets-make/generated_sboms/Python/source/trivy-sbom.json\n",
      "✅ SBOM file saved.\n",
      "--------------------------------------------------\n",
      "▶️  Entering: python-mini-projects\n",
      "   Executing: trivy fs . --format spdx-json --output spdx-json-by-trivy.json\n",
      "✅ Trivy execution successful.\n",
      "   Moving SBOM to: /home/moriwaki-y/ritsumei/sbom/auto-datasets-make/generated_sboms/python-mini-projects/source/trivy-sbom.json\n",
      "✅ SBOM file saved.\n",
      "--------------------------------------------------\n",
      "▶️  Entering: sbom-go-test\n",
      "   Executing: trivy fs . --format spdx-json --output spdx-json-by-trivy.json\n",
      "✅ Trivy execution successful.\n",
      "   Moving SBOM to: /home/moriwaki-y/ritsumei/sbom/auto-datasets-make/generated_sboms/sbom-go-test/source/trivy-sbom.json\n",
      "✅ SBOM file saved.\n",
      "--------------------------------------------------\n",
      "All processes finished.\n"
     ]
    }
   ],
   "source": [
    "# --- 設定項目 ---\n",
    "\n",
    "# クローンされたリポジトリの保存ディレクトリ\n",
    "clone_to_directory = 'cloned_repositories'\n",
    "# 生成されたSBOMの保存ルートディレクトリ\n",
    "sbom_output_directory = 'generated_sboms'\n",
    "\n",
    "# --- 処理の開始 ---\n",
    "# Trivyを使ったSBOM生成処理開始メッセージを表示\n",
    "print(f\"--- Starting: Generating SBOMs with Trivy ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 現在の作業ディレクトリを保存\n",
    "original_path = os.getcwd()\n",
    "# SBOM出力ディレクトリが存在しない場合は作成\n",
    "os.makedirs(sbom_output_directory, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # クローンディレクトリ内のリポジトリ一覧を取得\n",
    "    repo_dirs = [d for d in os.listdir(clone_to_directory) if os.path.isdir(os.path.join(clone_to_directory, d))]\n",
    "    \n",
    "    if not repo_dirs:\n",
    "        print(\"No repositories found to run commands on.\")\n",
    "\n",
    "    # 各リポジトリに対してTrivyを使ったSBOM生成処理を実行\n",
    "    for repo_name in repo_dirs:\n",
    "        repo_path = os.path.join(clone_to_directory, repo_name)\n",
    "        \n",
    "        try:\n",
    "            # --- 最終的なファイルパスを定義 ---\n",
    "            # SBOMの最終的な保存先ディレクトリを構築\n",
    "            destination_dir = os.path.join(original_path, sbom_output_directory, repo_name, 'source')\n",
    "            \n",
    "            # 生成されるSBOMのファイル名を 'trivy-sbom.json' に固定\n",
    "            final_sbom_filename = \"trivy-sbom.json\"\n",
    "            \n",
    "            # 最終的なSBOMファイルのフルパスを構築\n",
    "            final_sbom_path = os.path.join(destination_dir, final_sbom_filename)\n",
    "\n",
    "            # --- 処理をスキップするかの判定 ---\n",
    "            # 既にSBOMファイルが存在する場合はスキップ\n",
    "            if os.path.exists(final_sbom_path):\n",
    "                print(f\"🟢 Skipping: {repo_name} (SBOM file already exists)\")\n",
    "                print(\"-\" * 50)\n",
    "                continue\n",
    "\n",
    "            # --- ここからリポジトリ内での処理 ---\n",
    "            print(f\"▶️  Entering: {repo_name}\")\n",
    "            # カレントディレクトリをリポジトリのパスに変更\n",
    "            os.chdir(repo_path)\n",
    "            \n",
    "            # --- trivyコマンドの実行 ---\n",
    "            # trivyが出力する一時ファイル名を定義\n",
    "            temp_sbom_filename = 'spdx-json-by-trivy.json'\n",
    "            # trivyコマンドを構築\n",
    "            command = ['trivy', 'fs', '.', '--format', 'spdx-json', '--output', temp_sbom_filename]\n",
    "            print(f\"   Executing: {' '.join(command)}\")\n",
    "            \n",
    "            # trivyコマンドを実行\n",
    "            # Trivyはファイルに直接出力するため,出力のキャプチャは不要\n",
    "            subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "            print(\"✅ Trivy execution successful.\")\n",
    "\n",
    "            # --- 一時ファイルを最終的な場所に移動 ---\n",
    "            # 最終的な保存先ディレクトリが存在しない場合は作成\n",
    "            os.makedirs(destination_dir, exist_ok=True)\n",
    "            print(f\"   Moving SBOM to: {final_sbom_path}\")\n",
    "            # 一時ファイルを最終的な保存先にリネームしながら移動\n",
    "            shutil.move(temp_sbom_filename, final_sbom_path)\n",
    "            print(\"✅ SBOM file saved.\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            # 'trivy'コマンドが見つからない場合のエラー処理\n",
    "            print(f\"❌ Error: The command 'trivy' was not found.\")\n",
    "            break\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            # コマンド実行中にエラーが発生した場合の処理\n",
    "            print(f\"❌ Error executing command in {repo_name}.\")\n",
    "            if e.stdout:\n",
    "                print(f\"   [stdout]:\\n{e.stdout.strip()}\")\n",
    "            if e.stderr:\n",
    "                print(f\"   [stderr]:\\n{e.stderr.strip()}\")\n",
    "        finally:\n",
    "            # カレントディレクトリを元のパスに戻す\n",
    "            os.chdir(original_path)\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    # クローンディレクトリが見つからない場合のエラー処理\n",
    "    print(f\"❌ Error: The directory '{clone_to_directory}' was not found.\")\n",
    "\n",
    "# 全てのTrivyを使ったSBOM生成処理が完了\n",
    "print(\"All processes finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1539950b",
   "metadata": {},
   "source": [
    "# Step 6: ベースSBOMの作成と整形\n",
    "\n",
    "このステップでは,`Step 2`で`sbom-tool`が出力した`manifest.spdx.json`をコピーし,後続の処理の基礎となる **`combined_sbom.json`** を作成します.同時に,JSONファイルのトップレベルのキーの順序を統一することで,ファイルの一貫性を保ちます.\n",
    "\n",
    "### ## 事前準備 📝\n",
    "\n",
    "* `Step 2`の`sbom-tool`によるSBOM生成が完了している必要があります.\n",
    "* **`generated_sboms/<リポジトリ名>/source/_manifest`** ディレクトリ内に,`manifest.spdx.json`が存在している必要があります.\n",
    "\n",
    "### ## 実行内容 ⚙️\n",
    "\n",
    "以下のコードは,`generated_sboms`内の各リポジトリを巡回し,以下の処理を自動的に実行します.\n",
    "\n",
    "1.  `source/_manifest/spdx_2.2/manifest.spdx.json` を **`combined_sbom.json`** として各リポジトリのルートにコピーします.\n",
    "2.  コピー直後に`combined_sbom.json`を再度開き,定義された`key_order`リストの順序に従ってキーを並び替えます.\n",
    "3.  並び替えた内容でファイルを上書き保存します."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04a2e5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting: Copying and reordering SBOMs ---\n",
      "--------------------------------------------------\n",
      "▶️  Processing: sbom-python-test\n",
      "   Copying sbom-tool's output to 'combined_sbom.json'...\n",
      "   ✅ Copy successful.\n",
      "   Reordering keys...\n",
      "   ✅ Keys reordered and saved.\n",
      "--------------------------------------------------\n",
      "▶️  Processing: Python\n",
      "🟢 Skipping: 'combined_sbom.json' already exists.\n",
      "--------------------------------------------------\n",
      "▶️  Processing: python-mini-projects\n",
      "🟢 Skipping: 'combined_sbom.json' already exists.\n",
      "--------------------------------------------------\n",
      "▶️  Processing: sbom-go-test\n",
      "🟢 Skipping: 'combined_sbom.json' already exists.\n",
      "--------------------------------------------------\n",
      "All processes finished.\n"
     ]
    }
   ],
   "source": [
    "# --- 設定項目 ---\n",
    "\n",
    "# 1. 処理対象の親ディレクトリ\n",
    "target_directory = 'generated_sboms'\n",
    "\n",
    "# 2. 生成するファイル名\n",
    "target_filename = 'combined_sbom.json'\n",
    "\n",
    "# 3. 並び替えたいキーの順番\n",
    "key_order = [\n",
    "    \"SPDXID\",\n",
    "    \"spdxVersion\",\n",
    "    \"creationInfo\",\n",
    "    \"name\",\n",
    "    \"dataLicense\",\n",
    "    \"documentNamespace\",\n",
    "    \"documentDescribes\",\n",
    "    \"externalDocumentRefs\",\n",
    "    \"packages\",\n",
    "    \"files\",\n",
    "    \"relationships\",\n",
    "]\n",
    "\n",
    "\n",
    "# --- 処理の開始 ---\n",
    "print(f\"--- Starting: Copying and reordering SBOMs ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "try:\n",
    "    # 'generated_sboms' 内のリポジトリ名を取得\n",
    "    repo_dirs = [d for d in os.listdir(target_directory) if os.path.isdir(os.path.join(target_directory, d))]\n",
    "    \n",
    "    if not repo_dirs:\n",
    "         print(f\"No repository directories found in '{target_directory}'.\")\n",
    "\n",
    "    for repo_name in repo_dirs:\n",
    "        print(f\"▶️  Processing: {repo_name}\")\n",
    "\n",
    "        # --- パスの定義 ---\n",
    "        source_sbom_path = os.path.join(target_directory, repo_name, 'source', '_manifest', 'spdx_2.2', 'manifest.spdx.json')\n",
    "        destination_sbom_path = os.path.join(target_directory, repo_name, target_filename)\n",
    "\n",
    "        # --- スキップ判定 ---\n",
    "        if os.path.exists(destination_sbom_path):\n",
    "            print(f\"🟢 Skipping: '{target_filename}' already exists.\")\n",
    "            print(\"-\" * 50)\n",
    "            continue\n",
    "        \n",
    "        # --- コピー元の存在確認 ---\n",
    "        if not os.path.exists(source_sbom_path):\n",
    "            print(f\"⚠️ Warning: sbom-tool SBOM not found for {repo_name}. Skipping.\")\n",
    "            print(\"-\" * 50)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # --- ステップ1: コピー ---\n",
    "            print(f\"   Copying sbom-tool's output to '{target_filename}'...\")\n",
    "            shutil.copy(source_sbom_path, destination_sbom_path)\n",
    "            print(\"   ✅ Copy successful.\")\n",
    "\n",
    "            # --- ステップ2: 読み込みと並び替え ---\n",
    "            with open(destination_sbom_path, 'r', encoding='utf-8') as f:\n",
    "                original_data = json.load(f)\n",
    "\n",
    "            ordered_data = {}\n",
    "            # 指定された順でキーを追加\n",
    "            for key in key_order:\n",
    "                if key in original_data:\n",
    "                    ordered_data[key] = original_data[key]\n",
    "            # 残りのキーを末尾に追加\n",
    "            for key, value in original_data.items():\n",
    "                if key not in ordered_data:\n",
    "                    ordered_data[key] = value\n",
    "\n",
    "            # --- ステップ3: 整形して上書き保存 ---\n",
    "            print(f\"   Reordering keys...\")\n",
    "            with open(destination_sbom_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(ordered_data, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"   ✅ Keys reordered and saved.\")\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"❌ Error: Could not parse source JSON file. It may be corrupted.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ An unexpected error occurred: {e}\")\n",
    "        \n",
    "        finally:\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: The source directory '{target_directory}' was not found.\")\n",
    "\n",
    "print(\"All processes finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb964aea",
   "metadata": {},
   "source": [
    "# Step 7: SBOMの統合 (GitHub Dependency Graph)\n",
    "\n",
    "このステップでは,`Step 6`で作成したベースSBOM (`combined_sbom.json`) に対して,`Step 4`でGitHub APIから取得した`dependency-graph-sbom.json`の情報を統合します.この処理により,特に**ライセンス**や**著作権**に関する情報が大幅に補強されます.\n",
    "\n",
    "### ## 実行内容 ⚙️\n",
    "\n",
    "以下のコードは,2つのSBOMファイルを比較し,`combined_sbom.json`をより完全なものにするために,以下の4つの主要な処理を実行します.\n",
    "\n",
    "#### 1. 既存パッケージ情報の補完\n",
    "`purl`（Package URL）を基準に2つのSBOM間でパッケージを照合し,`combined_sbom.json`のパッケージ情報に不足があれば,`dependency-graph-sbom.json`から以下の情報を補完します.\n",
    "\n",
    "* **`licenseConcluded`**: ライセンス情報が`NOASSERTION`の場合に更新します.\n",
    "* **`copyrightText`**: 著作権情報が`NOASSERTION`の場合に更新します.\n",
    "\n",
    "#### 2. 不足パッケージの追加\n",
    "`sbom-tool`では検出されなかったが,`dependency-graph`では検出されたパッケージ（主にGitHub Actionsなど）を追加します.重複を防ぐため,**`name`（パッケージ名）**が`combined_sbom.json`に存在しないもののみが追加対象となります.\n",
    "\n",
    "#### 3. `creators`情報の追記\n",
    "`creationInfo`セクションに,`dependency-graph`を生成したツールの情報（`Tool: ...`）を追記します.\n",
    "\n",
    "#### 4. ドキュメントコメントの追記\n",
    "ファイル全体に関する`comment`フィールドに,`dependency-graph`からの注釈を追記します."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63d8ccd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting: Supplementing 'combined_sbom.json' with richer data and comments ---\n",
      "--------------------------------------------------\n",
      "▶️  Processing: sbom-python-test\n",
      "   Added new package: com.github.MoriwakiYusuke/sbom-python-test\n",
      "   Added CONTAINS relationship for: com.github.MoriwakiYusuke/sbom-python-test\n",
      "   7 total changes. Reordering and saving file...\n",
      "✅ Successfully supplemented 'combined_sbom.json'.\n",
      "--------------------------------------------------\n",
      "▶️  Processing: Python\n",
      "   No fields needed updating or adding.\n",
      "--------------------------------------------------\n",
      "▶️  Processing: python-mini-projects\n",
      "   11 total changes. Reordering and saving file...\n",
      "✅ Successfully supplemented 'combined_sbom.json'.\n",
      "--------------------------------------------------\n",
      "▶️  Processing: sbom-go-test\n",
      "   No fields needed updating or adding.\n",
      "--------------------------------------------------\n",
      "All processes finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def get_purl_from_package(pkg):\n",
    "    \"\"\"パッケージ情報からpurl（Package URL）を抽出する.\"\"\"\n",
    "    if 'externalRefs' in pkg:\n",
    "        for ref in pkg['externalRefs']:\n",
    "            if ref.get('referenceType') == 'purl':\n",
    "                return ref.get('referenceLocator')\n",
    "    return None\n",
    "\n",
    "# --- 設定項目 ---\n",
    "target_directory = 'generated_sboms'\n",
    "base_sbom_filename = 'combined_sbom.json'\n",
    "source_sbom_filename = 'dependency-graph-sbom.json'\n",
    "\n",
    "\n",
    "# --- 処理の開始 ---\n",
    "print(f\"--- Starting: Supplementing '{base_sbom_filename}' with richer data and comments ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "try:\n",
    "    # 'generated_sboms' ディレクトリ内のリポジトリ名一覧を取得する\n",
    "    repo_dirs = [d for d in os.listdir(target_directory) if os.path.isdir(os.path.join(target_directory, d))]\n",
    "\n",
    "    if not repo_dirs:\n",
    "        print(f\"No repository directories found in '{target_directory}'.\")\n",
    "\n",
    "    for repo_name in repo_dirs:\n",
    "        print(f\"▶️  Processing: {repo_name}\")\n",
    "\n",
    "        base_sbom_path = os.path.join(target_directory, repo_name, base_sbom_filename)\n",
    "        source_sbom_path = os.path.join(target_directory, repo_name, 'source', source_sbom_filename)\n",
    "\n",
    "        if not os.path.exists(base_sbom_path) or not os.path.exists(source_sbom_path):\n",
    "            print(f\"⚠️ Warning: One or both SBOM files are missing. Skipping.\")\n",
    "            print(\"-\" * 50)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            with open(base_sbom_path, 'r', encoding='utf-8') as f:\n",
    "                base_data = json.load(f)\n",
    "            with open(source_sbom_path, 'r', encoding='utf-8') as f:\n",
    "                source_data = json.load(f)\n",
    "\n",
    "            changes_made = 0\n",
    "\n",
    "            # --- ステップ2: 既存パッケージの情報を補完 ---\n",
    "            source_package_map = {}\n",
    "            if 'packages' in source_data:\n",
    "                for pkg in source_data['packages']:\n",
    "                    purl = get_purl_from_package(pkg)\n",
    "                    if purl:\n",
    "                        source_package_map[purl] = {\n",
    "                            'licenseConcluded': pkg.get('licenseConcluded', 'NOASSERTION'),\n",
    "                            'copyrightText': pkg.get('copyrightText', 'NOASSERTION')\n",
    "                        }\n",
    "\n",
    "            if 'packages' in base_data:\n",
    "                for pkg in base_data['packages']:\n",
    "                    purl = get_purl_from_package(pkg)\n",
    "                    if purl and purl in source_package_map:\n",
    "                        source_pkg_info = source_package_map[purl]\n",
    "                        if pkg.get('licenseConcluded') == 'NOASSERTION' and source_pkg_info['licenseConcluded'] != 'NOASSERTION':\n",
    "                            pkg['licenseConcluded'] = source_pkg_info['licenseConcluded']\n",
    "                            changes_made += 1\n",
    "                        if pkg.get('copyrightText') == 'NOASSERTION' and source_pkg_info['copyrightText'] != 'NOASSERTION':\n",
    "                            pkg['copyrightText'] = source_pkg_info['copyrightText']\n",
    "                            changes_made += 1\n",
    "            \n",
    "            # --- ステップ3: 不足パッケージと関連するRelationshipを追加 ---\n",
    "            if 'packages' in source_data:\n",
    "                # 1. 親となるトップレベルパッケージのSPDXIDを特定する\n",
    "                main_package_spdx_id = None\n",
    "                for rel in base_data.get('relationships', []):\n",
    "                    if rel.get('relationshipType') == 'DESCRIBES' and rel.get('spdxElementId') == 'SPDXRef-DOCUMENT':\n",
    "                        main_package_spdx_id = rel.get('relatedSpdxElement')\n",
    "                        break\n",
    "                \n",
    "                if not main_package_spdx_id:\n",
    "                    print(\"⚠️ Warning: Could not find the main package ID (DESCRIBES relationship). Cannot add new relationships.\")\n",
    "                \n",
    "                base_pkg_names = {pkg.get('name') for pkg in base_data.get('packages', []) if pkg.get('name')}\n",
    "                \n",
    "                for source_pkg in source_data.get('packages', []):\n",
    "                    pkg_name = source_pkg.get('name')\n",
    "                    # パッケージ名がベースSBOMに存在しない場合のみ追加\n",
    "                    if pkg_name and pkg_name not in base_pkg_names:\n",
    "                        # パッケージを追加\n",
    "                        base_data.setdefault('packages', []).append(source_pkg)\n",
    "                        base_pkg_names.add(pkg_name)\n",
    "                        changes_made += 1\n",
    "                        print(f\"   Added new package: {pkg_name}\")\n",
    "                        \n",
    "                        # 2. Relationshipも追加する (親IDが見つかっている場合)\n",
    "                        new_pkg_spdx_id = source_pkg.get('SPDXID')\n",
    "                        if main_package_spdx_id and new_pkg_spdx_id:\n",
    "                            new_relationship = {\n",
    "                                'spdxElementId': main_package_spdx_id,\n",
    "                                'relatedSpdxElement': new_pkg_spdx_id,\n",
    "                                'relationshipType': 'CONTAINS'\n",
    "                            }\n",
    "                            # 既存のrelationshipsになければ追加\n",
    "                            if new_relationship not in base_data.get('relationships', []):\n",
    "                                base_data.setdefault('relationships', []).append(new_relationship)\n",
    "                                print(f\"   Added CONTAINS relationship for: {pkg_name}\")\n",
    "\n",
    "            # --- ステップ4: creationInfo.creators の情報を追記 ---\n",
    "            if 'creationInfo' in source_data and 'creators' in source_data['creationInfo'] and \\\n",
    "               'creationInfo' in base_data and 'creators' in base_data['creationInfo']:\n",
    "                base_creators = base_data['creationInfo']['creators']\n",
    "                for creator in source_data['creationInfo']['creators']:\n",
    "                    if creator not in base_creators:\n",
    "                        base_creators.append(creator)\n",
    "                        changes_made += 1\n",
    "\n",
    "            # --- ステップ5: コメントを追記 ---\n",
    "            source_doc_comment = source_data.get('comment')\n",
    "            if source_doc_comment:\n",
    "                comment_header = \"Note from dependency-graph\"\n",
    "                full_comment_to_add = f\"{comment_header}: {source_doc_comment}\"\n",
    "                if 'comment' not in base_data or not base_data.get('comment'):\n",
    "                    base_data['comment'] = full_comment_to_add\n",
    "                    changes_made += 1\n",
    "                elif full_comment_to_add not in base_data['comment']:\n",
    "                    base_data['comment'] += f\"\\\\n\\\\n{full_comment_to_add}\"\n",
    "                    changes_made += 1\n",
    "\n",
    "            # --- ステップ6: 変更があった場合のみファイルを上書き保存 ---\n",
    "            if changes_made > 0:\n",
    "                print(f\"   {changes_made} total changes. Reordering and saving file...\")\n",
    "                key_order = [\n",
    "                    \"SPDXID\", \"spdxVersion\", \"creationInfo\", \"name\", \"dataLicense\",\n",
    "                    \"documentNamespace\", \"comment\", \"documentDescribes\", \"externalDocumentRefs\",\n",
    "                    \"packages\", \"files\", \"relationships\"\n",
    "                ]\n",
    "                ordered_data = {key: base_data[key] for key in key_order if key in base_data}\n",
    "                ordered_data.update({key: value for key, value in base_data.items() if key not in ordered_data})\n",
    "                with open(base_sbom_path, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(ordered_data, f, indent=2, ensure_ascii=False)\n",
    "                print(f\"✅ Successfully supplemented '{base_sbom_filename}'.\")\n",
    "            else:\n",
    "                print(\"   No fields needed updating or adding.\")\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"❌ Error: Could not parse a JSON file. Details: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ An unexpected error occurred: {e}\")\n",
    "        finally:\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: The top-level directory '{target_directory}' was not found.\")\n",
    "\n",
    "print(\"All processes finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7103721d",
   "metadata": {},
   "source": [
    "# Step 8: SBOMの統合 (Syft)\n",
    "\n",
    "`sbom-tool`とGitHub APIの情報を統合した`combined_sbom.json`に対し,さらに`syft`が検出した情報をマージしてSBOMを完成させます.`syft`は,パッケージの提供者（`supplier`）や作成元（`originator`）,検出場所（`sourceInfo`）,そして脆弱性スキャンに不可欠な**CPE**（Common Platform Enumeration）などの詳細情報を検出する能力に優れています.\n",
    "\n",
    "### ## 実行内容 ⚙️\n",
    "\n",
    "以下のコードは,2つのSBOMファイルを比較し,`combined_sbom.json`をさらにリッチなものにするために,以下の4つの主要な処理を実行します.\n",
    "\n",
    "#### 1. 既存パッケージ情報の補完\n",
    "`purl`を基準にパッケージを照合し,`combined_sbom.json`のパッケージ情報に不足があれば,`syft-sbom.json`から以下の情報を補完します.\n",
    "\n",
    "* **`supplier`** と **`originator`**: `NOASSERTION`の場合に更新します.\n",
    "* **`sourceInfo`**: 項目が存在しない場合に追加します.\n",
    "* **`externalRefs`**: `purl`や`cpe`などの外部リンクが重複しないように追記します.\n",
    "\n",
    "#### 2. 不足パッケージの追加\n",
    "`sbom-tool`やGitHub APIでは検出されなかったが,`syft`では検出されたパッケージを追加します.重複を防ぐため,**`name`（パッケージ名）**が`combined_sbom.json`に存在しないもののみが追加対象となります.\n",
    "\n",
    "#### 3. `creators`情報の追記\n",
    "`creationInfo`セクションに,`syft`を生成したツールの情報（`Tool: syft-...`）を追記します.\n",
    "\n",
    "#### 4. 整形して保存\n",
    "最後に,すべての情報が統合された`combined_sbom.json`のキーの順序を統一的なフォーマットに整え,ファイルを上書き保存します."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a2e1aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting: Supplementing 'combined_sbom.json' with data from syft (using name for matching) ---\n",
      "--------------------------------------------------\n",
      "▶️  Processing: sbom-python-test\n",
      "   Added new package from syft: ./\n",
      "   Added CONTAINS relationship for: ./\n",
      "   Changes detected. Reordering keys and saving file...\n",
      "✅ Successfully supplemented and reordered 'combined_sbom.json'.\n",
      "--------------------------------------------------\n",
      "▶️  Processing: Python\n",
      "   Added new package from syft: absl-py\n",
      "   Added CONTAINS relationship for: absl-py\n",
      "   Added new package from syft: alabaster\n",
      "   Added CONTAINS relationship for: alabaster\n",
      "   Added new package from syft: anyio\n",
      "   Added CONTAINS relationship for: anyio\n",
      "   Added new package from syft: astroid\n",
      "   Added CONTAINS relationship for: astroid\n",
      "   Added new package from syft: babel\n",
      "   Added CONTAINS relationship for: babel\n",
      "   Added new package from syft: certifi\n",
      "   Added CONTAINS relationship for: certifi\n",
      "   Added new package from syft: charset-normalizer\n",
      "   Added CONTAINS relationship for: charset-normalizer\n",
      "   Added new package from syft: colorama\n",
      "   Added CONTAINS relationship for: colorama\n",
      "   Added new package from syft: contourpy\n",
      "   Added CONTAINS relationship for: contourpy\n",
      "   Added new package from syft: coverage\n",
      "   Added CONTAINS relationship for: coverage\n",
      "   Added new package from syft: cycler\n",
      "   Added CONTAINS relationship for: cycler\n",
      "   Added new package from syft: docutils\n",
      "   Added CONTAINS relationship for: docutils\n",
      "   Added new package from syft: dom-toml\n",
      "   Added CONTAINS relationship for: dom-toml\n",
      "   Added new package from syft: domdf-python-tools\n",
      "   Added CONTAINS relationship for: domdf-python-tools\n",
      "   Added new package from syft: fonttools\n",
      "   Added CONTAINS relationship for: fonttools\n",
      "   Added new package from syft: h11\n",
      "   Added CONTAINS relationship for: h11\n",
      "   Added new package from syft: h5py\n",
      "   Added CONTAINS relationship for: h5py\n",
      "   Added new package from syft: httpcore\n",
      "   Added CONTAINS relationship for: httpcore\n",
      "   Added new package from syft: idna\n",
      "   Added CONTAINS relationship for: idna\n",
      "   Added new package from syft: imagesize\n",
      "   Added CONTAINS relationship for: imagesize\n",
      "   Added new package from syft: iniconfig\n",
      "   Added CONTAINS relationship for: iniconfig\n",
      "   Added new package from syft: jinja2\n",
      "   Added CONTAINS relationship for: jinja2\n",
      "   Added new package from syft: joblib\n",
      "   Added CONTAINS relationship for: joblib\n",
      "   Added new package from syft: kiwisolver\n",
      "   Added CONTAINS relationship for: kiwisolver\n",
      "   Added new package from syft: markdown-it-py\n",
      "   Added CONTAINS relationship for: markdown-it-py\n",
      "   Added new package from syft: markupsafe\n",
      "   Added CONTAINS relationship for: markupsafe\n",
      "   Added new package from syft: mdit-py-plugins\n",
      "   Added CONTAINS relationship for: mdit-py-plugins\n",
      "   Added new package from syft: mdurl\n",
      "   Added CONTAINS relationship for: mdurl\n",
      "   Added new package from syft: ml-dtypes\n",
      "   Added CONTAINS relationship for: ml-dtypes\n",
      "   Added new package from syft: mpmath\n",
      "   Added CONTAINS relationship for: mpmath\n",
      "   Added new package from syft: myst-parser\n",
      "   Added CONTAINS relationship for: myst-parser\n",
      "   Added new package from syft: namex\n",
      "   Added CONTAINS relationship for: namex\n",
      "   Added new package from syft: natsort\n",
      "   Added CONTAINS relationship for: natsort\n",
      "   Added new package from syft: nvidia-nccl-cu12\n",
      "   Added CONTAINS relationship for: nvidia-nccl-cu12\n",
      "   Added new package from syft: oauthlib\n",
      "   Added CONTAINS relationship for: oauthlib\n",
      "   Added new package from syft: optree\n",
      "   Added CONTAINS relationship for: optree\n",
      "   Added new package from syft: packaging\n",
      "   Added CONTAINS relationship for: packaging\n",
      "   Added new package from syft: patsy\n",
      "   Added CONTAINS relationship for: patsy\n",
      "   Added new package from syft: pluggy\n",
      "   Added CONTAINS relationship for: pluggy\n",
      "   Added new package from syft: pygments\n",
      "   Added CONTAINS relationship for: pygments\n",
      "   Added new package from syft: pyparsing\n",
      "   Added CONTAINS relationship for: pyparsing\n",
      "   Added new package from syft: pytest\n",
      "   Added CONTAINS relationship for: pytest\n",
      "   Added new package from syft: pytest-cov\n",
      "   Added CONTAINS relationship for: pytest-cov\n",
      "   Added new package from syft: python-dateutil\n",
      "   Added CONTAINS relationship for: python-dateutil\n",
      "   Added new package from syft: pytz\n",
      "   Added CONTAINS relationship for: pytz\n",
      "   Added new package from syft: pyyaml\n",
      "   Added CONTAINS relationship for: pyyaml\n",
      "   Added new package from syft: requests\n",
      "   Added CONTAINS relationship for: requests\n",
      "   Added new package from syft: requests-oauthlib\n",
      "   Added CONTAINS relationship for: requests-oauthlib\n",
      "   Added new package from syft: roman-numerals-py\n",
      "   Added CONTAINS relationship for: roman-numerals-py\n",
      "   Added new package from syft: six\n",
      "   Added CONTAINS relationship for: six\n",
      "   Added new package from syft: sniffio\n",
      "   Added CONTAINS relationship for: sniffio\n",
      "   Added new package from syft: snowballstemmer\n",
      "   Added CONTAINS relationship for: snowballstemmer\n",
      "   Added new package from syft: soupsieve\n",
      "   Added CONTAINS relationship for: soupsieve\n",
      "   Added new package from syft: sphinx\n",
      "   Added CONTAINS relationship for: sphinx\n",
      "   Added new package from syft: sphinx-autoapi\n",
      "   Added CONTAINS relationship for: sphinx-autoapi\n",
      "   Added new package from syft: sphinxcontrib-applehelp\n",
      "   Added CONTAINS relationship for: sphinxcontrib-applehelp\n",
      "   Added new package from syft: sphinxcontrib-devhelp\n",
      "   Added CONTAINS relationship for: sphinxcontrib-devhelp\n",
      "   Added new package from syft: sphinxcontrib-htmlhelp\n",
      "   Added CONTAINS relationship for: sphinxcontrib-htmlhelp\n",
      "   Added new package from syft: sphinxcontrib-jsmath\n",
      "   Added CONTAINS relationship for: sphinxcontrib-jsmath\n",
      "   Added new package from syft: sphinxcontrib-qthelp\n",
      "   Added CONTAINS relationship for: sphinxcontrib-qthelp\n",
      "   Added new package from syft: sphinxcontrib-serializinghtml\n",
      "   Added CONTAINS relationship for: sphinxcontrib-serializinghtml\n",
      "   Added new package from syft: thealgorithms-python\n",
      "   Added CONTAINS relationship for: thealgorithms-python\n",
      "   Added new package from syft: threadpoolctl\n",
      "   Added CONTAINS relationship for: threadpoolctl\n",
      "   Added new package from syft: tomli\n",
      "   Added CONTAINS relationship for: tomli\n",
      "   Added new package from syft: tzdata\n",
      "   Added CONTAINS relationship for: tzdata\n",
      "   Added new package from syft: urllib3\n",
      "   Added CONTAINS relationship for: urllib3\n",
      "   Added new package from syft: ./\n",
      "   Added CONTAINS relationship for: ./\n",
      "   Changes detected. Reordering keys and saving file...\n",
      "✅ Successfully supplemented and reordered 'combined_sbom.json'.\n",
      "--------------------------------------------------\n",
      "▶️  Processing: python-mini-projects\n",
      "   Added new package from syft: ./\n",
      "   Added CONTAINS relationship for: ./\n",
      "   Changes detected. Reordering keys and saving file...\n",
      "✅ Successfully supplemented and reordered 'combined_sbom.json'.\n",
      "--------------------------------------------------\n",
      "▶️  Processing: sbom-go-test\n",
      "   Added new package from syft: stdlib\n",
      "   Added CONTAINS relationship for: stdlib\n",
      "   Added new package from syft: ./\n",
      "   Added CONTAINS relationship for: ./\n",
      "   Changes detected. Reordering keys and saving file...\n",
      "✅ Successfully supplemented and reordered 'combined_sbom.json'.\n",
      "--------------------------------------------------\n",
      "All processes finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def get_purl_from_package(pkg):\n",
    "    \"\"\"パッケージ情報からpurl（Package URL）を抽出する.\"\"\"\n",
    "    if 'externalRefs' in pkg:\n",
    "        for ref in pkg['externalRefs']:\n",
    "            if ref.get('referenceType') == 'purl':\n",
    "                return ref.get('referenceLocator')\n",
    "    return None\n",
    "\n",
    "# --- 設定項目 ---\n",
    "target_directory = 'generated_sboms'\n",
    "base_sbom_filename = 'combined_sbom.json'\n",
    "source_sbom_filename = 'syft-sbom.json'\n",
    "\n",
    "# --- 処理の開始 ---\n",
    "print(f\"--- Starting: Supplementing '{base_sbom_filename}' with data from syft (using name for matching) ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "try:\n",
    "    # 'generated_sboms' 内のリポジトリ名を取得する\n",
    "    repo_dirs = [d for d in os.listdir(target_directory) if os.path.isdir(os.path.join(target_directory, d))]\n",
    "    \n",
    "    if not repo_dirs:\n",
    "        print(f\"No repository directories found in '{target_directory}'.\")\n",
    "\n",
    "    # 各リポジトリに対して処理を実行する\n",
    "    for repo_name in repo_dirs:\n",
    "        print(f\"▶️  Processing: {repo_name}\")\n",
    "\n",
    "        # --- パスの定義 ---\n",
    "        base_sbom_path = os.path.join(target_directory, repo_name, base_sbom_filename)\n",
    "        source_sbom_path = os.path.join(target_directory, repo_name, 'source', source_sbom_filename)\n",
    "\n",
    "        # --- ファイルの存在確認 ---\n",
    "        if not os.path.exists(base_sbom_path) or not os.path.exists(source_sbom_path):\n",
    "            print(f\"⚠️ Warning: One or both SBOM files are missing. Skipping.\")\n",
    "            print(\"-\" * 50)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # --- ステップ1: 両方のSBOMファイルを読み込む ---\n",
    "            with open(base_sbom_path, 'r', encoding='utf-8') as f:\n",
    "                base_data = json.load(f)\n",
    "            with open(source_sbom_path, 'r', encoding='utf-8') as f:\n",
    "                source_data = json.load(f)\n",
    "\n",
    "            # 変更を検出するため、処理前のデータを文字列として保存する\n",
    "            initial_data_str = json.dumps(base_data, sort_keys=True)\n",
    "\n",
    "            # --- ステップ2: syftのパッケージ情報をpurlをキーにした辞書に整理 ---\n",
    "            source_package_map = {}\n",
    "            if 'packages' in source_data:\n",
    "                for pkg in source_data['packages']:\n",
    "                    purl = get_purl_from_package(pkg)\n",
    "                    if purl and purl not in source_package_map:\n",
    "                        source_package_map[purl] = pkg\n",
    "\n",
    "            # --- ステップ3: 既存パッケージの情報を補完 ---\n",
    "            if 'packages' in base_data:\n",
    "                for pkg in base_data['packages']:\n",
    "                    purl = get_purl_from_package(pkg)\n",
    "                    if purl and purl in source_package_map:\n",
    "                        source_pkg = source_package_map[purl]\n",
    "                        \n",
    "                        # サプライヤー情報を補完\n",
    "                        if (not pkg.get('supplier') or pkg.get('supplier') == 'NOASSERTION') and \\\n",
    "                           source_pkg.get('supplier') and source_pkg.get('supplier') != 'NOASSERTION':\n",
    "                            pkg['supplier'] = source_pkg['supplier']\n",
    "                        \n",
    "                        # 作成元情報を補完\n",
    "                        if (not pkg.get('originator') or pkg.get('originator') == 'NOASSERTION') and \\\n",
    "                           source_pkg.get('originator') and source_pkg.get('originator') != 'NOASSERTION':\n",
    "                            pkg['originator'] = source_pkg['originator']\n",
    "\n",
    "                        # 検出元情報を補完\n",
    "                        if 'sourceInfo' not in pkg and source_pkg.get('sourceInfo'):\n",
    "                            pkg['sourceInfo'] = source_pkg['sourceInfo']\n",
    "                        \n",
    "                        # 外部リンク(CPEなど)を追記\n",
    "                        if 'externalRefs' not in pkg: pkg['externalRefs'] = []\n",
    "                        existing_locators = {ref.get('referenceLocator') for ref in pkg['externalRefs']}\n",
    "                        for new_ref in source_pkg.get('externalRefs', []):\n",
    "                            if new_ref.get('referenceLocator') not in existing_locators:\n",
    "                                pkg['externalRefs'].append(new_ref)\n",
    "\n",
    "            # --- ステップ4: 不足パッケージと関連するRelationshipを追加 ---\n",
    "            if 'packages' in source_data:\n",
    "                # 親となるトップレベルパッケージのSPDXIDを特定する\n",
    "                main_package_spdx_id = None\n",
    "                for rel in base_data.get('relationships', []):\n",
    "                    if rel.get('relationshipType') == 'DESCRIBES' and rel.get('spdxElementId') == 'SPDXRef-DOCUMENT':\n",
    "                        main_package_spdx_id = rel.get('relatedSpdxElement')\n",
    "                        break\n",
    "                \n",
    "                if not main_package_spdx_id:\n",
    "                    print(\"⚠️ Warning: Could not find the main package ID. Cannot add new relationships.\")\n",
    "                \n",
    "                base_pkg_names = {pkg.get('name') for pkg in base_data.get('packages', []) if pkg.get('name')}\n",
    "                \n",
    "                for source_pkg in source_data.get('packages', []):\n",
    "                    pkg_name = source_pkg.get('name')\n",
    "                    if pkg_name and pkg_name not in base_pkg_names:\n",
    "                        # パッケージを追加\n",
    "                        base_data.setdefault('packages', []).append(source_pkg)\n",
    "                        base_pkg_names.add(pkg_name)\n",
    "                        print(f\"   Added new package from syft: {pkg_name}\")\n",
    "                        \n",
    "                        # Relationshipも追加\n",
    "                        new_pkg_spdx_id = source_pkg.get('SPDXID')\n",
    "                        if main_package_spdx_id and new_pkg_spdx_id:\n",
    "                            new_relationship = {\n",
    "                                'spdxElementId': main_package_spdx_id,\n",
    "                                'relatedSpdxElement': new_pkg_spdx_id,\n",
    "                                'relationshipType': 'CONTAINS'\n",
    "                            }\n",
    "                            if new_relationship not in base_data.get('relationships', []):\n",
    "                                base_data.setdefault('relationships', []).append(new_relationship)\n",
    "                                print(f\"   Added CONTAINS relationship for: {pkg_name}\")\n",
    "\n",
    "            # --- ステップ5: syftのツール情報をcreatorsに追加 ---\n",
    "            if 'creationInfo' in source_data and 'creators' in source_data['creationInfo']:\n",
    "                base_creators = base_data.setdefault('creationInfo', {}).setdefault('creators', [])\n",
    "                for creator in source_data['creationInfo']['creators']:\n",
    "                    if creator not in base_creators:\n",
    "                        base_creators.append(creator)\n",
    "            \n",
    "            # --- ステップ6: 変更があった場合のみファイルを保存 ---\n",
    "            if initial_data_str != json.dumps(base_data, sort_keys=True):\n",
    "                print(f\"   Changes detected. Reordering keys and saving file...\")\n",
    "\n",
    "                key_order = [\n",
    "                    \"SPDXID\", \"spdxVersion\", \"creationInfo\", \"name\", \"dataLicense\",\n",
    "                    \"documentNamespace\", \"comment\", \"documentDescribes\", \"externalDocumentRefs\",\n",
    "                    \"packages\", \"files\", \"relationships\"\n",
    "                ]\n",
    "                ordered_data = {key: base_data[key] for key in key_order if key in base_data}\n",
    "                ordered_data.update({key: value for key, value in base_data.items() if key not in ordered_data})\n",
    "\n",
    "                with open(base_sbom_path, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(ordered_data, f, indent=2, ensure_ascii=False)\n",
    "                print(f\"✅ Successfully supplemented and reordered '{base_sbom_filename}'.\")\n",
    "            else:\n",
    "                print(\"   No new information to supplement from syft.\")\n",
    "\n",
    "        except (json.JSONDecodeError, KeyError) as e:\n",
    "            print(f\"❌ Error processing files for {repo_name}. Details: {e}\")\n",
    "        \n",
    "        finally:\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: The top-level directory '{target_directory}' was not found.\")\n",
    "\n",
    "print(\"All processes finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61f686b",
   "metadata": {},
   "source": [
    "# Step 9: SBOMの統合 (Trivy)\n",
    "\n",
    "このステップでは,これまでの処理で情報を充実させてきた`combined_sbom.json`に対し,最後に`Trivy`が生成した`trivy-sbom.json`の情報を統合します.`Trivy`は,パッケージの目的 (`primaryPackagePurpose`) や,ツール固有の注釈 (`annotations`) といった,他のツールでは得られないユニークな情報を提供します.\n",
    "\n",
    "### ## 実行内容 ⚙️\n",
    "\n",
    "以下のコードは,`combined_sbom.json`を最終的に完成させるため,以下の4つの主要な処理を実行します.\n",
    "\n",
    "#### 1. 既存パッケージ情報の補完\n",
    "`purl`を基準にパッケージを照合し,`combined_sbom.json`のパッケージ情報に不足があれば,`trivy-sbom.json`から以下の情報を補完します.\n",
    "\n",
    "* **`primaryPackagePurpose`**: パッケージの主な目的（例: `LIBRARY`, `APPLICATION`）が`NOASSERTION`または未設定の場合に更新します.\n",
    "* **`annotations`**: `Trivy`による注釈情報（例: `PkgType: pip`）が未設定の場合に追加します.\n",
    "\n",
    "#### 2. 不足パッケージの追加\n",
    "これまでのツールでは検出されなかったが,`Trivy`が独自に検出したパッケージを追加します.重複を防ぐため,**`name`（パッケージ名）**が`combined_sbom.json`に存在しないもののみが追加対象となります.\n",
    "\n",
    "#### 3. `creators`情報の追記\n",
    "`creationInfo`セクションに,`Trivy`を生成したツールの情報（`Tool: trivy-...`）を追記します.\n",
    "\n",
    "#### 4. 整形して保存\n",
    "最後に,すべての情報が統合された`combined_sbom.json`のキーの順序を統一的なフォーマットに整え,ファイルを上書き保存します."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c6f7d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting: Supplementing 'combined_sbom.json' with data from Trivy ---\n",
      "--------------------------------------------------\n",
      "▶️  Processing: sbom-python-test\n",
      "   Updated primaryPackagePurpose for: pyfiglet\n",
      "   Added annotations for: pyfiglet\n",
      "   Updated primaryPackagePurpose for: colorama\n",
      "   Added annotations for: colorama\n",
      "   Added new package from Trivy: requirements.txt\n",
      "   Added CONTAINS relationship for: requirements.txt\n",
      "   Added new package from Trivy: .\n",
      "   Added CONTAINS relationship for: .\n",
      "   Changes detected. Reordering keys and saving file...\n",
      "✅ Successfully supplemented and reordered 'combined_sbom.json'.\n",
      "--------------------------------------------------\n",
      "▶️  Processing: Python\n",
      "   Updated primaryPackagePurpose for: absl-py\n",
      "   Added annotations for: absl-py\n",
      "   Updated primaryPackagePurpose for: anyio\n",
      "   Added annotations for: anyio\n",
      "   Updated primaryPackagePurpose for: certifi\n",
      "   Added annotations for: certifi\n",
      "   Updated primaryPackagePurpose for: charset-normalizer\n",
      "   Added annotations for: charset-normalizer\n",
      "   Updated primaryPackagePurpose for: contourpy\n",
      "   Added annotations for: contourpy\n",
      "   Updated primaryPackagePurpose for: cycler\n",
      "   Added annotations for: cycler\n",
      "   Updated primaryPackagePurpose for: dom-toml\n",
      "   Added annotations for: dom-toml\n",
      "   Updated primaryPackagePurpose for: domdf-python-tools\n",
      "   Added annotations for: domdf-python-tools\n",
      "   Updated primaryPackagePurpose for: fonttools\n",
      "   Added annotations for: fonttools\n",
      "   Updated primaryPackagePurpose for: h11\n",
      "   Added annotations for: h11\n",
      "   Updated primaryPackagePurpose for: h5py\n",
      "   Added annotations for: h5py\n",
      "   Updated primaryPackagePurpose for: httpcore\n",
      "   Added annotations for: httpcore\n",
      "   Updated primaryPackagePurpose for: idna\n",
      "   Added annotations for: idna\n",
      "   Updated primaryPackagePurpose for: joblib\n",
      "   Added annotations for: joblib\n",
      "   Updated primaryPackagePurpose for: kiwisolver\n",
      "   Added annotations for: kiwisolver\n",
      "   Updated primaryPackagePurpose for: markdown-it-py\n",
      "   Added annotations for: markdown-it-py\n",
      "   Updated primaryPackagePurpose for: mdurl\n",
      "   Added annotations for: mdurl\n",
      "   Updated primaryPackagePurpose for: ml-dtypes\n",
      "   Added annotations for: ml-dtypes\n",
      "   Updated primaryPackagePurpose for: mpmath\n",
      "   Added annotations for: mpmath\n",
      "   Updated primaryPackagePurpose for: namex\n",
      "   Added annotations for: namex\n",
      "   Updated primaryPackagePurpose for: natsort\n",
      "   Added annotations for: natsort\n",
      "   Updated primaryPackagePurpose for: nvidia-nccl-cu12\n",
      "   Added annotations for: nvidia-nccl-cu12\n",
      "   Updated primaryPackagePurpose for: oauthlib\n",
      "   Added annotations for: oauthlib\n",
      "   Updated primaryPackagePurpose for: optree\n",
      "   Added annotations for: optree\n",
      "   Updated primaryPackagePurpose for: packaging\n",
      "   Added annotations for: packaging\n",
      "   Updated primaryPackagePurpose for: patsy\n",
      "   Added annotations for: patsy\n",
      "   Updated primaryPackagePurpose for: pygments\n",
      "   Added annotations for: pygments\n",
      "   Updated primaryPackagePurpose for: pyparsing\n",
      "   Added annotations for: pyparsing\n",
      "   Updated primaryPackagePurpose for: python-dateutil\n",
      "   Added annotations for: python-dateutil\n",
      "   Updated primaryPackagePurpose for: pytz\n",
      "   Added annotations for: pytz\n",
      "   Updated primaryPackagePurpose for: requests\n",
      "   Added annotations for: requests\n",
      "   Updated primaryPackagePurpose for: requests-oauthlib\n",
      "   Added annotations for: requests-oauthlib\n",
      "   Updated primaryPackagePurpose for: six\n",
      "   Added annotations for: six\n",
      "   Updated primaryPackagePurpose for: sniffio\n",
      "   Added annotations for: sniffio\n",
      "   Updated primaryPackagePurpose for: soupsieve\n",
      "   Added annotations for: soupsieve\n",
      "   Updated primaryPackagePurpose for: thealgorithms-python\n",
      "   Added annotations for: thealgorithms-python\n",
      "   Updated primaryPackagePurpose for: threadpoolctl\n",
      "   Added annotations for: threadpoolctl\n",
      "   Updated primaryPackagePurpose for: tomli\n",
      "   Added annotations for: tomli\n",
      "   Updated primaryPackagePurpose for: tzdata\n",
      "   Added annotations for: tzdata\n",
      "   Updated primaryPackagePurpose for: urllib3\n",
      "   Added annotations for: urllib3\n",
      "   Added new package from Trivy: uv.lock\n",
      "   Added CONTAINS relationship for: uv.lock\n",
      "   Added new package from Trivy: .\n",
      "   Added CONTAINS relationship for: .\n",
      "   Changes detected. Reordering keys and saving file...\n",
      "✅ Successfully supplemented and reordered 'combined_sbom.json'.\n",
      "--------------------------------------------------\n",
      "▶️  Processing: python-mini-projects\n",
      "   Updated primaryPackagePurpose for: click\n",
      "   Added annotations for: click\n",
      "   Updated primaryPackagePurpose for: idna\n",
      "   Added annotations for: idna\n",
      "   Updated primaryPackagePurpose for: webdriver-manager\n",
      "   Added annotations for: webdriver-manager\n",
      "   Updated primaryPackagePurpose for: pycryptodome\n",
      "   Added annotations for: pycryptodome\n",
      "   Updated primaryPackagePurpose for: requests\n",
      "   Added annotations for: requests\n",
      "   Updated primaryPackagePurpose for: beautifulsoup4\n",
      "   Added annotations for: beautifulsoup4\n",
      "   Updated primaryPackagePurpose for: selenium\n",
      "   Added annotations for: selenium\n",
      "   Updated primaryPackagePurpose for: soupsieve\n",
      "   Added annotations for: soupsieve\n",
      "   Updated primaryPackagePurpose for: chardet\n",
      "   Added annotations for: chardet\n",
      "   Updated primaryPackagePurpose for: wordcloud\n",
      "   Added annotations for: wordcloud\n",
      "   Updated primaryPackagePurpose for: matplotlib\n",
      "   Added annotations for: matplotlib\n",
      "   Updated primaryPackagePurpose for: Pillow\n",
      "   Added annotations for: Pillow\n",
      "   Updated primaryPackagePurpose for: urllib3\n",
      "   Added annotations for: urllib3\n",
      "   Updated primaryPackagePurpose for: pyparsing\n",
      "   Added annotations for: pyparsing\n",
      "   Updated primaryPackagePurpose for: certifi\n",
      "   Added annotations for: certifi\n",
      "   Updated primaryPackagePurpose for: boto3\n",
      "   Added annotations for: boto3\n",
      "   Updated primaryPackagePurpose for: python-dateutil\n",
      "   Added annotations for: python-dateutil\n",
      "   Updated primaryPackagePurpose for: six\n",
      "   Added annotations for: six\n",
      "   Updated primaryPackagePurpose for: wikipedia\n",
      "   Added annotations for: wikipedia\n",
      "   Updated primaryPackagePurpose for: kiwisolver\n",
      "   Added annotations for: kiwisolver\n",
      "   Updated primaryPackagePurpose for: cycler\n",
      "   Added annotations for: cycler\n",
      "   Updated primaryPackagePurpose for: numpy\n",
      "   Added annotations for: numpy\n",
      "   Updated primaryPackagePurpose for: pypdf2\n",
      "   Added annotations for: pypdf2\n",
      "   Updated primaryPackagePurpose for: botocore\n",
      "   Added annotations for: botocore\n",
      "   Updated primaryPackagePurpose for: requests\n",
      "   Added annotations for: requests\n",
      "   Updated primaryPackagePurpose for: nltk\n",
      "   Added annotations for: nltk\n",
      "   Updated primaryPackagePurpose for: pandas\n",
      "   Added annotations for: pandas\n",
      "   Updated primaryPackagePurpose for: newspaper\n",
      "   Added annotations for: newspaper\n",
      "   Updated primaryPackagePurpose for: img2pdf\n",
      "   Added annotations for: img2pdf\n",
      "   Updated primaryPackagePurpose for: tensorflow\n",
      "   Added annotations for: tensorflow\n",
      "   Updated primaryPackagePurpose for: wget\n",
      "   Added annotations for: wget\n",
      "   Updated primaryPackagePurpose for: sumy\n",
      "   Added annotations for: sumy\n",
      "   Updated primaryPackagePurpose for: progress\n",
      "   Added annotations for: progress\n",
      "   Updated primaryPackagePurpose for: gensim\n",
      "   Added annotations for: gensim\n",
      "   Updated primaryPackagePurpose for: sumeval\n",
      "   Added annotations for: sumeval\n",
      "   Updated primaryPackagePurpose for: python-dateutil\n",
      "   Added annotations for: python-dateutil\n",
      "   Updated primaryPackagePurpose for: openpyxl\n",
      "   Added annotations for: openpyxl\n",
      "   Updated primaryPackagePurpose for: model\n",
      "   Added annotations for: model\n",
      "   Updated primaryPackagePurpose for: Pillow\n",
      "   Added annotations for: Pillow\n",
      "   Updated primaryPackagePurpose for: utils\n",
      "   Added annotations for: utils\n",
      "   Updated primaryPackagePurpose for: idna\n",
      "   Added annotations for: idna\n",
      "   Updated primaryPackagePurpose for: six\n",
      "   Added annotations for: six\n",
      "   Updated primaryPackagePurpose for: et-xmlfile\n",
      "   Added annotations for: et-xmlfile\n",
      "   Updated primaryPackagePurpose for: colorama\n",
      "   Added annotations for: colorama\n",
      "   Updated primaryPackagePurpose for: ipaddr\n",
      "   Added annotations for: ipaddr\n",
      "   Updated primaryPackagePurpose for: numpy\n",
      "   Added annotations for: numpy\n",
      "   Updated primaryPackagePurpose for: html5lib\n",
      "   Added annotations for: html5lib\n",
      "   Updated primaryPackagePurpose for: pytz\n",
      "   Added annotations for: pytz\n",
      "   Updated primaryPackagePurpose for: tqdm\n",
      "   Added annotations for: tqdm\n",
      "   Updated primaryPackagePurpose for: webencodings\n",
      "   Added annotations for: webencodings\n",
      "   Updated primaryPackagePurpose for: beautifulsoup4\n",
      "   Added annotations for: beautifulsoup4\n",
      "   Updated primaryPackagePurpose for: bs4\n",
      "   Added annotations for: bs4\n",
      "   Updated primaryPackagePurpose for: urllib3\n",
      "   Added annotations for: urllib3\n",
      "   Updated primaryPackagePurpose for: pep517\n",
      "   Added annotations for: pep517\n",
      "   Updated primaryPackagePurpose for: contextlib2\n",
      "   Added annotations for: contextlib2\n",
      "   Updated primaryPackagePurpose for: certifi\n",
      "   Added annotations for: certifi\n",
      "   Updated primaryPackagePurpose for: retrying\n",
      "   Added annotations for: retrying\n",
      "   Updated primaryPackagePurpose for: distro\n",
      "   Added annotations for: distro\n",
      "   Updated primaryPackagePurpose for: lockfile\n",
      "   Added annotations for: lockfile\n",
      "   Updated primaryPackagePurpose for: msgpack\n",
      "   Added annotations for: msgpack\n",
      "   Updated primaryPackagePurpose for: packaging\n",
      "   Added annotations for: packaging\n",
      "   Updated primaryPackagePurpose for: six\n",
      "   Added annotations for: six\n",
      "   Updated primaryPackagePurpose for: lxml\n",
      "   Added annotations for: lxml\n",
      "   Updated primaryPackagePurpose for: pyparsing\n",
      "   Added annotations for: pyparsing\n",
      "   Updated primaryPackagePurpose for: requests\n",
      "   Added annotations for: requests\n",
      "   Updated primaryPackagePurpose for: appdirs\n",
      "   Added annotations for: appdirs\n",
      "   Updated primaryPackagePurpose for: distlib\n",
      "   Added annotations for: distlib\n",
      "   Updated primaryPackagePurpose for: pytoml\n",
      "   Added annotations for: pytoml\n",
      "   Updated primaryPackagePurpose for: Pillow\n",
      "   Added annotations for: Pillow\n",
      "   Updated primaryPackagePurpose for: certifi\n",
      "   Added annotations for: certifi\n",
      "   Updated primaryPackagePurpose for: CacheControl\n",
      "   Added annotations for: CacheControl\n",
      "   Updated primaryPackagePurpose for: zipp\n",
      "   Added annotations for: zipp\n",
      "   Updated primaryPackagePurpose for: prettytable\n",
      "   Added annotations for: prettytable\n",
      "   Updated primaryPackagePurpose for: tweepy\n",
      "   Added annotations for: tweepy\n",
      "   Updated primaryPackagePurpose for: emoji\n",
      "   Added annotations for: emoji\n",
      "   Updated primaryPackagePurpose for: charset-normalizer\n",
      "   Added annotations for: charset-normalizer\n",
      "   Updated primaryPackagePurpose for: jinja2\n",
      "   Added annotations for: jinja2\n",
      "   Updated primaryPackagePurpose for: requests\n",
      "   Added annotations for: requests\n",
      "   Updated primaryPackagePurpose for: idna\n",
      "   Added annotations for: idna\n",
      "   Updated primaryPackagePurpose for: pyecharts\n",
      "   Added annotations for: pyecharts\n",
      "   Updated primaryPackagePurpose for: pymysql\n",
      "   Added annotations for: pymysql\n",
      "   Updated primaryPackagePurpose for: simplejson\n",
      "   Added annotations for: simplejson\n",
      "   Updated primaryPackagePurpose for: tqdm\n",
      "   Added annotations for: tqdm\n",
      "   Updated primaryPackagePurpose for: xlwt\n",
      "   Added annotations for: xlwt\n",
      "   Updated primaryPackagePurpose for: PIL\n",
      "   Added annotations for: PIL\n",
      "   Updated primaryPackagePurpose for: typing-extensions\n",
      "   Added annotations for: typing-extensions\n",
      "   Updated primaryPackagePurpose for: wcwidth\n",
      "   Added annotations for: wcwidth\n",
      "   Updated primaryPackagePurpose for: urllib3\n",
      "   Added annotations for: urllib3\n",
      "   Updated primaryPackagePurpose for: configparser\n",
      "   Added annotations for: configparser\n",
      "   Updated primaryPackagePurpose for: gtts\n",
      "   Added annotations for: gtts\n",
      "   Updated primaryPackagePurpose for: markupsafe\n",
      "   Added annotations for: markupsafe\n",
      "   Updated primaryPackagePurpose for: importlib-metadata\n",
      "   Added annotations for: importlib-metadata\n",
      "   Updated primaryPackagePurpose for: pathlib\n",
      "   Added annotations for: pathlib\n",
      "   Updated primaryPackagePurpose for: googletrans\n",
      "   Added annotations for: googletrans\n",
      "   Updated primaryPackagePurpose for: opencv-python\n",
      "   Added annotations for: opencv-python\n",
      "   Updated primaryPackagePurpose for: agentocr\n",
      "   Added annotations for: agentocr\n",
      "   Updated primaryPackagePurpose for: ffpyplayer\n",
      "   Added annotations for: ffpyplayer\n",
      "   Updated primaryPackagePurpose for: xmltodict\n",
      "   Added annotations for: xmltodict\n",
      "   Updated primaryPackagePurpose for: htmlparser\n",
      "   Added annotations for: htmlparser\n",
      "   Updated primaryPackagePurpose for: opencv-python\n",
      "   Added annotations for: opencv-python\n",
      "   Updated primaryPackagePurpose for: geopy\n",
      "   Added annotations for: geopy\n",
      "   Updated primaryPackagePurpose for: opencv-python\n",
      "   Added annotations for: opencv-python\n",
      "   Updated primaryPackagePurpose for: jupyterlab\n",
      "   Added annotations for: jupyterlab\n",
      "   Updated primaryPackagePurpose for: matplotlib\n",
      "   Added annotations for: matplotlib\n",
      "   Updated primaryPackagePurpose for: pandas\n",
      "   Added annotations for: pandas\n",
      "   Updated primaryPackagePurpose for: onnxruntime\n",
      "   Added annotations for: onnxruntime\n",
      "   Updated primaryPackagePurpose for: notebook\n",
      "   Added annotations for: notebook\n",
      "   Updated primaryPackagePurpose for: pyautogui\n",
      "   Added annotations for: pyautogui\n",
      "   Updated primaryPackagePurpose for: numpy\n",
      "   Added annotations for: numpy\n",
      "   Updated primaryPackagePurpose for: rich\n",
      "   Added annotations for: rich\n",
      "   Updated primaryPackagePurpose for: chromedriver-binary\n",
      "   Added annotations for: chromedriver-binary\n",
      "   Updated primaryPackagePurpose for: proxytest\n",
      "   Added annotations for: proxytest\n",
      "   Updated primaryPackagePurpose for: psutil\n",
      "   Added annotations for: psutil\n",
      "   Updated primaryPackagePurpose for: ffmpeg\n",
      "   Added annotations for: ffmpeg\n",
      "   Updated primaryPackagePurpose for: flask-sqlalchemy\n",
      "   Added annotations for: flask-sqlalchemy\n",
      "   Updated primaryPackagePurpose for: pandas\n",
      "   Added annotations for: pandas\n",
      "   Updated primaryPackagePurpose for: pytz\n",
      "   Added annotations for: pytz\n",
      "   Updated primaryPackagePurpose for: py-notifier\n",
      "   Added annotations for: py-notifier\n",
      "   Updated primaryPackagePurpose for: win10toast\n",
      "   Added annotations for: win10toast\n",
      "   Updated primaryPackagePurpose for: ExifRead\n",
      "   Added annotations for: ExifRead\n",
      "   Updated primaryPackagePurpose for: speechrecognition\n",
      "   Added annotations for: speechrecognition\n",
      "   Updated primaryPackagePurpose for: pygame\n",
      "   Added annotations for: pygame\n",
      "   Updated primaryPackagePurpose for: dlib\n",
      "   Added annotations for: dlib\n",
      "   Updated primaryPackagePurpose for: pyaudio\n",
      "   Added annotations for: pyaudio\n",
      "   Updated primaryPackagePurpose for: pandas\n",
      "   Added annotations for: pandas\n",
      "   Updated primaryPackagePurpose for: flask\n",
      "   Added annotations for: flask\n",
      "   Updated primaryPackagePurpose for: dnspython\n",
      "   Added annotations for: dnspython\n",
      "   Updated primaryPackagePurpose for: exifread\n",
      "   Added annotations for: exifread\n",
      "   Updated primaryPackagePurpose for: pil\n",
      "   Added annotations for: pil\n",
      "   Updated primaryPackagePurpose for: cachecontrol\n",
      "   Added annotations for: cachecontrol\n",
      "   Added new package from Trivy: projects/All_links_from_given_webpage/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/All_links_from_given_webpage/requirements.txt\n",
      "   Added new package from Trivy: projects/Ascii_art/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Ascii_art/requirements.txt\n",
      "   Added new package from Trivy: projects/Battery_notification/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Battery_notification/requirements.txt\n",
      "   Added new package from Trivy: projects/Bouncing_ball_simulator/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Bouncing_ball_simulator/requirements.txt\n",
      "   Added new package from Trivy: projects/Capture_Video_Frames/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Capture_Video_Frames/requirements.txt\n",
      "   Added new package from Trivy: projects/Cli_todo/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Cli_todo/requirements.txt\n",
      "   Added new package from Trivy: projects/Convert_XML_To_JSON/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Convert_XML_To_JSON/requirements.txt\n",
      "   Added new package from Trivy: projects/Convert_a_image_to_pdf/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Convert_a_image_to_pdf/requirements.txt\n",
      "   Added new package from Trivy: projects/Create_a_script_to_encrypt_files_and_folder/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Create_a_script_to_encrypt_files_and_folder/requirements.txt\n",
      "   Added new package from Trivy: projects/Diff_Util/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Diff_Util/requirements.txt\n",
      "   Added new package from Trivy: projects/Dns_record/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Dns_record/requirements.txt\n",
      "   Added new package from Trivy: projects/Dominant_color/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Dominant_color/requirements.txt\n",
      "   Added new package from Trivy: projects/Download_images_from_website/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Download_images_from_website/requirements.txt\n",
      "   Added new package from Trivy: projects/EasyVideoPlayer/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/EasyVideoPlayer/requirements.txt\n",
      "   Added new package from Trivy: projects/Encrypt_and_decrypt_text/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Encrypt_and_decrypt_text/requirements.txt\n",
      "   Added new package from Trivy: projects/Fetch HTTP status code/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Fetch HTTP status code/requirements.txt\n",
      "   Added new package from Trivy: projects/Fetch_and_store_tweets/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Fetch_and_store_tweets/requirements.txt\n",
      "   Added new package from Trivy: projects/Find_imdb_rating/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Find_imdb_rating/requirements.txt\n",
      "   Added new package from Trivy: projects/Geocoding/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Geocoding/requirements.txt\n",
      "   Added new package from Trivy: projects/Get_meta_information_of_images/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Get_meta_information_of_images/requirements.txt\n",
      "   Added new package from Trivy: projects/Image_watermark/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Image_watermark/requirements.txt\n",
      "   Added new package from Trivy: projects/Instagram_profile/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Instagram_profile/requirements.txt\n",
      "   Added new package from Trivy: projects/Language_translator/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Language_translator/requirements.txt\n",
      "   Added new package from Trivy: projects/Merge_csv_files/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Merge_csv_files/requirements.txt\n",
      "   Added new package from Trivy: projects/Merge_pdfs/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Merge_pdfs/requirements.txt\n",
      "   Added new package from Trivy: projects/Movie Information Scraper/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Movie Information Scraper/requirements.txt\n",
      "   Added new package from Trivy: projects/Multi_language_OCR/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Multi_language_OCR/requirements.txt\n",
      "   Added new package from Trivy: projects/Random_Wikipedia_Article/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Random_Wikipedia_Article/requirements.txt\n",
      "   Added new package from Trivy: projects/S3_File_Upload/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/S3_File_Upload/requirements.txt\n",
      "   Added new package from Trivy: projects/Scrape_quotes/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Scrape_quotes/requirements.txt\n",
      "   Added new package from Trivy: projects/Scraping Medium Articles/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Scraping Medium Articles/requirements.txt\n",
      "   Added new package from Trivy: projects/Snapshot_of_given_website/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Snapshot_of_given_website/requirements.txt\n",
      "   Added new package from Trivy: projects/Speech_to_text/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Speech_to_text/requirements.txt\n",
      "   Added new package from Trivy: projects/Speed_Game/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Speed_Game/requirements.txt\n",
      "   Added new package from Trivy: projects/Split_File/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Split_File/requirements.txt\n",
      "   Added new package from Trivy: projects/Split_a_video_file_by_given_time_period/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Split_a_video_file_by_given_time_period/requirements.txt\n",
      "   Added new package from Trivy: projects/Terminal_progress_bar_with_images_resizing/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Terminal_progress_bar_with_images_resizing/requirements.txt\n",
      "   Added new package from Trivy: projects/Text_to_speech/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Text_to_speech/requirements.txt\n",
      "   Added new package from Trivy: projects/Todo_app/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Todo_app/requirements.txt\n",
      "   Added new package from Trivy: projects/Web_page_summation/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Web_page_summation/requirements.txt\n",
      "   Added new package from Trivy: projects/Web_scraping_a_youtube_comment/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Web_scraping_a_youtube_comment/requirements.txt\n",
      "   Added new package from Trivy: projects/Wikipedia_search_wordcloud/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/Wikipedia_search_wordcloud/requirements.txt\n",
      "   Added new package from Trivy: projects/XKCD_downloader/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/XKCD_downloader/requirements.txt\n",
      "   Added new package from Trivy: projects/capture_screenshot/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/capture_screenshot/requirements.txt\n",
      "   Added new package from Trivy: projects/cli_proxy_tester/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/cli_proxy_tester/requirements.txt\n",
      "   Added new package from Trivy: projects/convert_Imgs/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/convert_Imgs/requirements.txt\n",
      "   Added new package from Trivy: projects/convert_png_images_to_ico_format/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/convert_png_images_to_ico_format/requirements.txt\n",
      "   Added new package from Trivy: projects/detect_align_faces/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/detect_align_faces/requirements.txt\n",
      "   Added new package from Trivy: projects/download GeeksForGeeks articles/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/download GeeksForGeeks articles/requirements.txt\n",
      "   Added new package from Trivy: projects/export_mysql_to_csv_send_to_wocom/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/export_mysql_to_csv_send_to_wocom/requirements.txt\n",
      "   Added new package from Trivy: projects/racing_barchart_animation/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/racing_barchart_animation/requirements.txt\n",
      "   Added new package from Trivy: projects/steganography/requirements.txt\n",
      "   Added CONTAINS relationship for: projects/steganography/requirements.txt\n",
      "   Added new package from Trivy: Flask\n",
      "   Added CONTAINS relationship for: Flask\n",
      "   Added new package from Trivy: Flask-SQLAlchemy\n",
      "   Added CONTAINS relationship for: Flask-SQLAlchemy\n",
      "   Added new package from Trivy: HTMLParser\n",
      "   Added CONTAINS relationship for: HTMLParser\n",
      "   Added new package from Trivy: Jinja2\n",
      "   Added CONTAINS relationship for: Jinja2\n",
      "   Added new package from Trivy: MarkupSafe\n",
      "   Added CONTAINS relationship for: MarkupSafe\n",
      "   Added new package from Trivy: PyAudio\n",
      "   Added CONTAINS relationship for: PyAudio\n",
      "   Added new package from Trivy: PyAutoGUI\n",
      "   Added CONTAINS relationship for: PyAutoGUI\n",
      "   Added new package from Trivy: PyMySQL\n",
      "   Added CONTAINS relationship for: PyMySQL\n",
      "   Added new package from Trivy: PyPDF2\n",
      "   Added CONTAINS relationship for: PyPDF2\n",
      "   Added new package from Trivy: SpeechRecognition\n",
      "   Added CONTAINS relationship for: SpeechRecognition\n",
      "   Added new package from Trivy: gTTS\n",
      "   Added CONTAINS relationship for: gTTS\n",
      "   Added new package from Trivy: .\n",
      "   Added CONTAINS relationship for: .\n",
      "   Changes detected. Reordering keys and saving file...\n",
      "✅ Successfully supplemented and reordered 'combined_sbom.json'.\n",
      "--------------------------------------------------\n",
      "▶️  Processing: sbom-go-test\n",
      "   Updated primaryPackagePurpose for: github.com/common-nighthawk/go-figure\n",
      "   Added annotations for: github.com/common-nighthawk/go-figure\n",
      "   Updated primaryPackagePurpose for: golang.org/x/sys\n",
      "   Added annotations for: golang.org/x/sys\n",
      "   Updated primaryPackagePurpose for: github.com/mattn/go-colorable\n",
      "   Added annotations for: github.com/mattn/go-colorable\n",
      "   Updated primaryPackagePurpose for: github.com/mattn/go-isatty\n",
      "   Added annotations for: github.com/mattn/go-isatty\n",
      "   Updated primaryPackagePurpose for: github.com/fatih/color\n",
      "   Added annotations for: github.com/fatih/color\n",
      "   Added new package from Trivy: go.mod\n",
      "   Added CONTAINS relationship for: go.mod\n",
      "   Added new package from Trivy: .\n",
      "   Added CONTAINS relationship for: .\n",
      "   Changes detected. Reordering keys and saving file...\n",
      "✅ Successfully supplemented and reordered 'combined_sbom.json'.\n",
      "--------------------------------------------------\n",
      "All processes finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def get_purl_from_package(pkg):\n",
    "    \"\"\"パッケージ情報からpurl（Package URL）を抽出する.\"\"\"\n",
    "    if 'externalRefs' in pkg:\n",
    "        for ref in pkg['externalRefs']:\n",
    "            if ref.get('referenceType') == 'purl':\n",
    "                return ref.get('referenceLocator')\n",
    "    return None\n",
    "\n",
    "# --- 設定項目 ---\n",
    "target_directory = 'generated_sboms'\n",
    "base_sbom_filename = 'combined_sbom.json'\n",
    "# Trivyで生成したファイル名を指定\n",
    "source_sbom_filename = 'trivy-sbom.json'\n",
    "\n",
    "# --- 処理の開始 ---\n",
    "print(f\"--- Starting: Supplementing '{base_sbom_filename}' with data from Trivy ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "try:\n",
    "    # 'generated_sboms' 内のリポジトリ名を取得する\n",
    "    repo_dirs = [d for d in os.listdir(target_directory) if os.path.isdir(os.path.join(target_directory, d))]\n",
    "    \n",
    "    if not repo_dirs:\n",
    "        print(f\"No repository directories found in '{target_directory}'.\")\n",
    "\n",
    "    # 各リポジトリに対して処理を実行する\n",
    "    for repo_name in repo_dirs:\n",
    "        print(f\"▶️  Processing: {repo_name}\")\n",
    "\n",
    "        # --- パスの定義 ---\n",
    "        base_sbom_path = os.path.join(target_directory, repo_name, base_sbom_filename)\n",
    "        source_sbom_path = os.path.join(target_directory, repo_name, 'source', source_sbom_filename)\n",
    "\n",
    "        # --- ファイルの存在確認 ---\n",
    "        if not os.path.exists(base_sbom_path) or not os.path.exists(source_sbom_path):\n",
    "            print(f\"⚠️ Warning: One or both SBOM files are missing. Skipping.\")\n",
    "            print(\"-\" * 50)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # --- ステップ1: 両方のSBOMファイルを読み込む ---\n",
    "            with open(base_sbom_path, 'r', encoding='utf-8') as f:\n",
    "                base_data = json.load(f)\n",
    "            with open(source_sbom_path, 'r', encoding='utf-8') as f:\n",
    "                source_data = json.load(f)\n",
    "\n",
    "            initial_data_str = json.dumps(base_data, sort_keys=True)\n",
    "\n",
    "            # --- ステップ2: Trivyのパッケージ情報をpurlをキーにした辞書に整理 ---\n",
    "            source_package_map = {}\n",
    "            if 'packages' in source_data:\n",
    "                for pkg in source_data['packages']:\n",
    "                    purl = get_purl_from_package(pkg)\n",
    "                    if purl and purl not in source_package_map:\n",
    "                        source_package_map[purl] = pkg\n",
    "\n",
    "            # --- ステップ3: 既存パッケージの情報を補完 ---\n",
    "            if 'packages' in base_data:\n",
    "                for pkg in base_data['packages']:\n",
    "                    purl = get_purl_from_package(pkg)\n",
    "                    if purl and purl in source_package_map:\n",
    "                        source_pkg = source_package_map[purl]\n",
    "                        \n",
    "                        # primaryPackagePurposeを補完\n",
    "                        if (not pkg.get('primaryPackagePurpose') or pkg.get('primaryPackagePurpose') == 'NOASSERTION') and \\\n",
    "                           source_pkg.get('primaryPackagePurpose') and source_pkg.get('primaryPackagePurpose') != 'NOASSERTION':\n",
    "                            pkg['primaryPackagePurpose'] = source_pkg['primaryPackagePurpose']\n",
    "                            print(f\"   Updated primaryPackagePurpose for: {pkg.get('name')}\")\n",
    "\n",
    "                        # annotationsを追記\n",
    "                        if 'annotations' not in pkg and source_pkg.get('annotations'):\n",
    "                            pkg['annotations'] = source_pkg['annotations']\n",
    "                            print(f\"   Added annotations for: {pkg.get('name')}\")\n",
    "\n",
    "            # --- ステップ4: 不足パッケージと関連するRelationshipを追加 ---\n",
    "            if 'packages' in source_data:\n",
    "                # 親となるトップレベルパッケージのSPDXIDを特定する\n",
    "                main_package_spdx_id = None\n",
    "                for rel in base_data.get('relationships', []):\n",
    "                    if rel.get('relationshipType') == 'DESCRIBES' and rel.get('spdxElementId') == 'SPDXRef-DOCUMENT':\n",
    "                        main_package_spdx_id = rel.get('relatedSpdxElement')\n",
    "                        break\n",
    "                \n",
    "                if not main_package_spdx_id:\n",
    "                    print(\"⚠️ Warning: Could not find the main package ID. Cannot add new relationships.\")\n",
    "\n",
    "                base_pkg_names = {pkg.get('name') for pkg in base_data.get('packages', []) if pkg.get('name')}\n",
    "                \n",
    "                for source_pkg in source_data.get('packages', []):\n",
    "                    pkg_name = source_pkg.get('name')\n",
    "                    # パッケージ名がベースSBOMに存在しない場合のみ追加\n",
    "                    if pkg_name and pkg_name not in base_pkg_names:\n",
    "                        # パッケージを追加\n",
    "                        base_data.setdefault('packages', []).append(source_pkg)\n",
    "                        base_pkg_names.add(pkg_name)\n",
    "                        print(f\"   Added new package from Trivy: {pkg_name}\")\n",
    "                        \n",
    "                        # Relationshipも追加\n",
    "                        new_pkg_spdx_id = source_pkg.get('SPDXID')\n",
    "                        if main_package_spdx_id and new_pkg_spdx_id:\n",
    "                            new_relationship = {\n",
    "                                'spdxElementId': main_package_spdx_id,\n",
    "                                'relatedSpdxElement': new_pkg_spdx_id,\n",
    "                                'relationshipType': 'CONTAINS'\n",
    "                            }\n",
    "                            if new_relationship not in base_data.get('relationships', []):\n",
    "                                base_data.setdefault('relationships', []).append(new_relationship)\n",
    "                                print(f\"   Added CONTAINS relationship for: {pkg_name}\")\n",
    "\n",
    "            # --- ステップ5: Trivyのツール情報をcreatorsに追加 ---\n",
    "            if 'creationInfo' in source_data and 'creators' in source_data['creationInfo']:\n",
    "                base_creators = base_data.setdefault('creationInfo', {}).setdefault('creators', [])\n",
    "                for creator in source_data['creationInfo']['creators']:\n",
    "                    if creator not in base_creators:\n",
    "                        base_creators.append(creator)\n",
    "            \n",
    "            # --- ステップ6: 変更があった場合のみファイルを保存 ---\n",
    "            if initial_data_str != json.dumps(base_data, sort_keys=True):\n",
    "                print(f\"   Changes detected. Reordering keys and saving file...\")\n",
    "\n",
    "                key_order = [\n",
    "                    \"SPDXID\", \"spdxVersion\", \"creationInfo\", \"name\", \"dataLicense\",\n",
    "                    \"documentNamespace\", \"comment\", \"documentDescribes\", \"externalDocumentRefs\",\n",
    "                    \"packages\", \"files\", \"relationships\"\n",
    "                ]\n",
    "                ordered_data = {key: base_data[key] for key in key_order if key in base_data}\n",
    "                ordered_data.update({key: value for key, value in base_data.items() if key not in ordered_data})\n",
    "\n",
    "                with open(base_sbom_path, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(ordered_data, f, indent=2, ensure_ascii=False)\n",
    "                print(f\"✅ Successfully supplemented and reordered '{base_sbom_filename}'.\")\n",
    "            else:\n",
    "                print(\"   No new information to supplement from Trivy.\")\n",
    "\n",
    "        except (json.JSONDecodeError, KeyError) as e:\n",
    "            print(f\"❌ Error processing files for {repo_name}. Details: {e}\")\n",
    "        \n",
    "        finally:\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: The top-level directory '{target_directory}' was not found.\")\n",
    "\n",
    "print(\"All processes finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
